{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "living-ambassador",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-mistake",
   "metadata": {},
   "source": [
    "# Extract train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv(\"valeo_xtrain.csv\")\n",
    "ytrain = pd.read_csv(\"valeo_ytrain.csv\")\n",
    "xtest = pd.read_csv(\"valeo_xtest.csv\")\n",
    "\n",
    "X_train_full = xtrain.to_numpy()\n",
    "X_test_full = xtest.to_numpy()\n",
    "y_train_full = ytrain.to_numpy().ravel()\n",
    "y_train = np.copy(y_train_full)\n",
    "X_train = np.copy(X_train_full)\n",
    "X_test = np.copy(X_test_full)\n",
    "\n",
    "X_full = np.concatenate((X_train, X_test), axis = 0)\n",
    "\n",
    "index = ytrain[ytrain['Anomaly']==0].index.tolist()\n",
    "index_anomally = ytrain[ytrain['Anomaly']==1].index.tolist()\n",
    "X_normal = X_train[index]\n",
    "y_normal = y_train[index]\n",
    "X_anomally = X_train[index_anomally]\n",
    "y_anomally = y_train[index_anomally]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-floating",
   "metadata": {},
   "source": [
    "# Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "universal-anniversary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27586, 27)\n",
      "(27587, 27)\n",
      "(55173, 27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_full)\n",
    "X_full = scaler.transform(X_full)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-input",
   "metadata": {},
   "source": [
    "# Suppression des outliers des données normales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-craft",
   "metadata": {},
   "source": [
    "#### IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17063919979176737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "IQR = []\n",
    "for column in X_normal.T :\n",
    "    Q1 = np.quantile(column,0.25)\n",
    "    Q3 = np.quantile(column,0.75)\n",
    "    IQR.append((Q1 - 1.5*(Q3 - Q1), Q3 + 1.5*(Q3 - Q1)))\n",
    "\n",
    "idx = []\n",
    "index = 0\n",
    "for line in X_normal :\n",
    "    k = 0\n",
    "    for feature in line :\n",
    "        if feature < IQR[k][0] or feature > IQR[k][1] :\n",
    "            idx.append(index)\n",
    "            break\n",
    "        k+=1\n",
    "    index +=1\n",
    "print(len(idx)/len(X_normal))\n",
    "\n",
    "X_train = np.concatenate((np.delete(X_normal, idx, 0), X_anomally), axis=0)\n",
    "y_train = np.concatenate((np.delete(y_normal, idx, 0), y_anomally), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-singing",
   "metadata": {},
   "source": [
    "# Split train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parliamentary-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-commons",
   "metadata": {},
   "source": [
    "# Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030134365352002434"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination = np.count_nonzero(y_train == 1) / len(y_train)\n",
    "contamination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-realtor",
   "metadata": {},
   "source": [
    "### COPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "coated-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COPOD(contamination=0.02512143841078808)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.copod import COPOD\n",
    "\n",
    "clf = COPOD(contamination = contamination)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.6172656029613117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "linear-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ABOD(contamination=0.024968279862243974, method='fast', n_neighbors=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.abod import ABOD\n",
    "\n",
    "clf = ABOD(contamination = contamination, n_neighbors=20, method='fast')\n",
    "clf.fit(X_train)\n",
    "#0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fewer-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 27)                756       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 27)                756       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 27)                756       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 27)                162       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 27)                756       \n",
      "=================================================================\n",
      "Total params: 3,356\n",
      "Trainable params: 3,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "621/621 [==============================] - 3s 3ms/step - loss: 2.4051 - val_loss: 5.0571\n",
      "Epoch 2/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 1.0965 - val_loss: 5.8742\n",
      "Epoch 3/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 1.0398 - val_loss: 6.2737\n",
      "Epoch 4/100\n",
      "621/621 [==============================] - 2s 2ms/step - loss: 1.0145 - val_loss: 6.5098\n",
      "Epoch 5/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9735 - val_loss: 6.6758\n",
      "Epoch 6/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9722 - val_loss: 6.8040\n",
      "Epoch 7/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9918 - val_loss: 6.9137\n",
      "Epoch 8/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9730 - val_loss: 7.0117\n",
      "Epoch 9/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9641 - val_loss: 7.1037\n",
      "Epoch 10/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9951 - val_loss: 7.1886\n",
      "Epoch 11/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9597 - val_loss: 7.2621\n",
      "Epoch 12/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9702 - val_loss: 7.3265\n",
      "Epoch 13/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9725 - val_loss: 7.3856\n",
      "Epoch 14/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9802 - val_loss: 7.4311\n",
      "Epoch 15/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9710 - val_loss: 7.4679\n",
      "Epoch 16/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9709 - val_loss: 7.4900\n",
      "Epoch 17/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9747 - val_loss: 7.5119\n",
      "Epoch 18/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9732 - val_loss: 7.5233\n",
      "Epoch 19/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9763 - val_loss: 7.5286\n",
      "Epoch 20/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9494 - val_loss: 7.5318\n",
      "Epoch 21/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9807 - val_loss: 7.5332\n",
      "Epoch 22/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9493 - val_loss: 7.5334\n",
      "Epoch 23/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9694 - val_loss: 7.5333\n",
      "Epoch 24/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9451 - val_loss: 7.5332\n",
      "Epoch 25/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9496 - val_loss: 7.5331\n",
      "Epoch 26/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9481 - val_loss: 7.5330\n",
      "Epoch 27/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9578 - val_loss: 7.5329\n",
      "Epoch 28/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9725 - val_loss: 7.5329\n",
      "Epoch 29/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9601 - val_loss: 7.5328\n",
      "Epoch 30/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9668 - val_loss: 7.5328\n",
      "Epoch 31/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9551 - val_loss: 7.5328\n",
      "Epoch 32/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9592 - val_loss: 7.5328\n",
      "Epoch 33/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9481 - val_loss: 7.5328\n",
      "Epoch 34/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9703 - val_loss: 7.5327\n",
      "Epoch 35/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9578 - val_loss: 7.5327\n",
      "Epoch 36/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9548 - val_loss: 7.5327\n",
      "Epoch 37/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9577 - val_loss: 7.5327\n",
      "Epoch 38/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9668 - val_loss: 7.5327\n",
      "Epoch 39/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9725 - val_loss: 7.5326\n",
      "Epoch 40/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9679 - val_loss: 7.5326\n",
      "Epoch 41/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9563 - val_loss: 7.5326\n",
      "Epoch 42/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9636 - val_loss: 7.5326\n",
      "Epoch 43/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9621 - val_loss: 7.5326\n",
      "Epoch 44/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9546 - val_loss: 7.5326\n",
      "Epoch 45/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9595 - val_loss: 7.5326\n",
      "Epoch 46/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9531 - val_loss: 7.5326\n",
      "Epoch 47/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9550 - val_loss: 7.5326\n",
      "Epoch 48/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9485 - val_loss: 7.5326\n",
      "Epoch 49/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9658 - val_loss: 7.5326\n",
      "Epoch 50/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9517 - val_loss: 7.5326\n",
      "Epoch 51/100\n",
      "621/621 [==============================] - 2s 3ms/step - loss: 0.9448 - val_loss: 7.5326\n",
      "Epoch 52/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9481 - val_loss: 7.5326\n",
      "Epoch 53/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9482 - val_loss: 7.5326\n",
      "Epoch 54/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9552 - val_loss: 7.5326\n",
      "Epoch 55/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9540 - val_loss: 7.5326\n",
      "Epoch 56/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9530 - val_loss: 7.5326\n",
      "Epoch 57/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9543 - val_loss: 7.5326\n",
      "Epoch 58/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9835 - val_loss: 7.5326\n",
      "Epoch 59/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9503 - val_loss: 7.5326\n",
      "Epoch 60/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9580 - val_loss: 7.5326\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9603 - val_loss: 7.5326\n",
      "Epoch 62/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9629 - val_loss: 7.5326\n",
      "Epoch 63/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9370 - val_loss: 7.5326\n",
      "Epoch 64/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9642 - val_loss: 7.5326\n",
      "Epoch 65/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9712 - val_loss: 7.5326\n",
      "Epoch 66/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9699 - val_loss: 7.5326\n",
      "Epoch 67/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9678 - val_loss: 7.5326\n",
      "Epoch 68/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9622 - val_loss: 7.5326\n",
      "Epoch 69/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9490 - val_loss: 7.5326\n",
      "Epoch 70/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9562 - val_loss: 7.5326\n",
      "Epoch 71/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9484 - val_loss: 7.5326\n",
      "Epoch 72/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9517 - val_loss: 7.5326\n",
      "Epoch 73/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9522 - val_loss: 7.5326\n",
      "Epoch 74/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9561 - val_loss: 7.5326\n",
      "Epoch 75/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9697 - val_loss: 7.5326\n",
      "Epoch 76/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9445 - val_loss: 7.5326\n",
      "Epoch 77/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9371 - val_loss: 7.5326\n",
      "Epoch 78/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9479 - val_loss: 7.5326\n",
      "Epoch 79/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9756 - val_loss: 7.5326\n",
      "Epoch 80/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9683 - val_loss: 7.5326\n",
      "Epoch 81/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9582 - val_loss: 7.5326\n",
      "Epoch 82/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9458 - val_loss: 7.5326\n",
      "Epoch 83/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9529 - val_loss: 7.5326\n",
      "Epoch 84/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9747 - val_loss: 7.5326\n",
      "Epoch 85/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9684 - val_loss: 7.5326\n",
      "Epoch 86/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9638 - val_loss: 7.5326\n",
      "Epoch 87/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9627 - val_loss: 7.5326\n",
      "Epoch 88/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9495 - val_loss: 7.5326\n",
      "Epoch 89/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9734 - val_loss: 7.5326\n",
      "Epoch 90/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9471 - val_loss: 7.5326\n",
      "Epoch 91/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9601 - val_loss: 7.5326\n",
      "Epoch 92/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9617 - val_loss: 7.5326\n",
      "Epoch 93/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9561 - val_loss: 7.5326\n",
      "Epoch 94/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9461 - val_loss: 7.5326\n",
      "Epoch 95/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9471 - val_loss: 7.5326\n",
      "Epoch 96/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9715 - val_loss: 7.5326\n",
      "Epoch 97/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9632 - val_loss: 7.5326\n",
      "Epoch 98/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9765 - val_loss: 7.5326\n",
      "Epoch 99/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9681 - val_loss: 7.5326\n",
      "Epoch 100/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.9514 - val_loss: 7.5326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.024968279862243974,\n",
       "      dropout_rate=0.2, epochs=100, hidden_activation='relu',\n",
       "      hidden_neurons=[27, 5, 5, 27], l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x0000024809C8C0D8>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "clf = AutoEncoder(hidden_neurons = [27, 5, 5, 27],epochs=100, batch_size=32, dropout_rate=0.2, l2_regularizer=0.1, validation_size=0.1\n",
    "                  , preprocessing=True, verbose=1, random_state=None, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n",
    "# 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=2,assign_labels=\"discretize\")\n",
    "clf = CBLOF(contamination = contamination, n_clusters=2, clustering_estimator =clustering)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "engaged-sally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COF(contamination=0.025036818851251842, n_neighbors=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.cof import COF\n",
    "\n",
    "clf = COF(contamination=contamination, n_neighbors=2)\n",
    "clf.fit(X_train)\n",
    "\n",
    "# 0.6 mais seulement sur le train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulated-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureBagging(base_estimator=None, bootstrap_features=False,\n",
       "        check_detector=True, check_estimator=False, combination='average',\n",
       "        contamination=0.024605764002175096, estimator_params={},\n",
       "        max_features=1.0, n_estimators=10, n_jobs=1, random_state=None,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "\n",
    "clf = FeatureBagging(base_estimator=None, n_estimators=10, contamination=contamination, max_features=1.0, bootstrap_features=False, \n",
    "           check_detector=True, check_estimator=False, n_jobs=1, random_state=None, combination='average',\n",
    "           verbose=0, estimator_params=None)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floating-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBOS(alpha=0.1, contamination=0.024605764002175096, n_bins=10, tol=0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "clf = HBOS(n_bins=10, alpha=0.1, tol=0.5, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-shanghai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IForest(behaviour='old', bootstrap=False, contamination=0.024605764002175096,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=1,\n",
       "    random_state=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "clf = IForest(n_estimators=100, max_samples='auto', contamination=contamination, max_features=1.0, \n",
    "        bootstrap=False, n_jobs=1, behaviour='old', random_state=None, verbose=0)\n",
    "clf.fit(X_train)\n",
    "\n",
    "# 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "measured-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(algorithm='auto', contamination=0.024605764002175096, leaf_size=30,\n",
       "  method='largest', metric='minkowski', metric_params=None, n_jobs=1,\n",
       "  n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.knn import KNN\n",
    "\n",
    "clf = KNN(contamination=contamination, n_neighbors=5, method='largest', radius=1.0, algorithm='auto',\n",
    "          leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=1)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.5263176850471933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parallel-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMDD(contamination=0.024605764002175096, dis_measure='aad', n_iter=2,\n",
       "   random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "clf = LMDD(contamination=contamination, n_iter=2, dis_measure='aad', random_state=None)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comparable-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LODA(contamination=0.024605764002175096, n_bins=10, n_random_cuts=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.loda import LODA\n",
    "\n",
    "clf = LODA(contamination=contamination, n_bins=10, n_random_cuts=100)\n",
    "clf.fit(X_train)\n",
    "\n",
    "# 0.4670479384003974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "official-israel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOF(algorithm='auto', contamination=0.024605764002175096, leaf_size=30,\n",
       "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=20, p=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.lof import LOF\n",
    "\n",
    "clf = LOF(n_neighbors=20, algorithm='auto', leaf_size=30, metric='minkowski', p=2, \n",
    "          metric_params=None, contamination=contamination, n_jobs=1)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#compute pas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "engaged-james",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7b0284d605d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOCI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\loci.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_decision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         self.labels_ = (self.decision_scores_ > self.threshold_).astype(\n\u001b[0;32m    237\u001b[0m             'int').ravel()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\loci.py\u001b[0m in \u001b[0;36m_calculate_decision_score\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    204\u001b[0m                 n_values = self._get_alpha_n(dist_matrix,\n\u001b[0;32m    205\u001b[0m                                              _get_sampling_N(dist_matrix,\n\u001b[1;32m--> 206\u001b[1;33m                                                              p_ix, r), r)\n\u001b[0m\u001b[0;32m    207\u001b[0m                 \u001b[0mcur_alpha_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_alpha_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[0mn_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\loci.py\u001b[0m in \u001b[0;36m_get_alpha_n\u001b[1;34m(self, dist_matrix, indices, r)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             alpha_n = np.count_nonzero(\n\u001b[1;32m--> 179\u001b[1;33m                 dist_matrix[indices, :] < (r * self.alpha), axis=1)\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0malpha_n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyod.models.loci import LOCI\n",
    "\n",
    "clf = LOCI(contamination=contamination, alpha=0.5, k=1)\n",
    "clf.fit(X_val)\n",
    "\n",
    "#trop long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pleased-receipt",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6a634962ff65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlscp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSCP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m clf = LSCP(detector_list, local_region_size=30, local_max_features=1.0, n_bins=10, \n\u001b[0m\u001b[0;32m      4\u001b[0m            random_state=None, contamination=contamination)\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detector_list' is not defined"
     ]
    }
   ],
   "source": [
    "from pyod.models.lscp import LSCP\n",
    "\n",
    "clf = LSCP(detector_list, local_region_size=30, local_max_features=1.0, n_bins=10, \n",
    "           random_state=None, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "urban-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-392.334369588882510 > -594.372448752129230). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-518.554869030623195 > -529.673038789515999). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.147563016859067 > -594.902801234875710). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-394.588760364187124 > -589.809307124274937). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-540.126108886291490 > -592.496290943869667). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-420.727604237692503 > -593.402934912120713). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-525.414093427432135 > -565.929571210128643). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-393.594711311640140 > -595.449507988063715). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-423.403198640602398 > -592.729868022550363). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-557.413754527657261 > -625.646273781738273). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-422.547069803008412 > -593.871424747131869). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-388.989508330869739 > -591.209362864625973). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-389.608947424859139 > -587.506514437632518). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-391.409326812905476 > -627.309611045115275). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-524.267736744731337 > -593.648502818134602). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-422.298063657016030 > -487.037398774087933). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.518336079992480 > -593.484824005640576). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-420.686078918170494 > -600.657808321985613). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-413.619025347970307 > -601.524978467213941). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-419.751484560561551 > -556.271819840716034). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.470399613025791 > -589.862230114141880). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-518.898335293442301 > -569.114862001075380). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-525.844129862890554 > -564.709692412274308). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-488.523969850827257 > -495.659012510383889). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-391.850454882065833 > -660.007933812554825). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.717778367884875 > -591.533022945305675). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-422.452495947406533 > -626.269123924268229). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-428.346548206766101 > -600.265652025291274). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-425.677142931572405 > -596.596599227231195). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-400.071152878229498 > -626.758179813865127). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-426.352765826292966 > -596.618533496782902). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-487.171012900902724 > -494.736672884863140). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-489.822507903629685 > -489.957722868521103). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-448.690069265412546 > -593.357735576847404). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-423.528132071376604 > -628.961666534663436). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-521.802695793093790 > -525.812307109483299). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-450.430603429357859 > -626.478478913538993). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-448.660584840907973 > -594.178241485442641). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-495.982879033300662 > -515.358778822839554). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.322703906552363 > -590.855579423389258). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-527.048093281048750 > -594.799220711232465). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-425.263626830275598 > -593.527077935117291). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.927112394359597 > -587.534427343593165). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-487.651192058165350 > -555.251024135003149). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-490.064657354662813 > -595.227370564972148). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-430.306616445855866 > -627.346016103228294). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-525.568418499519225 > -593.959398363680407). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-422.239685714472671 > -600.754101653067323). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-428.123223204490216 > -591.804945431311126). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-388.575052941109902 > -587.908598240965375). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-488.388297058675789 > -558.852063988521195). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-519.199932748234801 > -626.445893938180120). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-452.981389599875172 > -592.560764338990339). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-534.721665103109785 > -626.369858698691814). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-518.842857971406602 > -588.406295485209398). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-491.963385908548673 > -492.999312152506775). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-502.455607254060396 > -632.371105028608554). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-491.772186974775082 > -591.246146688805425). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-522.696507538604351 > -589.392120561431398). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-426.821160479407581 > -628.954612041542077). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-424.054377411013206 > -594.188711660444596). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-419.662857760928489 > -597.934752728545959). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-497.319375546144499 > -590.475483061562500). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-513.195467856355094 > -530.070115963895887). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-395.555098722189655 > -591.541778777297168). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-487.053470757343462 > -493.761233762252402). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-427.103644693302158 > -589.786679636141912). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-517.069272630243859 > -527.031772658774116). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.940054064427557 > -578.179894779671599). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-493.920758230129991 > -508.537566577477321). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-516.937305567700037 > -552.138872638227554). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.982741555885013 > -649.103569305315204). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-410.029049922068225 > -581.749370798023051). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-510.032719732542773 > -517.282149213982166). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-388.295127407789721 > -618.227730097934113). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-381.501724374521132 > -581.355815774884263). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-416.730710686784676 > -577.582729848222129). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-385.139337331618890 > -608.939519589291308). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-390.196652354810169 > -578.199526296155113). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-481.003299567082308 > -481.567448586984881). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.124109097352743 > -577.123314099052550). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-480.605562043495468 > -484.334548493263298). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-387.142973605035536 > -580.751570971560682). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-510.248778041427329 > -514.990285096057846). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-411.285294995161962 > -647.422178320836565). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-384.472800769112553 > -579.293970815429248). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-486.618010452297028 > -513.750437696103518). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.167664640499538 > -580.404028590347025). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.425762660382134 > -615.305341301099816). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-514.401648581075619 > -516.585993442496033). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-479.934228448527620 > -483.568446246041503). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-393.233346098412540 > -580.278679043718512). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.275986806916649 > -585.197833702340859). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-392.499872654874025 > -610.438081257414865). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-480.019572634409883 > -482.537369465105257). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-511.718117156750338 > -518.489397450699016). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-417.526166262132108 > -580.727378542363908). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-443.184416122294806 > -641.781290013304783). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-448.408668542139935 > -618.211254876238513). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-407.716310785426401 > -582.146620312518621). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-389.780696193648794 > -610.505832184992983). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.033090421616805 > -611.754373531885335). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.786384176522631 > -618.795465357837770). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-419.047089966873898 > -619.125846216667924). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-544.646417585618792 > -547.343148777607780). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.471200718832051 > -578.082109069945091). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-447.244659314004650 > -617.436869687311855). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.231860319907980 > -617.627132718553071). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.841472181629115 > -611.501702181623841). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-513.362860267213364 > -515.101726092038575). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-486.027117375692114 > -519.174458800288676). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.895317052011592 > -613.905012530758768). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-509.316092817044876 > -515.974064347065678). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.454281030796722 > -584.117935647652416). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-416.866155580912107 > -584.985851889017454). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.391806857918425 > -613.159797037098542). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.281161257370968 > -580.556378624799549). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-518.043469581856698 > -537.923901447826097). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-489.217614887248999 > -515.563605444805717). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-419.022439013087137 > -577.909805924773650). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-411.838328006797781 > -581.521189983566046). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.653355899452947 > -612.602772476189898). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.123636487829117 > -586.606667538117222). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-385.565968448100875 > -583.833575304043165). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-416.987296468612499 > -649.056652359232771). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-387.386691260912130 > -577.557623477688480). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-446.441633026415388 > -619.246330315613818). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-385.225839410723495 > -611.996947443196291). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-497.399625130497952 > -507.894148843825576). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-385.820775589289951 > -615.856221388786821). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.170640186036962 > -583.976664648330598). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-519.585477937339647 > -541.667873348684225). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-443.118726436617692 > -616.577312038791661). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.765433963677140 > -581.029405606853743). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.698443372694669 > -582.157835345747344). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.276092484882497 > -614.875229741687576). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.577121722770869 > -615.279029233504502). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-413.413898221020418 > -612.183911367463224). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-481.785724320315296 > -508.730207565595322). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-413.314945761638796 > -588.376386663588391). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.998562459885704 > -574.066776666977717). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-396.603258372601886 > -578.607706071947291). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-380.258323715207553 > -578.153548834223329). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-391.969834913823377 > -580.573329119466393). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.444050311138767 > -579.848672261347588). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.478810464491289 > -587.307066775111934). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-485.846989536535034 > -518.297632035388460). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-441.623861648105446 > -582.924251860990125). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-383.412989181127614 > -579.130553475308034). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.822279321061330 > -612.919542524831627). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.291620941432939 > -588.978288725107745). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-387.589093852237795 > -547.001763347564292). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-384.996896243619517 > -579.415253265254819). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-446.905233509353877 > -619.004369964409648). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-410.257368569020457 > -613.147245617446060). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-389.386299987073301 > -585.550653592316053). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-446.815565498521892 > -643.332803651843619). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-511.686169989148880 > -522.626053257136959). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.249297949468485 > -588.246312534535718). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-484.818420926114300 > -517.454404680391463). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.771636912046404 > -551.383030571252903). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-418.186969737225581 > -614.987801855825865). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-413.104406906854479 > -645.619473152361820). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.656951823296936 > -575.867015565672546). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-424.350129927910473 > -621.759592730331974). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-491.023686421675166 > -512.279109581244370). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-482.045852600558192 > -513.701435670859155). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-515.187138094422380 > -550.338241003598000). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-480.937575778375106 > -518.791904057053102). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-445.545341420974466 > -647.001018543882651). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-413.699029873915435 > -586.697312008673975). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-446.445744211826252 > -647.045383018991288). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-421.942404504903834 > -614.095182680724747). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-415.964239034836282 > -619.445476355809546). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.305607326886047 > -583.388646341141907). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-512.440105719338931 > -517.651408240749220). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-482.418949016635452 > -517.921817903663737). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.668385361709852 > -580.287623563901775). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.740565082817056 > -617.459091001725483). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-386.501195939460160 > -615.923342084939463). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-481.224507664446151 > -486.108812831061073). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-482.622687866409592 > -516.629105981084876). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-387.053559551942442 > -576.287753044957981). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-510.928248876552857 > -515.074412562294583). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-511.237305881037969 > -513.663168398209109). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-417.002692805735251 > -620.829698172316853). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-389.597260489247674 > -613.359807816825423). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-446.164407444810422 > -615.879042923662155). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-444.895362666890662 > -587.658926387973224). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-416.775591186264080 > -613.056869641704225). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-481.854723356688510 > -508.754527823366686). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-510.970174248443641 > -515.595226937116195). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-487.456546680097574 > -516.987016417475388). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-411.796289082773512 > -582.816249052046601). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-482.143482890639973 > -511.423274033404311). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-419.475387265767040 > -612.358113907132974). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.388580309912754 > -642.767782644528552). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-382.989351049878280 > -580.658575590806095). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-414.664906598905645 > -577.990033020822693). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-383.188407697657851 > -615.700675661780451). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-412.695798073193430 > -648.673135255801981). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:171: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-404.931073578885560 > -596.680048942884241). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MCD(assume_centered=False, contamination=0.024605764002175096,\n",
       "  random_state=None, store_precision=True, support_fraction=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.mcd import MCD\n",
    "\n",
    "clf = MCD(contamination=contamination, store_precision=True, assume_centered=False, \n",
    "          support_fraction=None, random_state=None)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "twenty-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60\n",
      "\n",
      "Testing for epoch 1 index 1:\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D9534CBD38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D953635678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D9549841F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D954994708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D9549948B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D9536351F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D9536570D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D954AE4D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D954B9AD38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D954C51D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D954994EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D954984048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D95312B438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D956DBBB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Testing for epoch 1 index 2:\n",
      "\n",
      "Testing for epoch 1 index 3:\n",
      "\n",
      "Testing for epoch 1 index 4:\n",
      "\n",
      "Testing for epoch 1 index 5:\n",
      "\n",
      "Testing for epoch 1 index 6:\n",
      "\n",
      "Testing for epoch 1 index 7:\n",
      "\n",
      "Testing for epoch 1 index 8:\n",
      "\n",
      "Testing for epoch 1 index 9:\n",
      "\n",
      "Testing for epoch 1 index 10:\n",
      "\n",
      "Testing for epoch 1 index 11:\n",
      "\n",
      "Testing for epoch 1 index 12:\n",
      "\n",
      "Testing for epoch 1 index 13:\n",
      "\n",
      "Testing for epoch 1 index 14:\n",
      "\n",
      "Testing for epoch 1 index 15:\n",
      "\n",
      "Testing for epoch 1 index 16:\n",
      "\n",
      "Testing for epoch 1 index 17:\n",
      "\n",
      "Testing for epoch 1 index 18:\n",
      "\n",
      "Testing for epoch 1 index 19:\n",
      "\n",
      "Testing for epoch 1 index 20:\n",
      "\n",
      "Testing for epoch 1 index 21:\n",
      "\n",
      "Testing for epoch 1 index 22:\n",
      "\n",
      "Testing for epoch 1 index 23:\n",
      "\n",
      "Testing for epoch 1 index 24:\n",
      "\n",
      "Testing for epoch 1 index 25:\n",
      "\n",
      "Testing for epoch 1 index 26:\n",
      "\n",
      "Testing for epoch 1 index 27:\n",
      "\n",
      "Testing for epoch 1 index 28:\n",
      "\n",
      "Testing for epoch 1 index 29:\n",
      "\n",
      "Testing for epoch 1 index 30:\n",
      "\n",
      "Testing for epoch 1 index 31:\n",
      "\n",
      "Testing for epoch 1 index 32:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-20849cd93b2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMO_GAAL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_g\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-06\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\mo_gaal.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[1;31m# Get the target value of sub-generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                 \u001b[0mpred_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "\n",
    "clf = MO_GAAL(k=10, stop_epochs=20, lr_d=0.01, lr_g=0.0001, decay=1e-06, momentum=0.9, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "multiple-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCSVM(cache_size=200, coef0=0.0, contamination=0.001, degree=5, gamma='scale',\n",
       "   kernel='rbf', max_iter=-1, nu=0.99, shrinking=True, tol=0.001,\n",
       "   verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One class svm !\n",
    "\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "clf = OCSVM(kernel='poly', degree=5, gamma='scale', coef0=0.0, tol=0.001, nu=0.99, \n",
    "            shrinking=True, cache_size=200, verbose=False, max_iter=- 1, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.6692921013412817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charitable-gambling",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 22344 is out of bounds for axis 0 with size 22344",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9dde3a052598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 22344 is out of bounds for axis 0 with size 22344"
     ]
    }
   ],
   "source": [
    "np.concatenate((X_train[index], Xtest), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "substantial-crack",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1a460bdfe5ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel_execution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_decision_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrod_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrod_nD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mrod_nD\u001b[1;34m(X, parallel)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0msubspaces_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msubspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_subspaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0msubspaces_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubspaces_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mprocess_sub\u001b[1;34m(subspace)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mApply\u001b[0m \u001b[0mROD\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[1;36m3\u001b[0m\u001b[0mD\u001b[0m \u001b[0msubSpace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mmad_subspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrod_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmad_subspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mrod_3D\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m    134\u001b[0m     \u001b[1;31m# find the geometric median\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mgm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeometric_median\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;31m# find its norm and center data around it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mnorm_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36mgeometric_median\u001b[1;34m(x, eps)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mgm_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# initialize geometric median\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgm_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mnon_zeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mDinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_zeros\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyod\\models\\rod.py\u001b[0m in \u001b[0;36meuclidean\u001b[1;34m(v1, v2, c)\u001b[0m\n\u001b[0;32m    121\u001b[0m             res.append([np.sqrt((_v[0] - v2[0]) ** 2 +\n\u001b[0;32m    122\u001b[0m                                 \u001b[1;33m(\u001b[0m\u001b[0m_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                                 (_v[2] - v2[2]) ** 2)])\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     return np.sqrt((v1[0] - v2[0]) ** 2 +\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyod.models.rod import ROD\n",
    "\n",
    "clf = ROD(contamination=contamination, parallel_execution=False)\n",
    "clf.fit(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "referenced-rebel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOD(alpha=None, contamination=0.025196920873612604, n_neighbors=None,\n",
       "  ref_set=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.sod import SOD\n",
    "\n",
    "clf = SOD(contamination=contamination, n_neighbors=20, ref_set=10, alpha=0.8)\n",
    "clf.fit(X_val)\n",
    "\n",
    "#0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affecting-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60\n",
      "\n",
      "Testing for epoch 1 index 1:\n",
      "\n",
      "Testing for epoch 1 index 2:\n",
      "\n",
      "Testing for epoch 1 index 3:\n",
      "\n",
      "Testing for epoch 1 index 4:\n",
      "\n",
      "Testing for epoch 1 index 5:\n",
      "\n",
      "Testing for epoch 1 index 6:\n",
      "\n",
      "Testing for epoch 1 index 7:\n",
      "\n",
      "Testing for epoch 1 index 8:\n",
      "\n",
      "Testing for epoch 1 index 9:\n",
      "\n",
      "Testing for epoch 1 index 10:\n",
      "\n",
      "Testing for epoch 1 index 11:\n",
      "\n",
      "Testing for epoch 1 index 12:\n",
      "\n",
      "Testing for epoch 1 index 13:\n",
      "\n",
      "Testing for epoch 1 index 14:\n",
      "\n",
      "Testing for epoch 1 index 15:\n",
      "\n",
      "Testing for epoch 1 index 16:\n",
      "\n",
      "Testing for epoch 1 index 17:\n",
      "\n",
      "Testing for epoch 1 index 18:\n",
      "\n",
      "Testing for epoch 1 index 19:\n",
      "\n",
      "Testing for epoch 1 index 20:\n",
      "\n",
      "Testing for epoch 1 index 21:\n",
      "\n",
      "Testing for epoch 1 index 22:\n",
      "\n",
      "Testing for epoch 1 index 23:\n",
      "\n",
      "Testing for epoch 1 index 24:\n",
      "\n",
      "Testing for epoch 1 index 25:\n",
      "\n",
      "Testing for epoch 1 index 26:\n",
      "\n",
      "Testing for epoch 1 index 27:\n",
      "\n",
      "Testing for epoch 1 index 28:\n",
      "\n",
      "Testing for epoch 1 index 29:\n",
      "\n",
      "Testing for epoch 1 index 30:\n",
      "\n",
      "Testing for epoch 1 index 31:\n",
      "\n",
      "Testing for epoch 1 index 32:\n",
      "\n",
      "Testing for epoch 1 index 33:\n",
      "\n",
      "Testing for epoch 1 index 34:\n",
      "\n",
      "Testing for epoch 1 index 35:\n",
      "\n",
      "Testing for epoch 1 index 36:\n",
      "\n",
      "Testing for epoch 1 index 37:\n",
      "\n",
      "Testing for epoch 1 index 38:\n",
      "\n",
      "Testing for epoch 1 index 39:\n",
      "\n",
      "Testing for epoch 1 index 40:\n",
      "\n",
      "Testing for epoch 1 index 41:\n",
      "\n",
      "Testing for epoch 1 index 42:\n",
      "\n",
      "Testing for epoch 1 index 43:\n",
      "\n",
      "Testing for epoch 1 index 44:\n",
      "Epoch 2 of 60\n",
      "\n",
      "Testing for epoch 2 index 1:\n",
      "\n",
      "Testing for epoch 2 index 2:\n",
      "\n",
      "Testing for epoch 2 index 3:\n",
      "\n",
      "Testing for epoch 2 index 4:\n",
      "\n",
      "Testing for epoch 2 index 5:\n",
      "\n",
      "Testing for epoch 2 index 6:\n",
      "\n",
      "Testing for epoch 2 index 7:\n",
      "\n",
      "Testing for epoch 2 index 8:\n",
      "\n",
      "Testing for epoch 2 index 9:\n",
      "\n",
      "Testing for epoch 2 index 10:\n",
      "\n",
      "Testing for epoch 2 index 11:\n",
      "\n",
      "Testing for epoch 2 index 12:\n",
      "\n",
      "Testing for epoch 2 index 13:\n",
      "\n",
      "Testing for epoch 2 index 14:\n",
      "\n",
      "Testing for epoch 2 index 15:\n",
      "\n",
      "Testing for epoch 2 index 16:\n",
      "\n",
      "Testing for epoch 2 index 17:\n",
      "\n",
      "Testing for epoch 2 index 18:\n",
      "\n",
      "Testing for epoch 2 index 19:\n",
      "\n",
      "Testing for epoch 2 index 20:\n",
      "\n",
      "Testing for epoch 2 index 21:\n",
      "\n",
      "Testing for epoch 2 index 22:\n",
      "\n",
      "Testing for epoch 2 index 23:\n",
      "\n",
      "Testing for epoch 2 index 24:\n",
      "\n",
      "Testing for epoch 2 index 25:\n",
      "\n",
      "Testing for epoch 2 index 26:\n",
      "\n",
      "Testing for epoch 2 index 27:\n",
      "\n",
      "Testing for epoch 2 index 28:\n",
      "\n",
      "Testing for epoch 2 index 29:\n",
      "\n",
      "Testing for epoch 2 index 30:\n",
      "\n",
      "Testing for epoch 2 index 31:\n",
      "\n",
      "Testing for epoch 2 index 32:\n",
      "\n",
      "Testing for epoch 2 index 33:\n",
      "\n",
      "Testing for epoch 2 index 34:\n",
      "\n",
      "Testing for epoch 2 index 35:\n",
      "\n",
      "Testing for epoch 2 index 36:\n",
      "\n",
      "Testing for epoch 2 index 37:\n",
      "\n",
      "Testing for epoch 2 index 38:\n",
      "\n",
      "Testing for epoch 2 index 39:\n",
      "\n",
      "Testing for epoch 2 index 40:\n",
      "\n",
      "Testing for epoch 2 index 41:\n",
      "\n",
      "Testing for epoch 2 index 42:\n",
      "\n",
      "Testing for epoch 2 index 43:\n",
      "\n",
      "Testing for epoch 2 index 44:\n",
      "Epoch 3 of 60\n",
      "\n",
      "Testing for epoch 3 index 1:\n",
      "\n",
      "Testing for epoch 3 index 2:\n",
      "\n",
      "Testing for epoch 3 index 3:\n",
      "\n",
      "Testing for epoch 3 index 4:\n",
      "\n",
      "Testing for epoch 3 index 5:\n",
      "\n",
      "Testing for epoch 3 index 6:\n",
      "\n",
      "Testing for epoch 3 index 7:\n",
      "\n",
      "Testing for epoch 3 index 8:\n",
      "\n",
      "Testing for epoch 3 index 9:\n",
      "\n",
      "Testing for epoch 3 index 10:\n",
      "\n",
      "Testing for epoch 3 index 11:\n",
      "\n",
      "Testing for epoch 3 index 12:\n",
      "\n",
      "Testing for epoch 3 index 13:\n",
      "\n",
      "Testing for epoch 3 index 14:\n",
      "\n",
      "Testing for epoch 3 index 15:\n",
      "\n",
      "Testing for epoch 3 index 16:\n",
      "\n",
      "Testing for epoch 3 index 17:\n",
      "\n",
      "Testing for epoch 3 index 18:\n",
      "\n",
      "Testing for epoch 3 index 19:\n",
      "\n",
      "Testing for epoch 3 index 20:\n",
      "\n",
      "Testing for epoch 3 index 21:\n",
      "\n",
      "Testing for epoch 3 index 22:\n",
      "\n",
      "Testing for epoch 3 index 23:\n",
      "\n",
      "Testing for epoch 3 index 24:\n",
      "\n",
      "Testing for epoch 3 index 25:\n",
      "\n",
      "Testing for epoch 3 index 26:\n",
      "\n",
      "Testing for epoch 3 index 27:\n",
      "\n",
      "Testing for epoch 3 index 28:\n",
      "\n",
      "Testing for epoch 3 index 29:\n",
      "\n",
      "Testing for epoch 3 index 30:\n",
      "\n",
      "Testing for epoch 3 index 31:\n",
      "\n",
      "Testing for epoch 3 index 32:\n",
      "\n",
      "Testing for epoch 3 index 33:\n",
      "\n",
      "Testing for epoch 3 index 34:\n",
      "\n",
      "Testing for epoch 3 index 35:\n",
      "\n",
      "Testing for epoch 3 index 36:\n",
      "\n",
      "Testing for epoch 3 index 37:\n",
      "\n",
      "Testing for epoch 3 index 38:\n",
      "\n",
      "Testing for epoch 3 index 39:\n",
      "\n",
      "Testing for epoch 3 index 40:\n",
      "\n",
      "Testing for epoch 3 index 41:\n",
      "\n",
      "Testing for epoch 3 index 42:\n",
      "\n",
      "Testing for epoch 3 index 43:\n",
      "\n",
      "Testing for epoch 3 index 44:\n",
      "Epoch 4 of 60\n",
      "\n",
      "Testing for epoch 4 index 1:\n",
      "\n",
      "Testing for epoch 4 index 2:\n",
      "\n",
      "Testing for epoch 4 index 3:\n",
      "\n",
      "Testing for epoch 4 index 4:\n",
      "\n",
      "Testing for epoch 4 index 5:\n",
      "\n",
      "Testing for epoch 4 index 6:\n",
      "\n",
      "Testing for epoch 4 index 7:\n",
      "\n",
      "Testing for epoch 4 index 8:\n",
      "\n",
      "Testing for epoch 4 index 9:\n",
      "\n",
      "Testing for epoch 4 index 10:\n",
      "\n",
      "Testing for epoch 4 index 11:\n",
      "\n",
      "Testing for epoch 4 index 12:\n",
      "\n",
      "Testing for epoch 4 index 13:\n",
      "\n",
      "Testing for epoch 4 index 14:\n",
      "\n",
      "Testing for epoch 4 index 15:\n",
      "\n",
      "Testing for epoch 4 index 16:\n",
      "\n",
      "Testing for epoch 4 index 17:\n",
      "\n",
      "Testing for epoch 4 index 18:\n",
      "\n",
      "Testing for epoch 4 index 19:\n",
      "\n",
      "Testing for epoch 4 index 20:\n",
      "\n",
      "Testing for epoch 4 index 21:\n",
      "\n",
      "Testing for epoch 4 index 22:\n",
      "\n",
      "Testing for epoch 4 index 23:\n",
      "\n",
      "Testing for epoch 4 index 24:\n",
      "\n",
      "Testing for epoch 4 index 25:\n",
      "\n",
      "Testing for epoch 4 index 26:\n",
      "\n",
      "Testing for epoch 4 index 27:\n",
      "\n",
      "Testing for epoch 4 index 28:\n",
      "\n",
      "Testing for epoch 4 index 29:\n",
      "\n",
      "Testing for epoch 4 index 30:\n",
      "\n",
      "Testing for epoch 4 index 31:\n",
      "\n",
      "Testing for epoch 4 index 32:\n",
      "\n",
      "Testing for epoch 4 index 33:\n",
      "\n",
      "Testing for epoch 4 index 34:\n",
      "\n",
      "Testing for epoch 4 index 35:\n",
      "\n",
      "Testing for epoch 4 index 36:\n",
      "\n",
      "Testing for epoch 4 index 37:\n",
      "\n",
      "Testing for epoch 4 index 38:\n",
      "\n",
      "Testing for epoch 4 index 39:\n",
      "\n",
      "Testing for epoch 4 index 40:\n",
      "\n",
      "Testing for epoch 4 index 41:\n",
      "\n",
      "Testing for epoch 4 index 42:\n",
      "\n",
      "Testing for epoch 4 index 43:\n",
      "\n",
      "Testing for epoch 4 index 44:\n",
      "Epoch 5 of 60\n",
      "\n",
      "Testing for epoch 5 index 1:\n",
      "\n",
      "Testing for epoch 5 index 2:\n",
      "\n",
      "Testing for epoch 5 index 3:\n",
      "\n",
      "Testing for epoch 5 index 4:\n",
      "\n",
      "Testing for epoch 5 index 5:\n",
      "\n",
      "Testing for epoch 5 index 6:\n",
      "\n",
      "Testing for epoch 5 index 7:\n",
      "\n",
      "Testing for epoch 5 index 8:\n",
      "\n",
      "Testing for epoch 5 index 9:\n",
      "\n",
      "Testing for epoch 5 index 10:\n",
      "\n",
      "Testing for epoch 5 index 11:\n",
      "\n",
      "Testing for epoch 5 index 12:\n",
      "\n",
      "Testing for epoch 5 index 13:\n",
      "\n",
      "Testing for epoch 5 index 14:\n",
      "\n",
      "Testing for epoch 5 index 15:\n",
      "\n",
      "Testing for epoch 5 index 16:\n",
      "\n",
      "Testing for epoch 5 index 17:\n",
      "\n",
      "Testing for epoch 5 index 18:\n",
      "\n",
      "Testing for epoch 5 index 19:\n",
      "\n",
      "Testing for epoch 5 index 20:\n",
      "\n",
      "Testing for epoch 5 index 21:\n",
      "\n",
      "Testing for epoch 5 index 22:\n",
      "\n",
      "Testing for epoch 5 index 23:\n",
      "\n",
      "Testing for epoch 5 index 24:\n",
      "\n",
      "Testing for epoch 5 index 25:\n",
      "\n",
      "Testing for epoch 5 index 26:\n",
      "\n",
      "Testing for epoch 5 index 27:\n",
      "\n",
      "Testing for epoch 5 index 28:\n",
      "\n",
      "Testing for epoch 5 index 29:\n",
      "\n",
      "Testing for epoch 5 index 30:\n",
      "\n",
      "Testing for epoch 5 index 31:\n",
      "\n",
      "Testing for epoch 5 index 32:\n",
      "\n",
      "Testing for epoch 5 index 33:\n",
      "\n",
      "Testing for epoch 5 index 34:\n",
      "\n",
      "Testing for epoch 5 index 35:\n",
      "\n",
      "Testing for epoch 5 index 36:\n",
      "\n",
      "Testing for epoch 5 index 37:\n",
      "\n",
      "Testing for epoch 5 index 38:\n",
      "\n",
      "Testing for epoch 5 index 39:\n",
      "\n",
      "Testing for epoch 5 index 40:\n",
      "\n",
      "Testing for epoch 5 index 41:\n",
      "\n",
      "Testing for epoch 5 index 42:\n",
      "\n",
      "Testing for epoch 5 index 43:\n",
      "\n",
      "Testing for epoch 5 index 44:\n",
      "Epoch 6 of 60\n",
      "\n",
      "Testing for epoch 6 index 1:\n",
      "\n",
      "Testing for epoch 6 index 2:\n",
      "\n",
      "Testing for epoch 6 index 3:\n",
      "\n",
      "Testing for epoch 6 index 4:\n",
      "\n",
      "Testing for epoch 6 index 5:\n",
      "\n",
      "Testing for epoch 6 index 6:\n",
      "\n",
      "Testing for epoch 6 index 7:\n",
      "\n",
      "Testing for epoch 6 index 8:\n",
      "\n",
      "Testing for epoch 6 index 9:\n",
      "\n",
      "Testing for epoch 6 index 10:\n",
      "\n",
      "Testing for epoch 6 index 11:\n",
      "\n",
      "Testing for epoch 6 index 12:\n",
      "\n",
      "Testing for epoch 6 index 13:\n",
      "\n",
      "Testing for epoch 6 index 14:\n",
      "\n",
      "Testing for epoch 6 index 15:\n",
      "\n",
      "Testing for epoch 6 index 16:\n",
      "\n",
      "Testing for epoch 6 index 17:\n",
      "\n",
      "Testing for epoch 6 index 18:\n",
      "\n",
      "Testing for epoch 6 index 19:\n",
      "\n",
      "Testing for epoch 6 index 20:\n",
      "\n",
      "Testing for epoch 6 index 21:\n",
      "\n",
      "Testing for epoch 6 index 22:\n",
      "\n",
      "Testing for epoch 6 index 23:\n",
      "\n",
      "Testing for epoch 6 index 24:\n",
      "\n",
      "Testing for epoch 6 index 25:\n",
      "\n",
      "Testing for epoch 6 index 26:\n",
      "\n",
      "Testing for epoch 6 index 27:\n",
      "\n",
      "Testing for epoch 6 index 28:\n",
      "\n",
      "Testing for epoch 6 index 29:\n",
      "\n",
      "Testing for epoch 6 index 30:\n",
      "\n",
      "Testing for epoch 6 index 31:\n",
      "\n",
      "Testing for epoch 6 index 32:\n",
      "\n",
      "Testing for epoch 6 index 33:\n",
      "\n",
      "Testing for epoch 6 index 34:\n",
      "\n",
      "Testing for epoch 6 index 35:\n",
      "\n",
      "Testing for epoch 6 index 36:\n",
      "\n",
      "Testing for epoch 6 index 37:\n",
      "\n",
      "Testing for epoch 6 index 38:\n",
      "\n",
      "Testing for epoch 6 index 39:\n",
      "\n",
      "Testing for epoch 6 index 40:\n",
      "\n",
      "Testing for epoch 6 index 41:\n",
      "\n",
      "Testing for epoch 6 index 42:\n",
      "\n",
      "Testing for epoch 6 index 43:\n",
      "\n",
      "Testing for epoch 6 index 44:\n",
      "Epoch 7 of 60\n",
      "\n",
      "Testing for epoch 7 index 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing for epoch 7 index 2:\n",
      "\n",
      "Testing for epoch 7 index 3:\n",
      "\n",
      "Testing for epoch 7 index 4:\n",
      "\n",
      "Testing for epoch 7 index 5:\n",
      "\n",
      "Testing for epoch 7 index 6:\n",
      "\n",
      "Testing for epoch 7 index 7:\n",
      "\n",
      "Testing for epoch 7 index 8:\n",
      "\n",
      "Testing for epoch 7 index 9:\n",
      "\n",
      "Testing for epoch 7 index 10:\n",
      "\n",
      "Testing for epoch 7 index 11:\n",
      "\n",
      "Testing for epoch 7 index 12:\n",
      "\n",
      "Testing for epoch 7 index 13:\n",
      "\n",
      "Testing for epoch 7 index 14:\n",
      "\n",
      "Testing for epoch 7 index 15:\n",
      "\n",
      "Testing for epoch 7 index 16:\n",
      "\n",
      "Testing for epoch 7 index 17:\n",
      "\n",
      "Testing for epoch 7 index 18:\n",
      "\n",
      "Testing for epoch 7 index 19:\n",
      "\n",
      "Testing for epoch 7 index 20:\n",
      "\n",
      "Testing for epoch 7 index 21:\n",
      "\n",
      "Testing for epoch 7 index 22:\n",
      "\n",
      "Testing for epoch 7 index 23:\n",
      "\n",
      "Testing for epoch 7 index 24:\n",
      "\n",
      "Testing for epoch 7 index 25:\n",
      "\n",
      "Testing for epoch 7 index 26:\n",
      "\n",
      "Testing for epoch 7 index 27:\n",
      "\n",
      "Testing for epoch 7 index 28:\n",
      "\n",
      "Testing for epoch 7 index 29:\n",
      "\n",
      "Testing for epoch 7 index 30:\n",
      "\n",
      "Testing for epoch 7 index 31:\n",
      "\n",
      "Testing for epoch 7 index 32:\n",
      "\n",
      "Testing for epoch 7 index 33:\n",
      "\n",
      "Testing for epoch 7 index 34:\n",
      "\n",
      "Testing for epoch 7 index 35:\n",
      "\n",
      "Testing for epoch 7 index 36:\n",
      "\n",
      "Testing for epoch 7 index 37:\n",
      "\n",
      "Testing for epoch 7 index 38:\n",
      "\n",
      "Testing for epoch 7 index 39:\n",
      "\n",
      "Testing for epoch 7 index 40:\n",
      "\n",
      "Testing for epoch 7 index 41:\n",
      "\n",
      "Testing for epoch 7 index 42:\n",
      "\n",
      "Testing for epoch 7 index 43:\n",
      "\n",
      "Testing for epoch 7 index 44:\n",
      "Epoch 8 of 60\n",
      "\n",
      "Testing for epoch 8 index 1:\n",
      "\n",
      "Testing for epoch 8 index 2:\n",
      "\n",
      "Testing for epoch 8 index 3:\n",
      "\n",
      "Testing for epoch 8 index 4:\n",
      "\n",
      "Testing for epoch 8 index 5:\n",
      "\n",
      "Testing for epoch 8 index 6:\n",
      "\n",
      "Testing for epoch 8 index 7:\n",
      "\n",
      "Testing for epoch 8 index 8:\n",
      "\n",
      "Testing for epoch 8 index 9:\n",
      "\n",
      "Testing for epoch 8 index 10:\n",
      "\n",
      "Testing for epoch 8 index 11:\n",
      "\n",
      "Testing for epoch 8 index 12:\n",
      "\n",
      "Testing for epoch 8 index 13:\n",
      "\n",
      "Testing for epoch 8 index 14:\n",
      "\n",
      "Testing for epoch 8 index 15:\n",
      "\n",
      "Testing for epoch 8 index 16:\n",
      "\n",
      "Testing for epoch 8 index 17:\n",
      "\n",
      "Testing for epoch 8 index 18:\n",
      "\n",
      "Testing for epoch 8 index 19:\n",
      "\n",
      "Testing for epoch 8 index 20:\n",
      "\n",
      "Testing for epoch 8 index 21:\n",
      "\n",
      "Testing for epoch 8 index 22:\n",
      "\n",
      "Testing for epoch 8 index 23:\n",
      "\n",
      "Testing for epoch 8 index 24:\n",
      "\n",
      "Testing for epoch 8 index 25:\n",
      "\n",
      "Testing for epoch 8 index 26:\n",
      "\n",
      "Testing for epoch 8 index 27:\n",
      "\n",
      "Testing for epoch 8 index 28:\n",
      "\n",
      "Testing for epoch 8 index 29:\n",
      "\n",
      "Testing for epoch 8 index 30:\n",
      "\n",
      "Testing for epoch 8 index 31:\n",
      "\n",
      "Testing for epoch 8 index 32:\n",
      "\n",
      "Testing for epoch 8 index 33:\n",
      "\n",
      "Testing for epoch 8 index 34:\n",
      "\n",
      "Testing for epoch 8 index 35:\n",
      "\n",
      "Testing for epoch 8 index 36:\n",
      "\n",
      "Testing for epoch 8 index 37:\n",
      "\n",
      "Testing for epoch 8 index 38:\n",
      "\n",
      "Testing for epoch 8 index 39:\n",
      "\n",
      "Testing for epoch 8 index 40:\n",
      "\n",
      "Testing for epoch 8 index 41:\n",
      "\n",
      "Testing for epoch 8 index 42:\n",
      "\n",
      "Testing for epoch 8 index 43:\n",
      "\n",
      "Testing for epoch 8 index 44:\n",
      "Epoch 9 of 60\n",
      "\n",
      "Testing for epoch 9 index 1:\n",
      "\n",
      "Testing for epoch 9 index 2:\n",
      "\n",
      "Testing for epoch 9 index 3:\n",
      "\n",
      "Testing for epoch 9 index 4:\n",
      "\n",
      "Testing for epoch 9 index 5:\n",
      "\n",
      "Testing for epoch 9 index 6:\n",
      "\n",
      "Testing for epoch 9 index 7:\n",
      "\n",
      "Testing for epoch 9 index 8:\n",
      "\n",
      "Testing for epoch 9 index 9:\n",
      "\n",
      "Testing for epoch 9 index 10:\n",
      "\n",
      "Testing for epoch 9 index 11:\n",
      "\n",
      "Testing for epoch 9 index 12:\n",
      "\n",
      "Testing for epoch 9 index 13:\n",
      "\n",
      "Testing for epoch 9 index 14:\n",
      "\n",
      "Testing for epoch 9 index 15:\n",
      "\n",
      "Testing for epoch 9 index 16:\n",
      "\n",
      "Testing for epoch 9 index 17:\n",
      "\n",
      "Testing for epoch 9 index 18:\n",
      "\n",
      "Testing for epoch 9 index 19:\n",
      "\n",
      "Testing for epoch 9 index 20:\n",
      "\n",
      "Testing for epoch 9 index 21:\n",
      "\n",
      "Testing for epoch 9 index 22:\n",
      "\n",
      "Testing for epoch 9 index 23:\n",
      "\n",
      "Testing for epoch 9 index 24:\n",
      "\n",
      "Testing for epoch 9 index 25:\n",
      "\n",
      "Testing for epoch 9 index 26:\n",
      "\n",
      "Testing for epoch 9 index 27:\n",
      "\n",
      "Testing for epoch 9 index 28:\n",
      "\n",
      "Testing for epoch 9 index 29:\n",
      "\n",
      "Testing for epoch 9 index 30:\n",
      "\n",
      "Testing for epoch 9 index 31:\n",
      "\n",
      "Testing for epoch 9 index 32:\n",
      "\n",
      "Testing for epoch 9 index 33:\n",
      "\n",
      "Testing for epoch 9 index 34:\n",
      "\n",
      "Testing for epoch 9 index 35:\n",
      "\n",
      "Testing for epoch 9 index 36:\n",
      "\n",
      "Testing for epoch 9 index 37:\n",
      "\n",
      "Testing for epoch 9 index 38:\n",
      "\n",
      "Testing for epoch 9 index 39:\n",
      "\n",
      "Testing for epoch 9 index 40:\n",
      "\n",
      "Testing for epoch 9 index 41:\n",
      "\n",
      "Testing for epoch 9 index 42:\n",
      "\n",
      "Testing for epoch 9 index 43:\n",
      "\n",
      "Testing for epoch 9 index 44:\n",
      "Epoch 10 of 60\n",
      "\n",
      "Testing for epoch 10 index 1:\n",
      "\n",
      "Testing for epoch 10 index 2:\n",
      "\n",
      "Testing for epoch 10 index 3:\n",
      "\n",
      "Testing for epoch 10 index 4:\n",
      "\n",
      "Testing for epoch 10 index 5:\n",
      "\n",
      "Testing for epoch 10 index 6:\n",
      "\n",
      "Testing for epoch 10 index 7:\n",
      "\n",
      "Testing for epoch 10 index 8:\n",
      "\n",
      "Testing for epoch 10 index 9:\n",
      "\n",
      "Testing for epoch 10 index 10:\n",
      "\n",
      "Testing for epoch 10 index 11:\n",
      "\n",
      "Testing for epoch 10 index 12:\n",
      "\n",
      "Testing for epoch 10 index 13:\n",
      "\n",
      "Testing for epoch 10 index 14:\n",
      "\n",
      "Testing for epoch 10 index 15:\n",
      "\n",
      "Testing for epoch 10 index 16:\n",
      "\n",
      "Testing for epoch 10 index 17:\n",
      "\n",
      "Testing for epoch 10 index 18:\n",
      "\n",
      "Testing for epoch 10 index 19:\n",
      "\n",
      "Testing for epoch 10 index 20:\n",
      "\n",
      "Testing for epoch 10 index 21:\n",
      "\n",
      "Testing for epoch 10 index 22:\n",
      "\n",
      "Testing for epoch 10 index 23:\n",
      "\n",
      "Testing for epoch 10 index 24:\n",
      "\n",
      "Testing for epoch 10 index 25:\n",
      "\n",
      "Testing for epoch 10 index 26:\n",
      "\n",
      "Testing for epoch 10 index 27:\n",
      "\n",
      "Testing for epoch 10 index 28:\n",
      "\n",
      "Testing for epoch 10 index 29:\n",
      "\n",
      "Testing for epoch 10 index 30:\n",
      "\n",
      "Testing for epoch 10 index 31:\n",
      "\n",
      "Testing for epoch 10 index 32:\n",
      "\n",
      "Testing for epoch 10 index 33:\n",
      "\n",
      "Testing for epoch 10 index 34:\n",
      "\n",
      "Testing for epoch 10 index 35:\n",
      "\n",
      "Testing for epoch 10 index 36:\n",
      "\n",
      "Testing for epoch 10 index 37:\n",
      "\n",
      "Testing for epoch 10 index 38:\n",
      "\n",
      "Testing for epoch 10 index 39:\n",
      "\n",
      "Testing for epoch 10 index 40:\n",
      "\n",
      "Testing for epoch 10 index 41:\n",
      "\n",
      "Testing for epoch 10 index 42:\n",
      "\n",
      "Testing for epoch 10 index 43:\n",
      "\n",
      "Testing for epoch 10 index 44:\n",
      "Epoch 11 of 60\n",
      "\n",
      "Testing for epoch 11 index 1:\n",
      "\n",
      "Testing for epoch 11 index 2:\n",
      "\n",
      "Testing for epoch 11 index 3:\n",
      "\n",
      "Testing for epoch 11 index 4:\n",
      "\n",
      "Testing for epoch 11 index 5:\n",
      "\n",
      "Testing for epoch 11 index 6:\n",
      "\n",
      "Testing for epoch 11 index 7:\n",
      "\n",
      "Testing for epoch 11 index 8:\n",
      "\n",
      "Testing for epoch 11 index 9:\n",
      "\n",
      "Testing for epoch 11 index 10:\n",
      "\n",
      "Testing for epoch 11 index 11:\n",
      "\n",
      "Testing for epoch 11 index 12:\n",
      "\n",
      "Testing for epoch 11 index 13:\n",
      "\n",
      "Testing for epoch 11 index 14:\n",
      "\n",
      "Testing for epoch 11 index 15:\n",
      "\n",
      "Testing for epoch 11 index 16:\n",
      "\n",
      "Testing for epoch 11 index 17:\n",
      "\n",
      "Testing for epoch 11 index 18:\n",
      "\n",
      "Testing for epoch 11 index 19:\n",
      "\n",
      "Testing for epoch 11 index 20:\n",
      "\n",
      "Testing for epoch 11 index 21:\n",
      "\n",
      "Testing for epoch 11 index 22:\n",
      "\n",
      "Testing for epoch 11 index 23:\n",
      "\n",
      "Testing for epoch 11 index 24:\n",
      "\n",
      "Testing for epoch 11 index 25:\n",
      "\n",
      "Testing for epoch 11 index 26:\n",
      "\n",
      "Testing for epoch 11 index 27:\n",
      "\n",
      "Testing for epoch 11 index 28:\n",
      "\n",
      "Testing for epoch 11 index 29:\n",
      "\n",
      "Testing for epoch 11 index 30:\n",
      "\n",
      "Testing for epoch 11 index 31:\n",
      "\n",
      "Testing for epoch 11 index 32:\n",
      "\n",
      "Testing for epoch 11 index 33:\n",
      "\n",
      "Testing for epoch 11 index 34:\n",
      "\n",
      "Testing for epoch 11 index 35:\n",
      "\n",
      "Testing for epoch 11 index 36:\n",
      "\n",
      "Testing for epoch 11 index 37:\n",
      "\n",
      "Testing for epoch 11 index 38:\n",
      "\n",
      "Testing for epoch 11 index 39:\n",
      "\n",
      "Testing for epoch 11 index 40:\n",
      "\n",
      "Testing for epoch 11 index 41:\n",
      "\n",
      "Testing for epoch 11 index 42:\n",
      "\n",
      "Testing for epoch 11 index 43:\n",
      "\n",
      "Testing for epoch 11 index 44:\n",
      "Epoch 12 of 60\n",
      "\n",
      "Testing for epoch 12 index 1:\n",
      "\n",
      "Testing for epoch 12 index 2:\n",
      "\n",
      "Testing for epoch 12 index 3:\n",
      "\n",
      "Testing for epoch 12 index 4:\n",
      "\n",
      "Testing for epoch 12 index 5:\n",
      "\n",
      "Testing for epoch 12 index 6:\n",
      "\n",
      "Testing for epoch 12 index 7:\n",
      "\n",
      "Testing for epoch 12 index 8:\n",
      "\n",
      "Testing for epoch 12 index 9:\n",
      "\n",
      "Testing for epoch 12 index 10:\n",
      "\n",
      "Testing for epoch 12 index 11:\n",
      "\n",
      "Testing for epoch 12 index 12:\n",
      "\n",
      "Testing for epoch 12 index 13:\n",
      "\n",
      "Testing for epoch 12 index 14:\n",
      "\n",
      "Testing for epoch 12 index 15:\n",
      "\n",
      "Testing for epoch 12 index 16:\n",
      "\n",
      "Testing for epoch 12 index 17:\n",
      "\n",
      "Testing for epoch 12 index 18:\n",
      "\n",
      "Testing for epoch 12 index 19:\n",
      "\n",
      "Testing for epoch 12 index 20:\n",
      "\n",
      "Testing for epoch 12 index 21:\n",
      "\n",
      "Testing for epoch 12 index 22:\n",
      "\n",
      "Testing for epoch 12 index 23:\n",
      "\n",
      "Testing for epoch 12 index 24:\n",
      "\n",
      "Testing for epoch 12 index 25:\n",
      "\n",
      "Testing for epoch 12 index 26:\n",
      "\n",
      "Testing for epoch 12 index 27:\n",
      "\n",
      "Testing for epoch 12 index 28:\n",
      "\n",
      "Testing for epoch 12 index 29:\n",
      "\n",
      "Testing for epoch 12 index 30:\n",
      "\n",
      "Testing for epoch 12 index 31:\n",
      "\n",
      "Testing for epoch 12 index 32:\n",
      "\n",
      "Testing for epoch 12 index 33:\n",
      "\n",
      "Testing for epoch 12 index 34:\n",
      "\n",
      "Testing for epoch 12 index 35:\n",
      "\n",
      "Testing for epoch 12 index 36:\n",
      "\n",
      "Testing for epoch 12 index 37:\n",
      "\n",
      "Testing for epoch 12 index 38:\n",
      "\n",
      "Testing for epoch 12 index 39:\n",
      "\n",
      "Testing for epoch 12 index 40:\n",
      "\n",
      "Testing for epoch 12 index 41:\n",
      "\n",
      "Testing for epoch 12 index 42:\n",
      "\n",
      "Testing for epoch 12 index 43:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing for epoch 12 index 44:\n",
      "Epoch 13 of 60\n",
      "\n",
      "Testing for epoch 13 index 1:\n",
      "\n",
      "Testing for epoch 13 index 2:\n",
      "\n",
      "Testing for epoch 13 index 3:\n",
      "\n",
      "Testing for epoch 13 index 4:\n",
      "\n",
      "Testing for epoch 13 index 5:\n",
      "\n",
      "Testing for epoch 13 index 6:\n",
      "\n",
      "Testing for epoch 13 index 7:\n",
      "\n",
      "Testing for epoch 13 index 8:\n",
      "\n",
      "Testing for epoch 13 index 9:\n",
      "\n",
      "Testing for epoch 13 index 10:\n",
      "\n",
      "Testing for epoch 13 index 11:\n",
      "\n",
      "Testing for epoch 13 index 12:\n",
      "\n",
      "Testing for epoch 13 index 13:\n",
      "\n",
      "Testing for epoch 13 index 14:\n",
      "\n",
      "Testing for epoch 13 index 15:\n",
      "\n",
      "Testing for epoch 13 index 16:\n",
      "\n",
      "Testing for epoch 13 index 17:\n",
      "\n",
      "Testing for epoch 13 index 18:\n",
      "\n",
      "Testing for epoch 13 index 19:\n",
      "\n",
      "Testing for epoch 13 index 20:\n",
      "\n",
      "Testing for epoch 13 index 21:\n",
      "\n",
      "Testing for epoch 13 index 22:\n",
      "\n",
      "Testing for epoch 13 index 23:\n",
      "\n",
      "Testing for epoch 13 index 24:\n",
      "\n",
      "Testing for epoch 13 index 25:\n",
      "\n",
      "Testing for epoch 13 index 26:\n",
      "\n",
      "Testing for epoch 13 index 27:\n",
      "\n",
      "Testing for epoch 13 index 28:\n",
      "\n",
      "Testing for epoch 13 index 29:\n",
      "\n",
      "Testing for epoch 13 index 30:\n",
      "\n",
      "Testing for epoch 13 index 31:\n",
      "\n",
      "Testing for epoch 13 index 32:\n",
      "\n",
      "Testing for epoch 13 index 33:\n",
      "\n",
      "Testing for epoch 13 index 34:\n",
      "\n",
      "Testing for epoch 13 index 35:\n",
      "\n",
      "Testing for epoch 13 index 36:\n",
      "\n",
      "Testing for epoch 13 index 37:\n",
      "\n",
      "Testing for epoch 13 index 38:\n",
      "\n",
      "Testing for epoch 13 index 39:\n",
      "\n",
      "Testing for epoch 13 index 40:\n",
      "\n",
      "Testing for epoch 13 index 41:\n",
      "\n",
      "Testing for epoch 13 index 42:\n",
      "\n",
      "Testing for epoch 13 index 43:\n",
      "\n",
      "Testing for epoch 13 index 44:\n",
      "Epoch 14 of 60\n",
      "\n",
      "Testing for epoch 14 index 1:\n",
      "\n",
      "Testing for epoch 14 index 2:\n",
      "\n",
      "Testing for epoch 14 index 3:\n",
      "\n",
      "Testing for epoch 14 index 4:\n",
      "\n",
      "Testing for epoch 14 index 5:\n",
      "\n",
      "Testing for epoch 14 index 6:\n",
      "\n",
      "Testing for epoch 14 index 7:\n",
      "\n",
      "Testing for epoch 14 index 8:\n",
      "\n",
      "Testing for epoch 14 index 9:\n",
      "\n",
      "Testing for epoch 14 index 10:\n",
      "\n",
      "Testing for epoch 14 index 11:\n",
      "\n",
      "Testing for epoch 14 index 12:\n",
      "\n",
      "Testing for epoch 14 index 13:\n",
      "\n",
      "Testing for epoch 14 index 14:\n",
      "\n",
      "Testing for epoch 14 index 15:\n",
      "\n",
      "Testing for epoch 14 index 16:\n",
      "\n",
      "Testing for epoch 14 index 17:\n",
      "\n",
      "Testing for epoch 14 index 18:\n",
      "\n",
      "Testing for epoch 14 index 19:\n",
      "\n",
      "Testing for epoch 14 index 20:\n",
      "\n",
      "Testing for epoch 14 index 21:\n",
      "\n",
      "Testing for epoch 14 index 22:\n",
      "\n",
      "Testing for epoch 14 index 23:\n",
      "\n",
      "Testing for epoch 14 index 24:\n",
      "\n",
      "Testing for epoch 14 index 25:\n",
      "\n",
      "Testing for epoch 14 index 26:\n",
      "\n",
      "Testing for epoch 14 index 27:\n",
      "\n",
      "Testing for epoch 14 index 28:\n",
      "\n",
      "Testing for epoch 14 index 29:\n",
      "\n",
      "Testing for epoch 14 index 30:\n",
      "\n",
      "Testing for epoch 14 index 31:\n",
      "\n",
      "Testing for epoch 14 index 32:\n",
      "\n",
      "Testing for epoch 14 index 33:\n",
      "\n",
      "Testing for epoch 14 index 34:\n",
      "\n",
      "Testing for epoch 14 index 35:\n",
      "\n",
      "Testing for epoch 14 index 36:\n",
      "\n",
      "Testing for epoch 14 index 37:\n",
      "\n",
      "Testing for epoch 14 index 38:\n",
      "\n",
      "Testing for epoch 14 index 39:\n",
      "\n",
      "Testing for epoch 14 index 40:\n",
      "\n",
      "Testing for epoch 14 index 41:\n",
      "\n",
      "Testing for epoch 14 index 42:\n",
      "\n",
      "Testing for epoch 14 index 43:\n",
      "\n",
      "Testing for epoch 14 index 44:\n",
      "Epoch 15 of 60\n",
      "\n",
      "Testing for epoch 15 index 1:\n",
      "\n",
      "Testing for epoch 15 index 2:\n",
      "\n",
      "Testing for epoch 15 index 3:\n",
      "\n",
      "Testing for epoch 15 index 4:\n",
      "\n",
      "Testing for epoch 15 index 5:\n",
      "\n",
      "Testing for epoch 15 index 6:\n",
      "\n",
      "Testing for epoch 15 index 7:\n",
      "\n",
      "Testing for epoch 15 index 8:\n",
      "\n",
      "Testing for epoch 15 index 9:\n",
      "\n",
      "Testing for epoch 15 index 10:\n",
      "\n",
      "Testing for epoch 15 index 11:\n",
      "\n",
      "Testing for epoch 15 index 12:\n",
      "\n",
      "Testing for epoch 15 index 13:\n",
      "\n",
      "Testing for epoch 15 index 14:\n",
      "\n",
      "Testing for epoch 15 index 15:\n",
      "\n",
      "Testing for epoch 15 index 16:\n",
      "\n",
      "Testing for epoch 15 index 17:\n",
      "\n",
      "Testing for epoch 15 index 18:\n",
      "\n",
      "Testing for epoch 15 index 19:\n",
      "\n",
      "Testing for epoch 15 index 20:\n",
      "\n",
      "Testing for epoch 15 index 21:\n",
      "\n",
      "Testing for epoch 15 index 22:\n",
      "\n",
      "Testing for epoch 15 index 23:\n",
      "\n",
      "Testing for epoch 15 index 24:\n",
      "\n",
      "Testing for epoch 15 index 25:\n",
      "\n",
      "Testing for epoch 15 index 26:\n",
      "\n",
      "Testing for epoch 15 index 27:\n",
      "\n",
      "Testing for epoch 15 index 28:\n",
      "\n",
      "Testing for epoch 15 index 29:\n",
      "\n",
      "Testing for epoch 15 index 30:\n",
      "\n",
      "Testing for epoch 15 index 31:\n",
      "\n",
      "Testing for epoch 15 index 32:\n",
      "\n",
      "Testing for epoch 15 index 33:\n",
      "\n",
      "Testing for epoch 15 index 34:\n",
      "\n",
      "Testing for epoch 15 index 35:\n",
      "\n",
      "Testing for epoch 15 index 36:\n",
      "\n",
      "Testing for epoch 15 index 37:\n",
      "\n",
      "Testing for epoch 15 index 38:\n",
      "\n",
      "Testing for epoch 15 index 39:\n",
      "\n",
      "Testing for epoch 15 index 40:\n",
      "\n",
      "Testing for epoch 15 index 41:\n",
      "\n",
      "Testing for epoch 15 index 42:\n",
      "\n",
      "Testing for epoch 15 index 43:\n",
      "\n",
      "Testing for epoch 15 index 44:\n",
      "Epoch 16 of 60\n",
      "\n",
      "Testing for epoch 16 index 1:\n",
      "\n",
      "Testing for epoch 16 index 2:\n",
      "\n",
      "Testing for epoch 16 index 3:\n",
      "\n",
      "Testing for epoch 16 index 4:\n",
      "\n",
      "Testing for epoch 16 index 5:\n",
      "\n",
      "Testing for epoch 16 index 6:\n",
      "\n",
      "Testing for epoch 16 index 7:\n",
      "\n",
      "Testing for epoch 16 index 8:\n",
      "\n",
      "Testing for epoch 16 index 9:\n",
      "\n",
      "Testing for epoch 16 index 10:\n",
      "\n",
      "Testing for epoch 16 index 11:\n",
      "\n",
      "Testing for epoch 16 index 12:\n",
      "\n",
      "Testing for epoch 16 index 13:\n",
      "\n",
      "Testing for epoch 16 index 14:\n",
      "\n",
      "Testing for epoch 16 index 15:\n",
      "\n",
      "Testing for epoch 16 index 16:\n",
      "\n",
      "Testing for epoch 16 index 17:\n",
      "\n",
      "Testing for epoch 16 index 18:\n",
      "\n",
      "Testing for epoch 16 index 19:\n",
      "\n",
      "Testing for epoch 16 index 20:\n",
      "\n",
      "Testing for epoch 16 index 21:\n",
      "\n",
      "Testing for epoch 16 index 22:\n",
      "\n",
      "Testing for epoch 16 index 23:\n",
      "\n",
      "Testing for epoch 16 index 24:\n",
      "\n",
      "Testing for epoch 16 index 25:\n",
      "\n",
      "Testing for epoch 16 index 26:\n",
      "\n",
      "Testing for epoch 16 index 27:\n",
      "\n",
      "Testing for epoch 16 index 28:\n",
      "\n",
      "Testing for epoch 16 index 29:\n",
      "\n",
      "Testing for epoch 16 index 30:\n",
      "\n",
      "Testing for epoch 16 index 31:\n",
      "\n",
      "Testing for epoch 16 index 32:\n",
      "\n",
      "Testing for epoch 16 index 33:\n",
      "\n",
      "Testing for epoch 16 index 34:\n",
      "\n",
      "Testing for epoch 16 index 35:\n",
      "\n",
      "Testing for epoch 16 index 36:\n",
      "\n",
      "Testing for epoch 16 index 37:\n",
      "\n",
      "Testing for epoch 16 index 38:\n",
      "\n",
      "Testing for epoch 16 index 39:\n",
      "\n",
      "Testing for epoch 16 index 40:\n",
      "\n",
      "Testing for epoch 16 index 41:\n",
      "\n",
      "Testing for epoch 16 index 42:\n",
      "\n",
      "Testing for epoch 16 index 43:\n",
      "\n",
      "Testing for epoch 16 index 44:\n",
      "Epoch 17 of 60\n",
      "\n",
      "Testing for epoch 17 index 1:\n",
      "\n",
      "Testing for epoch 17 index 2:\n",
      "\n",
      "Testing for epoch 17 index 3:\n",
      "\n",
      "Testing for epoch 17 index 4:\n",
      "\n",
      "Testing for epoch 17 index 5:\n",
      "\n",
      "Testing for epoch 17 index 6:\n",
      "\n",
      "Testing for epoch 17 index 7:\n",
      "\n",
      "Testing for epoch 17 index 8:\n",
      "\n",
      "Testing for epoch 17 index 9:\n",
      "\n",
      "Testing for epoch 17 index 10:\n",
      "\n",
      "Testing for epoch 17 index 11:\n",
      "\n",
      "Testing for epoch 17 index 12:\n",
      "\n",
      "Testing for epoch 17 index 13:\n",
      "\n",
      "Testing for epoch 17 index 14:\n",
      "\n",
      "Testing for epoch 17 index 15:\n",
      "\n",
      "Testing for epoch 17 index 16:\n",
      "\n",
      "Testing for epoch 17 index 17:\n",
      "\n",
      "Testing for epoch 17 index 18:\n",
      "\n",
      "Testing for epoch 17 index 19:\n",
      "\n",
      "Testing for epoch 17 index 20:\n",
      "\n",
      "Testing for epoch 17 index 21:\n",
      "\n",
      "Testing for epoch 17 index 22:\n",
      "\n",
      "Testing for epoch 17 index 23:\n",
      "\n",
      "Testing for epoch 17 index 24:\n",
      "\n",
      "Testing for epoch 17 index 25:\n",
      "\n",
      "Testing for epoch 17 index 26:\n",
      "\n",
      "Testing for epoch 17 index 27:\n",
      "\n",
      "Testing for epoch 17 index 28:\n",
      "\n",
      "Testing for epoch 17 index 29:\n",
      "\n",
      "Testing for epoch 17 index 30:\n",
      "\n",
      "Testing for epoch 17 index 31:\n",
      "\n",
      "Testing for epoch 17 index 32:\n",
      "\n",
      "Testing for epoch 17 index 33:\n",
      "\n",
      "Testing for epoch 17 index 34:\n",
      "\n",
      "Testing for epoch 17 index 35:\n",
      "\n",
      "Testing for epoch 17 index 36:\n",
      "\n",
      "Testing for epoch 17 index 37:\n",
      "\n",
      "Testing for epoch 17 index 38:\n",
      "\n",
      "Testing for epoch 17 index 39:\n",
      "\n",
      "Testing for epoch 17 index 40:\n",
      "\n",
      "Testing for epoch 17 index 41:\n",
      "\n",
      "Testing for epoch 17 index 42:\n",
      "\n",
      "Testing for epoch 17 index 43:\n",
      "\n",
      "Testing for epoch 17 index 44:\n",
      "Epoch 18 of 60\n",
      "\n",
      "Testing for epoch 18 index 1:\n",
      "\n",
      "Testing for epoch 18 index 2:\n",
      "\n",
      "Testing for epoch 18 index 3:\n",
      "\n",
      "Testing for epoch 18 index 4:\n",
      "\n",
      "Testing for epoch 18 index 5:\n",
      "\n",
      "Testing for epoch 18 index 6:\n",
      "\n",
      "Testing for epoch 18 index 7:\n",
      "\n",
      "Testing for epoch 18 index 8:\n",
      "\n",
      "Testing for epoch 18 index 9:\n",
      "\n",
      "Testing for epoch 18 index 10:\n",
      "\n",
      "Testing for epoch 18 index 11:\n",
      "\n",
      "Testing for epoch 18 index 12:\n",
      "\n",
      "Testing for epoch 18 index 13:\n",
      "\n",
      "Testing for epoch 18 index 14:\n",
      "\n",
      "Testing for epoch 18 index 15:\n",
      "\n",
      "Testing for epoch 18 index 16:\n",
      "\n",
      "Testing for epoch 18 index 17:\n",
      "\n",
      "Testing for epoch 18 index 18:\n",
      "\n",
      "Testing for epoch 18 index 19:\n",
      "\n",
      "Testing for epoch 18 index 20:\n",
      "\n",
      "Testing for epoch 18 index 21:\n",
      "\n",
      "Testing for epoch 18 index 22:\n",
      "\n",
      "Testing for epoch 18 index 23:\n",
      "\n",
      "Testing for epoch 18 index 24:\n",
      "\n",
      "Testing for epoch 18 index 25:\n",
      "\n",
      "Testing for epoch 18 index 26:\n",
      "\n",
      "Testing for epoch 18 index 27:\n",
      "\n",
      "Testing for epoch 18 index 28:\n",
      "\n",
      "Testing for epoch 18 index 29:\n",
      "\n",
      "Testing for epoch 18 index 30:\n",
      "\n",
      "Testing for epoch 18 index 31:\n",
      "\n",
      "Testing for epoch 18 index 32:\n",
      "\n",
      "Testing for epoch 18 index 33:\n",
      "\n",
      "Testing for epoch 18 index 34:\n",
      "\n",
      "Testing for epoch 18 index 35:\n",
      "\n",
      "Testing for epoch 18 index 36:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing for epoch 18 index 37:\n",
      "\n",
      "Testing for epoch 18 index 38:\n",
      "\n",
      "Testing for epoch 18 index 39:\n",
      "\n",
      "Testing for epoch 18 index 40:\n",
      "\n",
      "Testing for epoch 18 index 41:\n",
      "\n",
      "Testing for epoch 18 index 42:\n",
      "\n",
      "Testing for epoch 18 index 43:\n",
      "\n",
      "Testing for epoch 18 index 44:\n",
      "Epoch 19 of 60\n",
      "\n",
      "Testing for epoch 19 index 1:\n",
      "\n",
      "Testing for epoch 19 index 2:\n",
      "\n",
      "Testing for epoch 19 index 3:\n",
      "\n",
      "Testing for epoch 19 index 4:\n",
      "\n",
      "Testing for epoch 19 index 5:\n",
      "\n",
      "Testing for epoch 19 index 6:\n",
      "\n",
      "Testing for epoch 19 index 7:\n",
      "\n",
      "Testing for epoch 19 index 8:\n",
      "\n",
      "Testing for epoch 19 index 9:\n",
      "\n",
      "Testing for epoch 19 index 10:\n",
      "\n",
      "Testing for epoch 19 index 11:\n",
      "\n",
      "Testing for epoch 19 index 12:\n",
      "\n",
      "Testing for epoch 19 index 13:\n",
      "\n",
      "Testing for epoch 19 index 14:\n",
      "\n",
      "Testing for epoch 19 index 15:\n",
      "\n",
      "Testing for epoch 19 index 16:\n",
      "\n",
      "Testing for epoch 19 index 17:\n",
      "\n",
      "Testing for epoch 19 index 18:\n",
      "\n",
      "Testing for epoch 19 index 19:\n",
      "\n",
      "Testing for epoch 19 index 20:\n",
      "\n",
      "Testing for epoch 19 index 21:\n",
      "\n",
      "Testing for epoch 19 index 22:\n",
      "\n",
      "Testing for epoch 19 index 23:\n",
      "\n",
      "Testing for epoch 19 index 24:\n",
      "\n",
      "Testing for epoch 19 index 25:\n",
      "\n",
      "Testing for epoch 19 index 26:\n",
      "\n",
      "Testing for epoch 19 index 27:\n",
      "\n",
      "Testing for epoch 19 index 28:\n",
      "\n",
      "Testing for epoch 19 index 29:\n",
      "\n",
      "Testing for epoch 19 index 30:\n",
      "\n",
      "Testing for epoch 19 index 31:\n",
      "\n",
      "Testing for epoch 19 index 32:\n",
      "\n",
      "Testing for epoch 19 index 33:\n",
      "\n",
      "Testing for epoch 19 index 34:\n",
      "\n",
      "Testing for epoch 19 index 35:\n",
      "\n",
      "Testing for epoch 19 index 36:\n",
      "\n",
      "Testing for epoch 19 index 37:\n",
      "\n",
      "Testing for epoch 19 index 38:\n",
      "\n",
      "Testing for epoch 19 index 39:\n",
      "\n",
      "Testing for epoch 19 index 40:\n",
      "\n",
      "Testing for epoch 19 index 41:\n",
      "\n",
      "Testing for epoch 19 index 42:\n",
      "\n",
      "Testing for epoch 19 index 43:\n",
      "\n",
      "Testing for epoch 19 index 44:\n",
      "Epoch 20 of 60\n",
      "\n",
      "Testing for epoch 20 index 1:\n",
      "\n",
      "Testing for epoch 20 index 2:\n",
      "\n",
      "Testing for epoch 20 index 3:\n",
      "\n",
      "Testing for epoch 20 index 4:\n",
      "\n",
      "Testing for epoch 20 index 5:\n",
      "\n",
      "Testing for epoch 20 index 6:\n",
      "\n",
      "Testing for epoch 20 index 7:\n",
      "\n",
      "Testing for epoch 20 index 8:\n",
      "\n",
      "Testing for epoch 20 index 9:\n",
      "\n",
      "Testing for epoch 20 index 10:\n",
      "\n",
      "Testing for epoch 20 index 11:\n",
      "\n",
      "Testing for epoch 20 index 12:\n",
      "\n",
      "Testing for epoch 20 index 13:\n",
      "\n",
      "Testing for epoch 20 index 14:\n",
      "\n",
      "Testing for epoch 20 index 15:\n",
      "\n",
      "Testing for epoch 20 index 16:\n",
      "\n",
      "Testing for epoch 20 index 17:\n",
      "\n",
      "Testing for epoch 20 index 18:\n",
      "\n",
      "Testing for epoch 20 index 19:\n",
      "\n",
      "Testing for epoch 20 index 20:\n",
      "\n",
      "Testing for epoch 20 index 21:\n",
      "\n",
      "Testing for epoch 20 index 22:\n",
      "\n",
      "Testing for epoch 20 index 23:\n",
      "\n",
      "Testing for epoch 20 index 24:\n",
      "\n",
      "Testing for epoch 20 index 25:\n",
      "\n",
      "Testing for epoch 20 index 26:\n",
      "\n",
      "Testing for epoch 20 index 27:\n",
      "\n",
      "Testing for epoch 20 index 28:\n",
      "\n",
      "Testing for epoch 20 index 29:\n",
      "\n",
      "Testing for epoch 20 index 30:\n",
      "\n",
      "Testing for epoch 20 index 31:\n",
      "\n",
      "Testing for epoch 20 index 32:\n",
      "\n",
      "Testing for epoch 20 index 33:\n",
      "\n",
      "Testing for epoch 20 index 34:\n",
      "\n",
      "Testing for epoch 20 index 35:\n",
      "\n",
      "Testing for epoch 20 index 36:\n",
      "\n",
      "Testing for epoch 20 index 37:\n",
      "\n",
      "Testing for epoch 20 index 38:\n",
      "\n",
      "Testing for epoch 20 index 39:\n",
      "\n",
      "Testing for epoch 20 index 40:\n",
      "\n",
      "Testing for epoch 20 index 41:\n",
      "\n",
      "Testing for epoch 20 index 42:\n",
      "\n",
      "Testing for epoch 20 index 43:\n",
      "\n",
      "Testing for epoch 20 index 44:\n",
      "Epoch 21 of 60\n",
      "\n",
      "Testing for epoch 21 index 1:\n",
      "\n",
      "Testing for epoch 21 index 2:\n",
      "\n",
      "Testing for epoch 21 index 3:\n",
      "\n",
      "Testing for epoch 21 index 4:\n",
      "\n",
      "Testing for epoch 21 index 5:\n",
      "\n",
      "Testing for epoch 21 index 6:\n",
      "\n",
      "Testing for epoch 21 index 7:\n",
      "\n",
      "Testing for epoch 21 index 8:\n",
      "\n",
      "Testing for epoch 21 index 9:\n",
      "\n",
      "Testing for epoch 21 index 10:\n",
      "\n",
      "Testing for epoch 21 index 11:\n",
      "\n",
      "Testing for epoch 21 index 12:\n",
      "\n",
      "Testing for epoch 21 index 13:\n",
      "\n",
      "Testing for epoch 21 index 14:\n",
      "\n",
      "Testing for epoch 21 index 15:\n",
      "\n",
      "Testing for epoch 21 index 16:\n",
      "\n",
      "Testing for epoch 21 index 17:\n",
      "\n",
      "Testing for epoch 21 index 18:\n",
      "\n",
      "Testing for epoch 21 index 19:\n",
      "\n",
      "Testing for epoch 21 index 20:\n",
      "\n",
      "Testing for epoch 21 index 21:\n",
      "\n",
      "Testing for epoch 21 index 22:\n",
      "\n",
      "Testing for epoch 21 index 23:\n",
      "\n",
      "Testing for epoch 21 index 24:\n",
      "\n",
      "Testing for epoch 21 index 25:\n",
      "\n",
      "Testing for epoch 21 index 26:\n",
      "\n",
      "Testing for epoch 21 index 27:\n",
      "\n",
      "Testing for epoch 21 index 28:\n",
      "\n",
      "Testing for epoch 21 index 29:\n",
      "\n",
      "Testing for epoch 21 index 30:\n",
      "\n",
      "Testing for epoch 21 index 31:\n",
      "\n",
      "Testing for epoch 21 index 32:\n",
      "\n",
      "Testing for epoch 21 index 33:\n",
      "\n",
      "Testing for epoch 21 index 34:\n",
      "\n",
      "Testing for epoch 21 index 35:\n",
      "\n",
      "Testing for epoch 21 index 36:\n",
      "\n",
      "Testing for epoch 21 index 37:\n",
      "\n",
      "Testing for epoch 21 index 38:\n",
      "\n",
      "Testing for epoch 21 index 39:\n",
      "\n",
      "Testing for epoch 21 index 40:\n",
      "\n",
      "Testing for epoch 21 index 41:\n",
      "\n",
      "Testing for epoch 21 index 42:\n",
      "\n",
      "Testing for epoch 21 index 43:\n",
      "\n",
      "Testing for epoch 21 index 44:\n",
      "Epoch 22 of 60\n",
      "\n",
      "Testing for epoch 22 index 1:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.1116\n",
      "\n",
      "Testing for epoch 22 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1345\n",
      "\n",
      "Testing for epoch 22 index 3:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.1434\n",
      "\n",
      "Testing for epoch 22 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1590\n",
      "\n",
      "Testing for epoch 22 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1625\n",
      "\n",
      "Testing for epoch 22 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1788\n",
      "\n",
      "Testing for epoch 22 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1996\n",
      "\n",
      "Testing for epoch 22 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2009\n",
      "\n",
      "Testing for epoch 22 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2195\n",
      "\n",
      "Testing for epoch 22 index 10:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 5.2258\n",
      "\n",
      "Testing for epoch 22 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.2371\n",
      "\n",
      "Testing for epoch 22 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2499\n",
      "\n",
      "Testing for epoch 22 index 13:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 5.2577\n",
      "\n",
      "Testing for epoch 22 index 14:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.2724\n",
      "\n",
      "Testing for epoch 22 index 15:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 5.2729\n",
      "\n",
      "Testing for epoch 22 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2874\n",
      "\n",
      "Testing for epoch 22 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.2926\n",
      "\n",
      "Testing for epoch 22 index 18:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 5.3189\n",
      "\n",
      "Testing for epoch 22 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3134\n",
      "\n",
      "Testing for epoch 22 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3154\n",
      "\n",
      "Testing for epoch 22 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.3202\n",
      "\n",
      "Testing for epoch 22 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3308\n",
      "\n",
      "Testing for epoch 22 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.3457\n",
      "\n",
      "Testing for epoch 22 index 24:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.3413\n",
      "\n",
      "Testing for epoch 22 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3584\n",
      "\n",
      "Testing for epoch 22 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3556\n",
      "\n",
      "Testing for epoch 22 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3705\n",
      "\n",
      "Testing for epoch 22 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3662\n",
      "\n",
      "Testing for epoch 22 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3739\n",
      "\n",
      "Testing for epoch 22 index 30:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.3778\n",
      "\n",
      "Testing for epoch 22 index 31:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.3840\n",
      "\n",
      "Testing for epoch 22 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3980\n",
      "\n",
      "Testing for epoch 22 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3931\n",
      "\n",
      "Testing for epoch 22 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4027\n",
      "\n",
      "Testing for epoch 22 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4092\n",
      "\n",
      "Testing for epoch 22 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4168\n",
      "\n",
      "Testing for epoch 22 index 37:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.4300\n",
      "\n",
      "Testing for epoch 22 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4325\n",
      "\n",
      "Testing for epoch 22 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4503\n",
      "\n",
      "Testing for epoch 22 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4582\n",
      "\n",
      "Testing for epoch 22 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4652\n",
      "\n",
      "Testing for epoch 22 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4695\n",
      "\n",
      "Testing for epoch 22 index 43:\n",
      "16/16 [==============================] - 0s 933us/step - loss: 5.4760\n",
      "\n",
      "Testing for epoch 22 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4753\n",
      "Epoch 23 of 60\n",
      "\n",
      "Testing for epoch 23 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4894\n",
      "\n",
      "Testing for epoch 23 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4956\n",
      "\n",
      "Testing for epoch 23 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4988\n",
      "\n",
      "Testing for epoch 23 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5049\n",
      "\n",
      "Testing for epoch 23 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5156\n",
      "\n",
      "Testing for epoch 23 index 6:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 5.5190\n",
      "\n",
      "Testing for epoch 23 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5341\n",
      "\n",
      "Testing for epoch 23 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5360\n",
      "\n",
      "Testing for epoch 23 index 9:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.5396\n",
      "\n",
      "Testing for epoch 23 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5517\n",
      "\n",
      "Testing for epoch 23 index 11:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.5581\n",
      "\n",
      "Testing for epoch 23 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5621\n",
      "\n",
      "Testing for epoch 23 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5642\n",
      "\n",
      "Testing for epoch 23 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5746\n",
      "\n",
      "Testing for epoch 23 index 15:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.5781\n",
      "\n",
      "Testing for epoch 23 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5803\n",
      "\n",
      "Testing for epoch 23 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5925\n",
      "\n",
      "Testing for epoch 23 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5945\n",
      "\n",
      "Testing for epoch 23 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5969\n",
      "\n",
      "Testing for epoch 23 index 20:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.6156\n",
      "\n",
      "Testing for epoch 23 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6105\n",
      "\n",
      "Testing for epoch 23 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6113\n",
      "\n",
      "Testing for epoch 23 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6288\n",
      "\n",
      "Testing for epoch 23 index 24:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 5.6280\n",
      "\n",
      "Testing for epoch 23 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.6258\n",
      "\n",
      "Testing for epoch 23 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6303\n",
      "\n",
      "Testing for epoch 23 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6349\n",
      "\n",
      "Testing for epoch 23 index 28:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.6418\n",
      "\n",
      "Testing for epoch 23 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6404\n",
      "\n",
      "Testing for epoch 23 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6491\n",
      "\n",
      "Testing for epoch 23 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6509\n",
      "\n",
      "Testing for epoch 23 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6590\n",
      "\n",
      "Testing for epoch 23 index 33:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.6570\n",
      "\n",
      "Testing for epoch 23 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6703\n",
      "\n",
      "Testing for epoch 23 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6738\n",
      "\n",
      "Testing for epoch 23 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6784\n",
      "\n",
      "Testing for epoch 23 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6849\n",
      "\n",
      "Testing for epoch 23 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6941\n",
      "\n",
      "Testing for epoch 23 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6981\n",
      "\n",
      "Testing for epoch 23 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.7067\n",
      "\n",
      "Testing for epoch 23 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7071\n",
      "\n",
      "Testing for epoch 23 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7159\n",
      "\n",
      "Testing for epoch 23 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7194\n",
      "\n",
      "Testing for epoch 23 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7280\n",
      "Epoch 24 of 60\n",
      "\n",
      "Testing for epoch 24 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7219\n",
      "\n",
      "Testing for epoch 24 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7346\n",
      "\n",
      "Testing for epoch 24 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7305\n",
      "\n",
      "Testing for epoch 24 index 4:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.7455\n",
      "\n",
      "Testing for epoch 24 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7459\n",
      "\n",
      "Testing for epoch 24 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7465\n",
      "\n",
      "Testing for epoch 24 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7584\n",
      "\n",
      "Testing for epoch 24 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7703\n",
      "\n",
      "Testing for epoch 24 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7731\n",
      "\n",
      "Testing for epoch 24 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7756\n",
      "\n",
      "Testing for epoch 24 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7849\n",
      "\n",
      "Testing for epoch 24 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7828\n",
      "\n",
      "Testing for epoch 24 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7865\n",
      "\n",
      "Testing for epoch 24 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7882\n",
      "\n",
      "Testing for epoch 24 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7928\n",
      "\n",
      "Testing for epoch 24 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8028\n",
      "\n",
      "Testing for epoch 24 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8094\n",
      "\n",
      "Testing for epoch 24 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8033\n",
      "\n",
      "Testing for epoch 24 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8123\n",
      "\n",
      "Testing for epoch 24 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8178\n",
      "\n",
      "Testing for epoch 24 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8191\n",
      "\n",
      "Testing for epoch 24 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8285\n",
      "\n",
      "Testing for epoch 24 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8349\n",
      "\n",
      "Testing for epoch 24 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8471\n",
      "\n",
      "Testing for epoch 24 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.8422\n",
      "\n",
      "Testing for epoch 24 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8487\n",
      "\n",
      "Testing for epoch 24 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8341\n",
      "\n",
      "Testing for epoch 24 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8500\n",
      "\n",
      "Testing for epoch 24 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8545\n",
      "\n",
      "Testing for epoch 24 index 30:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8535\n",
      "\n",
      "Testing for epoch 24 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8543\n",
      "\n",
      "Testing for epoch 24 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8580\n",
      "\n",
      "Testing for epoch 24 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8514\n",
      "\n",
      "Testing for epoch 24 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8754\n",
      "\n",
      "Testing for epoch 24 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8720\n",
      "\n",
      "Testing for epoch 24 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8806\n",
      "\n",
      "Testing for epoch 24 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8862\n",
      "\n",
      "Testing for epoch 24 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8895\n",
      "\n",
      "Testing for epoch 24 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8880\n",
      "\n",
      "Testing for epoch 24 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9031\n",
      "\n",
      "Testing for epoch 24 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9031\n",
      "\n",
      "Testing for epoch 24 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9034\n",
      "\n",
      "Testing for epoch 24 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9074\n",
      "\n",
      "Testing for epoch 24 index 44:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.9166\n",
      "Epoch 25 of 60\n",
      "\n",
      "Testing for epoch 25 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9096\n",
      "\n",
      "Testing for epoch 25 index 2:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 5.9250\n",
      "\n",
      "Testing for epoch 25 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9251\n",
      "\n",
      "Testing for epoch 25 index 4:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 5.9222\n",
      "\n",
      "Testing for epoch 25 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9350\n",
      "\n",
      "Testing for epoch 25 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.9424\n",
      "\n",
      "Testing for epoch 25 index 7:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 5.9429\n",
      "\n",
      "Testing for epoch 25 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9425\n",
      "\n",
      "Testing for epoch 25 index 9:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 5.9566\n",
      "\n",
      "Testing for epoch 25 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9509\n",
      "\n",
      "Testing for epoch 25 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9552\n",
      "\n",
      "Testing for epoch 25 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9638\n",
      "\n",
      "Testing for epoch 25 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9617\n",
      "\n",
      "Testing for epoch 25 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9716\n",
      "\n",
      "Testing for epoch 25 index 15:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 5.9733\n",
      "\n",
      "Testing for epoch 25 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9816\n",
      "\n",
      "Testing for epoch 25 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9761\n",
      "\n",
      "Testing for epoch 25 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9895\n",
      "\n",
      "Testing for epoch 25 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9940\n",
      "\n",
      "Testing for epoch 25 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9915\n",
      "\n",
      "Testing for epoch 25 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0026\n",
      "\n",
      "Testing for epoch 25 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9972\n",
      "\n",
      "Testing for epoch 25 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0045\n",
      "\n",
      "Testing for epoch 25 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0030\n",
      "\n",
      "Testing for epoch 25 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0140\n",
      "\n",
      "Testing for epoch 25 index 26:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.0131\n",
      "\n",
      "Testing for epoch 25 index 27:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.0157\n",
      "\n",
      "Testing for epoch 25 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0153\n",
      "\n",
      "Testing for epoch 25 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0199\n",
      "\n",
      "Testing for epoch 25 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0099\n",
      "\n",
      "Testing for epoch 25 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0151\n",
      "\n",
      "Testing for epoch 25 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0153\n",
      "\n",
      "Testing for epoch 25 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0261\n",
      "\n",
      "Testing for epoch 25 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0311\n",
      "\n",
      "Testing for epoch 25 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0268\n",
      "\n",
      "Testing for epoch 25 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0330\n",
      "\n",
      "Testing for epoch 25 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0478\n",
      "\n",
      "Testing for epoch 25 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0423\n",
      "\n",
      "Testing for epoch 25 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0468\n",
      "\n",
      "Testing for epoch 25 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0602\n",
      "\n",
      "Testing for epoch 25 index 41:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.0581\n",
      "\n",
      "Testing for epoch 25 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.0560\n",
      "\n",
      "Testing for epoch 25 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0696\n",
      "\n",
      "Testing for epoch 25 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0724\n",
      "Epoch 26 of 60\n",
      "\n",
      "Testing for epoch 26 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0660\n",
      "\n",
      "Testing for epoch 26 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0780\n",
      "\n",
      "Testing for epoch 26 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0743\n",
      "\n",
      "Testing for epoch 26 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0773\n",
      "\n",
      "Testing for epoch 26 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0855\n",
      "\n",
      "Testing for epoch 26 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0800\n",
      "\n",
      "Testing for epoch 26 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1041\n",
      "\n",
      "Testing for epoch 26 index 8:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1079\n",
      "\n",
      "Testing for epoch 26 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1052\n",
      "\n",
      "Testing for epoch 26 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1035\n",
      "\n",
      "Testing for epoch 26 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1057\n",
      "\n",
      "Testing for epoch 26 index 12:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.1205\n",
      "\n",
      "Testing for epoch 26 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1260\n",
      "\n",
      "Testing for epoch 26 index 14:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1125\n",
      "\n",
      "Testing for epoch 26 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1231\n",
      "\n",
      "Testing for epoch 26 index 16:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.1269\n",
      "\n",
      "Testing for epoch 26 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1230\n",
      "\n",
      "Testing for epoch 26 index 18:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.1249\n",
      "\n",
      "Testing for epoch 26 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1352\n",
      "\n",
      "Testing for epoch 26 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1338\n",
      "\n",
      "Testing for epoch 26 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1412\n",
      "\n",
      "Testing for epoch 26 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1309\n",
      "\n",
      "Testing for epoch 26 index 23:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.1475\n",
      "\n",
      "Testing for epoch 26 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1589\n",
      "\n",
      "Testing for epoch 26 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1554\n",
      "\n",
      "Testing for epoch 26 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1523\n",
      "\n",
      "Testing for epoch 26 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1499\n",
      "\n",
      "Testing for epoch 26 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1488\n",
      "\n",
      "Testing for epoch 26 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1559\n",
      "\n",
      "Testing for epoch 26 index 30:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1569\n",
      "\n",
      "Testing for epoch 26 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1637\n",
      "\n",
      "Testing for epoch 26 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1691\n",
      "\n",
      "Testing for epoch 26 index 33:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1673\n",
      "\n",
      "Testing for epoch 26 index 34:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.1735\n",
      "\n",
      "Testing for epoch 26 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1792\n",
      "\n",
      "Testing for epoch 26 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1718\n",
      "\n",
      "Testing for epoch 26 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1720\n",
      "\n",
      "Testing for epoch 26 index 38:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 6.1888\n",
      "\n",
      "Testing for epoch 26 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1820\n",
      "\n",
      "Testing for epoch 26 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1891\n",
      "\n",
      "Testing for epoch 26 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1910\n",
      "\n",
      "Testing for epoch 26 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1910\n",
      "\n",
      "Testing for epoch 26 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1981\n",
      "\n",
      "Testing for epoch 26 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2093\n",
      "Epoch 27 of 60\n",
      "\n",
      "Testing for epoch 27 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2021\n",
      "\n",
      "Testing for epoch 27 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.2053\n",
      "\n",
      "Testing for epoch 27 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2171\n",
      "\n",
      "Testing for epoch 27 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2187\n",
      "\n",
      "Testing for epoch 27 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2089\n",
      "\n",
      "Testing for epoch 27 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2179\n",
      "\n",
      "Testing for epoch 27 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2336\n",
      "\n",
      "Testing for epoch 27 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2409\n",
      "\n",
      "Testing for epoch 27 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2350\n",
      "\n",
      "Testing for epoch 27 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2260\n",
      "\n",
      "Testing for epoch 27 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2313\n",
      "\n",
      "Testing for epoch 27 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2411\n",
      "\n",
      "Testing for epoch 27 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2504\n",
      "\n",
      "Testing for epoch 27 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2489\n",
      "\n",
      "Testing for epoch 27 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2404\n",
      "\n",
      "Testing for epoch 27 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2459\n",
      "\n",
      "Testing for epoch 27 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2498\n",
      "\n",
      "Testing for epoch 27 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2464\n",
      "\n",
      "Testing for epoch 27 index 19:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.2517\n",
      "\n",
      "Testing for epoch 27 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2584\n",
      "\n",
      "Testing for epoch 27 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2620\n",
      "\n",
      "Testing for epoch 27 index 22:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.2563\n",
      "\n",
      "Testing for epoch 27 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2699\n",
      "\n",
      "Testing for epoch 27 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2749\n",
      "\n",
      "Testing for epoch 27 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2719\n",
      "\n",
      "Testing for epoch 27 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2826\n",
      "\n",
      "Testing for epoch 27 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2741\n",
      "\n",
      "Testing for epoch 27 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2750\n",
      "\n",
      "Testing for epoch 27 index 29:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.2762\n",
      "\n",
      "Testing for epoch 27 index 30:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.2849\n",
      "\n",
      "Testing for epoch 27 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2820\n",
      "\n",
      "Testing for epoch 27 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2869\n",
      "\n",
      "Testing for epoch 27 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2911\n",
      "\n",
      "Testing for epoch 27 index 34:\n",
      "16/16 [==============================] - 0s 929us/step - loss: 6.2995\n",
      "\n",
      "Testing for epoch 27 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2801\n",
      "\n",
      "Testing for epoch 27 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2822\n",
      "\n",
      "Testing for epoch 27 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2917\n",
      "\n",
      "Testing for epoch 27 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2962\n",
      "\n",
      "Testing for epoch 27 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3005\n",
      "\n",
      "Testing for epoch 27 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3147\n",
      "\n",
      "Testing for epoch 27 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2966\n",
      "\n",
      "Testing for epoch 27 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3204\n",
      "\n",
      "Testing for epoch 27 index 43:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.3065\n",
      "\n",
      "Testing for epoch 27 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3061\n",
      "Epoch 28 of 60\n",
      "\n",
      "Testing for epoch 28 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3143\n",
      "\n",
      "Testing for epoch 28 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3143\n",
      "\n",
      "Testing for epoch 28 index 3:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.3279\n",
      "\n",
      "Testing for epoch 28 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3236\n",
      "\n",
      "Testing for epoch 28 index 5:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 6.3313\n",
      "\n",
      "Testing for epoch 28 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3449\n",
      "\n",
      "Testing for epoch 28 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3322\n",
      "\n",
      "Testing for epoch 28 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3428\n",
      "\n",
      "Testing for epoch 28 index 9:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.3368\n",
      "\n",
      "Testing for epoch 28 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3488\n",
      "\n",
      "Testing for epoch 28 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3406\n",
      "\n",
      "Testing for epoch 28 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3571\n",
      "\n",
      "Testing for epoch 28 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3488\n",
      "\n",
      "Testing for epoch 28 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3505\n",
      "\n",
      "Testing for epoch 28 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3427\n",
      "\n",
      "Testing for epoch 28 index 16:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3538\n",
      "\n",
      "Testing for epoch 28 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3577\n",
      "\n",
      "Testing for epoch 28 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3481\n",
      "\n",
      "Testing for epoch 28 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3665\n",
      "\n",
      "Testing for epoch 28 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3751\n",
      "\n",
      "Testing for epoch 28 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3631\n",
      "\n",
      "Testing for epoch 28 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3654\n",
      "\n",
      "Testing for epoch 28 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3737\n",
      "\n",
      "Testing for epoch 28 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3713\n",
      "\n",
      "Testing for epoch 28 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3668\n",
      "\n",
      "Testing for epoch 28 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3774\n",
      "\n",
      "Testing for epoch 28 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3891\n",
      "\n",
      "Testing for epoch 28 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3843\n",
      "\n",
      "Testing for epoch 28 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3804\n",
      "\n",
      "Testing for epoch 28 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3880\n",
      "\n",
      "Testing for epoch 28 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3878\n",
      "\n",
      "Testing for epoch 28 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3910\n",
      "\n",
      "Testing for epoch 28 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4061\n",
      "\n",
      "Testing for epoch 28 index 34:\n",
      "16/16 [==============================] - 0s 798us/step - loss: 6.4041\n",
      "\n",
      "Testing for epoch 28 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3950\n",
      "\n",
      "Testing for epoch 28 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4044\n",
      "\n",
      "Testing for epoch 28 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3950\n",
      "\n",
      "Testing for epoch 28 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4063\n",
      "\n",
      "Testing for epoch 28 index 39:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.4212\n",
      "\n",
      "Testing for epoch 28 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4052\n",
      "\n",
      "Testing for epoch 28 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4065\n",
      "\n",
      "Testing for epoch 28 index 42:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 6.4274\n",
      "\n",
      "Testing for epoch 28 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4332\n",
      "\n",
      "Testing for epoch 28 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4122\n",
      "Epoch 29 of 60\n",
      "\n",
      "Testing for epoch 29 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4185\n",
      "\n",
      "Testing for epoch 29 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4226\n",
      "\n",
      "Testing for epoch 29 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4164\n",
      "\n",
      "Testing for epoch 29 index 4:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.4331\n",
      "\n",
      "Testing for epoch 29 index 5:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.4305\n",
      "\n",
      "Testing for epoch 29 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.4147\n",
      "\n",
      "Testing for epoch 29 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4453\n",
      "\n",
      "Testing for epoch 29 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4398\n",
      "\n",
      "Testing for epoch 29 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4483\n",
      "\n",
      "Testing for epoch 29 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4407\n",
      "\n",
      "Testing for epoch 29 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.4448\n",
      "\n",
      "Testing for epoch 29 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4440\n",
      "\n",
      "Testing for epoch 29 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4515\n",
      "\n",
      "Testing for epoch 29 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4574\n",
      "\n",
      "Testing for epoch 29 index 15:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.4494\n",
      "\n",
      "Testing for epoch 29 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4550\n",
      "\n",
      "Testing for epoch 29 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4624\n",
      "\n",
      "Testing for epoch 29 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4694\n",
      "\n",
      "Testing for epoch 29 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4570\n",
      "\n",
      "Testing for epoch 29 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4603\n",
      "\n",
      "Testing for epoch 29 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4832\n",
      "\n",
      "Testing for epoch 29 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4616\n",
      "\n",
      "Testing for epoch 29 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4653\n",
      "\n",
      "Testing for epoch 29 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4690\n",
      "\n",
      "Testing for epoch 29 index 25:\n",
      "16/16 [==============================] - 0s 932us/step - loss: 6.4690\n",
      "\n",
      "Testing for epoch 29 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4673\n",
      "\n",
      "Testing for epoch 29 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4801\n",
      "\n",
      "Testing for epoch 29 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4781\n",
      "\n",
      "Testing for epoch 29 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4883\n",
      "\n",
      "Testing for epoch 29 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4835\n",
      "\n",
      "Testing for epoch 29 index 31:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.4884\n",
      "\n",
      "Testing for epoch 29 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4810\n",
      "\n",
      "Testing for epoch 29 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4890\n",
      "\n",
      "Testing for epoch 29 index 34:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4785\n",
      "\n",
      "Testing for epoch 29 index 35:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4893\n",
      "\n",
      "Testing for epoch 29 index 36:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5036\n",
      "\n",
      "Testing for epoch 29 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4945\n",
      "\n",
      "Testing for epoch 29 index 38:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5005\n",
      "\n",
      "Testing for epoch 29 index 39:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.4968\n",
      "\n",
      "Testing for epoch 29 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5005\n",
      "\n",
      "Testing for epoch 29 index 41:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4901\n",
      "\n",
      "Testing for epoch 29 index 42:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5057\n",
      "\n",
      "Testing for epoch 29 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5095\n",
      "\n",
      "Testing for epoch 29 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4999\n",
      "Epoch 30 of 60\n",
      "\n",
      "Testing for epoch 30 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5230\n",
      "\n",
      "Testing for epoch 30 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5182\n",
      "\n",
      "Testing for epoch 30 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5246\n",
      "\n",
      "Testing for epoch 30 index 4:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5167\n",
      "\n",
      "Testing for epoch 30 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5176\n",
      "\n",
      "Testing for epoch 30 index 6:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5266\n",
      "\n",
      "Testing for epoch 30 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5250\n",
      "\n",
      "Testing for epoch 30 index 8:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 6.5190\n",
      "\n",
      "Testing for epoch 30 index 9:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5327\n",
      "\n",
      "Testing for epoch 30 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5297\n",
      "\n",
      "Testing for epoch 30 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5210\n",
      "\n",
      "Testing for epoch 30 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5327\n",
      "\n",
      "Testing for epoch 30 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5221\n",
      "\n",
      "Testing for epoch 30 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5417\n",
      "\n",
      "Testing for epoch 30 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5444\n",
      "\n",
      "Testing for epoch 30 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5437\n",
      "\n",
      "Testing for epoch 30 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5522\n",
      "\n",
      "Testing for epoch 30 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5511\n",
      "\n",
      "Testing for epoch 30 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5343\n",
      "\n",
      "Testing for epoch 30 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5508\n",
      "\n",
      "Testing for epoch 30 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5479\n",
      "\n",
      "Testing for epoch 30 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5553\n",
      "\n",
      "Testing for epoch 30 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5607\n",
      "\n",
      "Testing for epoch 30 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5611\n",
      "\n",
      "Testing for epoch 30 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5482\n",
      "\n",
      "Testing for epoch 30 index 26:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5490\n",
      "\n",
      "Testing for epoch 30 index 27:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5638\n",
      "\n",
      "Testing for epoch 30 index 28:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5696\n",
      "\n",
      "Testing for epoch 30 index 29:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.5644\n",
      "\n",
      "Testing for epoch 30 index 30:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5724\n",
      "\n",
      "Testing for epoch 30 index 31:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.5481\n",
      "\n",
      "Testing for epoch 30 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5858\n",
      "\n",
      "Testing for epoch 30 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5652\n",
      "\n",
      "Testing for epoch 30 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5677\n",
      "\n",
      "Testing for epoch 30 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5730\n",
      "\n",
      "Testing for epoch 30 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5776\n",
      "\n",
      "Testing for epoch 30 index 37:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.5891\n",
      "\n",
      "Testing for epoch 30 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5928\n",
      "\n",
      "Testing for epoch 30 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5886\n",
      "\n",
      "Testing for epoch 30 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5871\n",
      "\n",
      "Testing for epoch 30 index 41:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.5870\n",
      "\n",
      "Testing for epoch 30 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6030\n",
      "\n",
      "Testing for epoch 30 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5750\n",
      "\n",
      "Testing for epoch 30 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5844\n",
      "Epoch 31 of 60\n",
      "\n",
      "Testing for epoch 31 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5937\n",
      "\n",
      "Testing for epoch 31 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6031\n",
      "\n",
      "Testing for epoch 31 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6023\n",
      "\n",
      "Testing for epoch 31 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.5974\n",
      "\n",
      "Testing for epoch 31 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6057\n",
      "\n",
      "Testing for epoch 31 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6012\n",
      "\n",
      "Testing for epoch 31 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6213\n",
      "\n",
      "Testing for epoch 31 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6024\n",
      "\n",
      "Testing for epoch 31 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6267\n",
      "\n",
      "Testing for epoch 31 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.6254\n",
      "\n",
      "Testing for epoch 31 index 11:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6154\n",
      "\n",
      "Testing for epoch 31 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6172\n",
      "\n",
      "Testing for epoch 31 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6256\n",
      "\n",
      "Testing for epoch 31 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6161\n",
      "\n",
      "Testing for epoch 31 index 15:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6148\n",
      "\n",
      "Testing for epoch 31 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6183\n",
      "\n",
      "Testing for epoch 31 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6198\n",
      "\n",
      "Testing for epoch 31 index 18:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.6240\n",
      "\n",
      "Testing for epoch 31 index 19:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6367\n",
      "\n",
      "Testing for epoch 31 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6208\n",
      "\n",
      "Testing for epoch 31 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6411\n",
      "\n",
      "Testing for epoch 31 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6386\n",
      "\n",
      "Testing for epoch 31 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6236\n",
      "\n",
      "Testing for epoch 31 index 24:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6282\n",
      "\n",
      "Testing for epoch 31 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6405\n",
      "\n",
      "Testing for epoch 31 index 26:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6465\n",
      "\n",
      "Testing for epoch 31 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6362\n",
      "\n",
      "Testing for epoch 31 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6259\n",
      "\n",
      "Testing for epoch 31 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6328\n",
      "\n",
      "Testing for epoch 31 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6485\n",
      "\n",
      "Testing for epoch 31 index 31:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.6535\n",
      "\n",
      "Testing for epoch 31 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6565\n",
      "\n",
      "Testing for epoch 31 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6425\n",
      "\n",
      "Testing for epoch 31 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6609\n",
      "\n",
      "Testing for epoch 31 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6352\n",
      "\n",
      "Testing for epoch 31 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6678\n",
      "\n",
      "Testing for epoch 31 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6651\n",
      "\n",
      "Testing for epoch 31 index 38:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.6635\n",
      "\n",
      "Testing for epoch 31 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6682\n",
      "\n",
      "Testing for epoch 31 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6564\n",
      "\n",
      "Testing for epoch 31 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6708\n",
      "\n",
      "Testing for epoch 31 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6627\n",
      "\n",
      "Testing for epoch 31 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6509\n",
      "\n",
      "Testing for epoch 31 index 44:\n",
      "16/16 [==============================] - 0s 967us/step - loss: 6.6727\n",
      "Epoch 32 of 60\n",
      "\n",
      "Testing for epoch 32 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6695\n",
      "\n",
      "Testing for epoch 32 index 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6767\n",
      "\n",
      "Testing for epoch 32 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6770\n",
      "\n",
      "Testing for epoch 32 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6779\n",
      "\n",
      "Testing for epoch 32 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6871\n",
      "\n",
      "Testing for epoch 32 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6789\n",
      "\n",
      "Testing for epoch 32 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6691\n",
      "\n",
      "Testing for epoch 32 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6812\n",
      "\n",
      "Testing for epoch 32 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6817\n",
      "\n",
      "Testing for epoch 32 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6892\n",
      "\n",
      "Testing for epoch 32 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6762\n",
      "\n",
      "Testing for epoch 32 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7010\n",
      "\n",
      "Testing for epoch 32 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6995\n",
      "\n",
      "Testing for epoch 32 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6926\n",
      "\n",
      "Testing for epoch 32 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6887\n",
      "\n",
      "Testing for epoch 32 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6806\n",
      "\n",
      "Testing for epoch 32 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7055\n",
      "\n",
      "Testing for epoch 32 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.6920\n",
      "\n",
      "Testing for epoch 32 index 19:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 6.6989\n",
      "\n",
      "Testing for epoch 32 index 20:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.6900\n",
      "\n",
      "Testing for epoch 32 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7052\n",
      "\n",
      "Testing for epoch 32 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6927\n",
      "\n",
      "Testing for epoch 32 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6921\n",
      "\n",
      "Testing for epoch 32 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7159\n",
      "\n",
      "Testing for epoch 32 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7046\n",
      "\n",
      "Testing for epoch 32 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6970\n",
      "\n",
      "Testing for epoch 32 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7267\n",
      "\n",
      "Testing for epoch 32 index 28:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7082\n",
      "\n",
      "Testing for epoch 32 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7061\n",
      "\n",
      "Testing for epoch 32 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7028\n",
      "\n",
      "Testing for epoch 32 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7246\n",
      "\n",
      "Testing for epoch 32 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7244\n",
      "\n",
      "Testing for epoch 32 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7193\n",
      "\n",
      "Testing for epoch 32 index 34:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7040\n",
      "\n",
      "Testing for epoch 32 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7293\n",
      "\n",
      "Testing for epoch 32 index 36:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7215\n",
      "\n",
      "Testing for epoch 32 index 37:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7278\n",
      "\n",
      "Testing for epoch 32 index 38:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7296\n",
      "\n",
      "Testing for epoch 32 index 39:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.7262\n",
      "\n",
      "Testing for epoch 32 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7276\n",
      "\n",
      "Testing for epoch 32 index 41:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7324\n",
      "\n",
      "Testing for epoch 32 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7322\n",
      "\n",
      "Testing for epoch 32 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7207\n",
      "\n",
      "Testing for epoch 32 index 44:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.7470\n",
      "Epoch 33 of 60\n",
      "\n",
      "Testing for epoch 33 index 1:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.7474\n",
      "\n",
      "Testing for epoch 33 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7363\n",
      "\n",
      "Testing for epoch 33 index 3:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.7491\n",
      "\n",
      "Testing for epoch 33 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7551\n",
      "\n",
      "Testing for epoch 33 index 5:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7487\n",
      "\n",
      "Testing for epoch 33 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7561\n",
      "\n",
      "Testing for epoch 33 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7617\n",
      "\n",
      "Testing for epoch 33 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7448\n",
      "\n",
      "Testing for epoch 33 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7436\n",
      "\n",
      "Testing for epoch 33 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7681\n",
      "\n",
      "Testing for epoch 33 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7603\n",
      "\n",
      "Testing for epoch 33 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7619\n",
      "\n",
      "Testing for epoch 33 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7425\n",
      "\n",
      "Testing for epoch 33 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7643\n",
      "\n",
      "Testing for epoch 33 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7596\n",
      "\n",
      "Testing for epoch 33 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7535\n",
      "\n",
      "Testing for epoch 33 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7786\n",
      "\n",
      "Testing for epoch 33 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7661\n",
      "\n",
      "Testing for epoch 33 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7759\n",
      "\n",
      "Testing for epoch 33 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7608\n",
      "\n",
      "Testing for epoch 33 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7973\n",
      "\n",
      "Testing for epoch 33 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7792\n",
      "\n",
      "Testing for epoch 33 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7753\n",
      "\n",
      "Testing for epoch 33 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7602\n",
      "\n",
      "Testing for epoch 33 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7800\n",
      "\n",
      "Testing for epoch 33 index 26:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.7662\n",
      "\n",
      "Testing for epoch 33 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7609\n",
      "\n",
      "Testing for epoch 33 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7767\n",
      "\n",
      "Testing for epoch 33 index 29:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7912\n",
      "\n",
      "Testing for epoch 33 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7696\n",
      "\n",
      "Testing for epoch 33 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7831\n",
      "\n",
      "Testing for epoch 33 index 32:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8080\n",
      "\n",
      "Testing for epoch 33 index 33:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7917\n",
      "\n",
      "Testing for epoch 33 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7844\n",
      "\n",
      "Testing for epoch 33 index 35:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8041\n",
      "\n",
      "Testing for epoch 33 index 36:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 6.8002\n",
      "\n",
      "Testing for epoch 33 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7907\n",
      "\n",
      "Testing for epoch 33 index 38:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 6.8099\n",
      "\n",
      "Testing for epoch 33 index 39:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 6.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing for epoch 33 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.7890\n",
      "\n",
      "Testing for epoch 33 index 41:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8129\n",
      "\n",
      "Testing for epoch 33 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7904\n",
      "\n",
      "Testing for epoch 33 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8239\n",
      "\n",
      "Testing for epoch 33 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7912\n",
      "Epoch 34 of 60\n",
      "\n",
      "Testing for epoch 34 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8147\n",
      "\n",
      "Testing for epoch 34 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.7941\n",
      "\n",
      "Testing for epoch 34 index 3:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8201\n",
      "\n",
      "Testing for epoch 34 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8089\n",
      "\n",
      "Testing for epoch 34 index 5:\n",
      "16/16 [==============================] - 0s 995us/step - loss: 6.8223\n",
      "\n",
      "Testing for epoch 34 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8078\n",
      "\n",
      "Testing for epoch 34 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8146\n",
      "\n",
      "Testing for epoch 34 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8109\n",
      "\n",
      "Testing for epoch 34 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8252\n",
      "\n",
      "Testing for epoch 34 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8240\n",
      "\n",
      "Testing for epoch 34 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8318\n",
      "\n",
      "Testing for epoch 34 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8220\n",
      "\n",
      "Testing for epoch 34 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8247\n",
      "\n",
      "Testing for epoch 34 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8322\n",
      "\n",
      "Testing for epoch 34 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8390\n",
      "\n",
      "Testing for epoch 34 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8365\n",
      "\n",
      "Testing for epoch 34 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8162\n",
      "\n",
      "Testing for epoch 34 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8441\n",
      "\n",
      "Testing for epoch 34 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8259\n",
      "\n",
      "Testing for epoch 34 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8109\n",
      "\n",
      "Testing for epoch 34 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8516\n",
      "\n",
      "Testing for epoch 34 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8481\n",
      "\n",
      "Testing for epoch 34 index 23:\n",
      "16/16 [==============================] - 0s 960us/step - loss: 6.8582\n",
      "\n",
      "Testing for epoch 34 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8481\n",
      "\n",
      "Testing for epoch 34 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8304\n",
      "\n",
      "Testing for epoch 34 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8407\n",
      "\n",
      "Testing for epoch 34 index 27:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.8251\n",
      "\n",
      "Testing for epoch 34 index 28:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8414\n",
      "\n",
      "Testing for epoch 34 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8655\n",
      "\n",
      "Testing for epoch 34 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8326\n",
      "\n",
      "Testing for epoch 34 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8597\n",
      "\n",
      "Testing for epoch 34 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8342\n",
      "\n",
      "Testing for epoch 34 index 33:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8438\n",
      "\n",
      "Testing for epoch 34 index 34:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.8438\n",
      "\n",
      "Testing for epoch 34 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8675\n",
      "\n",
      "Testing for epoch 34 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8564\n",
      "\n",
      "Testing for epoch 34 index 37:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8324\n",
      "\n",
      "Testing for epoch 34 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8656\n",
      "\n",
      "Testing for epoch 34 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8672\n",
      "\n",
      "Testing for epoch 34 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8658\n",
      "\n",
      "Testing for epoch 34 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8590\n",
      "\n",
      "Testing for epoch 34 index 42:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8463\n",
      "\n",
      "Testing for epoch 34 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8573\n",
      "\n",
      "Testing for epoch 34 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8573\n",
      "Epoch 35 of 60\n",
      "\n",
      "Testing for epoch 35 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8680\n",
      "\n",
      "Testing for epoch 35 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8543\n",
      "\n",
      "Testing for epoch 35 index 3:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8612\n",
      "\n",
      "Testing for epoch 35 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8637\n",
      "\n",
      "Testing for epoch 35 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8797\n",
      "\n",
      "Testing for epoch 35 index 6:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8947\n",
      "\n",
      "Testing for epoch 35 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8710\n",
      "\n",
      "Testing for epoch 35 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8923\n",
      "\n",
      "Testing for epoch 35 index 9:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8766\n",
      "\n",
      "Testing for epoch 35 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8725\n",
      "\n",
      "Testing for epoch 35 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9115\n",
      "\n",
      "Testing for epoch 35 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8835\n",
      "\n",
      "Testing for epoch 35 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8912\n",
      "\n",
      "Testing for epoch 35 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8696\n",
      "\n",
      "Testing for epoch 35 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8951\n",
      "\n",
      "Testing for epoch 35 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8894\n",
      "\n",
      "Testing for epoch 35 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8733\n",
      "\n",
      "Testing for epoch 35 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8773\n",
      "\n",
      "Testing for epoch 35 index 19:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.9037\n",
      "\n",
      "Testing for epoch 35 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8863\n",
      "\n",
      "Testing for epoch 35 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8919\n",
      "\n",
      "Testing for epoch 35 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8771\n",
      "\n",
      "Testing for epoch 35 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8965\n",
      "\n",
      "Testing for epoch 35 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9013\n",
      "\n",
      "Testing for epoch 35 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8937\n",
      "\n",
      "Testing for epoch 35 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9081\n",
      "\n",
      "Testing for epoch 35 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9119\n",
      "\n",
      "Testing for epoch 35 index 28:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.8914\n",
      "\n",
      "Testing for epoch 35 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8728\n",
      "\n",
      "Testing for epoch 35 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9009\n",
      "\n",
      "Testing for epoch 35 index 31:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.9121\n",
      "\n",
      "Testing for epoch 35 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9098\n",
      "\n",
      "Testing for epoch 35 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9011\n",
      "\n",
      "Testing for epoch 35 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.8836\n",
      "\n",
      "Testing for epoch 35 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9128\n",
      "\n",
      "Testing for epoch 35 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9192\n",
      "\n",
      "Testing for epoch 35 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9210\n",
      "\n",
      "Testing for epoch 35 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9177\n",
      "\n",
      "Testing for epoch 35 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9221\n",
      "\n",
      "Testing for epoch 35 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9109\n",
      "\n",
      "Testing for epoch 35 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9281\n",
      "\n",
      "Testing for epoch 35 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9155\n",
      "\n",
      "Testing for epoch 35 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9306\n",
      "\n",
      "Testing for epoch 35 index 44:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9212\n",
      "Epoch 36 of 60\n",
      "\n",
      "Testing for epoch 36 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9280\n",
      "\n",
      "Testing for epoch 36 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9132\n",
      "\n",
      "Testing for epoch 36 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9393\n",
      "\n",
      "Testing for epoch 36 index 4:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.9452\n",
      "\n",
      "Testing for epoch 36 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9480\n",
      "\n",
      "Testing for epoch 36 index 6:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 6.9324\n",
      "\n",
      "Testing for epoch 36 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9261\n",
      "\n",
      "Testing for epoch 36 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9345\n",
      "\n",
      "Testing for epoch 36 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9443\n",
      "\n",
      "Testing for epoch 36 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9461\n",
      "\n",
      "Testing for epoch 36 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9389\n",
      "\n",
      "Testing for epoch 36 index 12:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 6.9523\n",
      "\n",
      "Testing for epoch 36 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9248\n",
      "\n",
      "Testing for epoch 36 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9576\n",
      "\n",
      "Testing for epoch 36 index 15:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9341\n",
      "\n",
      "Testing for epoch 36 index 16:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9520\n",
      "\n",
      "Testing for epoch 36 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9610\n",
      "\n",
      "Testing for epoch 36 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9356\n",
      "\n",
      "Testing for epoch 36 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9388\n",
      "\n",
      "Testing for epoch 36 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9513\n",
      "\n",
      "Testing for epoch 36 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9381\n",
      "\n",
      "Testing for epoch 36 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9531\n",
      "\n",
      "Testing for epoch 36 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9485\n",
      "\n",
      "Testing for epoch 36 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9486\n",
      "\n",
      "Testing for epoch 36 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9512\n",
      "\n",
      "Testing for epoch 36 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9615\n",
      "\n",
      "Testing for epoch 36 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9693\n",
      "\n",
      "Testing for epoch 36 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9378\n",
      "\n",
      "Testing for epoch 36 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9446\n",
      "\n",
      "Testing for epoch 36 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9875\n",
      "\n",
      "Testing for epoch 36 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9648\n",
      "\n",
      "Testing for epoch 36 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9868\n",
      "\n",
      "Testing for epoch 36 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9562\n",
      "\n",
      "Testing for epoch 36 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9908\n",
      "\n",
      "Testing for epoch 36 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9631\n",
      "\n",
      "Testing for epoch 36 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9838\n",
      "\n",
      "Testing for epoch 36 index 37:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.9516\n",
      "\n",
      "Testing for epoch 36 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9588\n",
      "\n",
      "Testing for epoch 36 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9679\n",
      "\n",
      "Testing for epoch 36 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9860\n",
      "\n",
      "Testing for epoch 36 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9646\n",
      "\n",
      "Testing for epoch 36 index 42:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 6.9646\n",
      "\n",
      "Testing for epoch 36 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9677\n",
      "\n",
      "Testing for epoch 36 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9708\n",
      "Epoch 37 of 60\n",
      "\n",
      "Testing for epoch 37 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9783\n",
      "\n",
      "Testing for epoch 37 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9868\n",
      "\n",
      "Testing for epoch 37 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9781\n",
      "\n",
      "Testing for epoch 37 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9861\n",
      "\n",
      "Testing for epoch 37 index 5:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9865\n",
      "\n",
      "Testing for epoch 37 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9693\n",
      "\n",
      "Testing for epoch 37 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9823\n",
      "\n",
      "Testing for epoch 37 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9989\n",
      "\n",
      "Testing for epoch 37 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9909\n",
      "\n",
      "Testing for epoch 37 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9869\n",
      "\n",
      "Testing for epoch 37 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0000\n",
      "\n",
      "Testing for epoch 37 index 12:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9711\n",
      "\n",
      "Testing for epoch 37 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0097\n",
      "\n",
      "Testing for epoch 37 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9981\n",
      "\n",
      "Testing for epoch 37 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9801\n",
      "\n",
      "Testing for epoch 37 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0072\n",
      "\n",
      "Testing for epoch 37 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0137\n",
      "\n",
      "Testing for epoch 37 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9762\n",
      "\n",
      "Testing for epoch 37 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9980\n",
      "\n",
      "Testing for epoch 37 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0043\n",
      "\n",
      "Testing for epoch 37 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9868\n",
      "\n",
      "Testing for epoch 37 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0069\n",
      "\n",
      "Testing for epoch 37 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.0238\n",
      "\n",
      "Testing for epoch 37 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9904\n",
      "\n",
      "Testing for epoch 37 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0124\n",
      "\n",
      "Testing for epoch 37 index 26:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9861\n",
      "\n",
      "Testing for epoch 37 index 27:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 6.9901\n",
      "\n",
      "Testing for epoch 37 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9986\n",
      "\n",
      "Testing for epoch 37 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9967\n",
      "\n",
      "Testing for epoch 37 index 30:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.0223\n",
      "\n",
      "Testing for epoch 37 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9814\n",
      "\n",
      "Testing for epoch 37 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0020\n",
      "\n",
      "Testing for epoch 37 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0078\n",
      "\n",
      "Testing for epoch 37 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9962\n",
      "\n",
      "Testing for epoch 37 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0142\n",
      "\n",
      "Testing for epoch 37 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0056\n",
      "\n",
      "Testing for epoch 37 index 37:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.0366\n",
      "\n",
      "Testing for epoch 37 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0074\n",
      "\n",
      "Testing for epoch 37 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0430\n",
      "\n",
      "Testing for epoch 37 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0143\n",
      "\n",
      "Testing for epoch 37 index 41:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.0039\n",
      "\n",
      "Testing for epoch 37 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0261\n",
      "\n",
      "Testing for epoch 37 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0249\n",
      "\n",
      "Testing for epoch 37 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0204\n",
      "Epoch 38 of 60\n",
      "\n",
      "Testing for epoch 38 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0470\n",
      "\n",
      "Testing for epoch 38 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0180\n",
      "\n",
      "Testing for epoch 38 index 3:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0260\n",
      "\n",
      "Testing for epoch 38 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0225\n",
      "\n",
      "Testing for epoch 38 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0307\n",
      "\n",
      "Testing for epoch 38 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0405\n",
      "\n",
      "Testing for epoch 38 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0227\n",
      "\n",
      "Testing for epoch 38 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0284\n",
      "\n",
      "Testing for epoch 38 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0258\n",
      "\n",
      "Testing for epoch 38 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0283\n",
      "\n",
      "Testing for epoch 38 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0190\n",
      "\n",
      "Testing for epoch 38 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0361\n",
      "\n",
      "Testing for epoch 38 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0423\n",
      "\n",
      "Testing for epoch 38 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0394\n",
      "\n",
      "Testing for epoch 38 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0207\n",
      "\n",
      "Testing for epoch 38 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0441\n",
      "\n",
      "Testing for epoch 38 index 17:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.0609\n",
      "\n",
      "Testing for epoch 38 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0446\n",
      "\n",
      "Testing for epoch 38 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0254\n",
      "\n",
      "Testing for epoch 38 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0389\n",
      "\n",
      "Testing for epoch 38 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0522\n",
      "\n",
      "Testing for epoch 38 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0665\n",
      "\n",
      "Testing for epoch 38 index 23:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.0491\n",
      "\n",
      "Testing for epoch 38 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0550\n",
      "\n",
      "Testing for epoch 38 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0454\n",
      "\n",
      "Testing for epoch 38 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0589\n",
      "\n",
      "Testing for epoch 38 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0417\n",
      "\n",
      "Testing for epoch 38 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0567\n",
      "\n",
      "Testing for epoch 38 index 29:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.0645\n",
      "\n",
      "Testing for epoch 38 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0363\n",
      "\n",
      "Testing for epoch 38 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0786\n",
      "\n",
      "Testing for epoch 38 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0487\n",
      "\n",
      "Testing for epoch 38 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0518\n",
      "\n",
      "Testing for epoch 38 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0572\n",
      "\n",
      "Testing for epoch 38 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0704\n",
      "\n",
      "Testing for epoch 38 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0682\n",
      "\n",
      "Testing for epoch 38 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0665\n",
      "\n",
      "Testing for epoch 38 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0549\n",
      "\n",
      "Testing for epoch 38 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0794\n",
      "\n",
      "Testing for epoch 38 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0573\n",
      "\n",
      "Testing for epoch 38 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0779\n",
      "\n",
      "Testing for epoch 38 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0969\n",
      "\n",
      "Testing for epoch 38 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0722\n",
      "\n",
      "Testing for epoch 38 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0773\n",
      "Epoch 39 of 60\n",
      "\n",
      "Testing for epoch 39 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0667\n",
      "\n",
      "Testing for epoch 39 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0752\n",
      "\n",
      "Testing for epoch 39 index 3:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.0839\n",
      "\n",
      "Testing for epoch 39 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0836\n",
      "\n",
      "Testing for epoch 39 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0803\n",
      "\n",
      "Testing for epoch 39 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0795\n",
      "\n",
      "Testing for epoch 39 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0844\n",
      "\n",
      "Testing for epoch 39 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0788\n",
      "\n",
      "Testing for epoch 39 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0838\n",
      "\n",
      "Testing for epoch 39 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0944\n",
      "\n",
      "Testing for epoch 39 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0780\n",
      "\n",
      "Testing for epoch 39 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0957\n",
      "\n",
      "Testing for epoch 39 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1035\n",
      "\n",
      "Testing for epoch 39 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0881\n",
      "\n",
      "Testing for epoch 39 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0924\n",
      "\n",
      "Testing for epoch 39 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0841\n",
      "\n",
      "Testing for epoch 39 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1012\n",
      "\n",
      "Testing for epoch 39 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0644\n",
      "\n",
      "Testing for epoch 39 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0591\n",
      "\n",
      "Testing for epoch 39 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0786\n",
      "\n",
      "Testing for epoch 39 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1003\n",
      "\n",
      "Testing for epoch 39 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0953\n",
      "\n",
      "Testing for epoch 39 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0888\n",
      "\n",
      "Testing for epoch 39 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0942\n",
      "\n",
      "Testing for epoch 39 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.0990\n",
      "\n",
      "Testing for epoch 39 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1286\n",
      "\n",
      "Testing for epoch 39 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0748\n",
      "\n",
      "Testing for epoch 39 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1001\n",
      "\n",
      "Testing for epoch 39 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1168\n",
      "\n",
      "Testing for epoch 39 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1130\n",
      "\n",
      "Testing for epoch 39 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0958\n",
      "\n",
      "Testing for epoch 39 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1060\n",
      "\n",
      "Testing for epoch 39 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1073\n",
      "\n",
      "Testing for epoch 39 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1201\n",
      "\n",
      "Testing for epoch 39 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1087\n",
      "\n",
      "Testing for epoch 39 index 36:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.1233\n",
      "\n",
      "Testing for epoch 39 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1101\n",
      "\n",
      "Testing for epoch 39 index 38:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1053\n",
      "\n",
      "Testing for epoch 39 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1093\n",
      "\n",
      "Testing for epoch 39 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1088\n",
      "\n",
      "Testing for epoch 39 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1282\n",
      "\n",
      "Testing for epoch 39 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1187\n",
      "\n",
      "Testing for epoch 39 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1033\n",
      "\n",
      "Testing for epoch 39 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1198\n",
      "Epoch 40 of 60\n",
      "\n",
      "Testing for epoch 40 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0981\n",
      "\n",
      "Testing for epoch 40 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1334\n",
      "\n",
      "Testing for epoch 40 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1597\n",
      "\n",
      "Testing for epoch 40 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1178\n",
      "\n",
      "Testing for epoch 40 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1102\n",
      "\n",
      "Testing for epoch 40 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1244\n",
      "\n",
      "Testing for epoch 40 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1285\n",
      "\n",
      "Testing for epoch 40 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1231\n",
      "\n",
      "Testing for epoch 40 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1070\n",
      "\n",
      "Testing for epoch 40 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1385\n",
      "\n",
      "Testing for epoch 40 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1055\n",
      "\n",
      "Testing for epoch 40 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1208\n",
      "\n",
      "Testing for epoch 40 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1243\n",
      "\n",
      "Testing for epoch 40 index 14:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1203\n",
      "\n",
      "Testing for epoch 40 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1398\n",
      "\n",
      "Testing for epoch 40 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1438\n",
      "\n",
      "Testing for epoch 40 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1519\n",
      "\n",
      "Testing for epoch 40 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1457\n",
      "\n",
      "Testing for epoch 40 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1532\n",
      "\n",
      "Testing for epoch 40 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1216\n",
      "\n",
      "Testing for epoch 40 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1320\n",
      "\n",
      "Testing for epoch 40 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1241\n",
      "\n",
      "Testing for epoch 40 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1518\n",
      "\n",
      "Testing for epoch 40 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1409\n",
      "\n",
      "Testing for epoch 40 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1344\n",
      "\n",
      "Testing for epoch 40 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1477\n",
      "\n",
      "Testing for epoch 40 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1396\n",
      "\n",
      "Testing for epoch 40 index 28:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.1300\n",
      "\n",
      "Testing for epoch 40 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1378\n",
      "\n",
      "Testing for epoch 40 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1402\n",
      "\n",
      "Testing for epoch 40 index 31:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.1723\n",
      "\n",
      "Testing for epoch 40 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1406\n",
      "\n",
      "Testing for epoch 40 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1567\n",
      "\n",
      "Testing for epoch 40 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1526\n",
      "\n",
      "Testing for epoch 40 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1382\n",
      "\n",
      "Testing for epoch 40 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1472\n",
      "\n",
      "Testing for epoch 40 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1507\n",
      "\n",
      "Testing for epoch 40 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1474\n",
      "\n",
      "Testing for epoch 40 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1391\n",
      "\n",
      "Testing for epoch 40 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1533\n",
      "\n",
      "Testing for epoch 40 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1477\n",
      "\n",
      "Testing for epoch 40 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1651\n",
      "\n",
      "Testing for epoch 40 index 43:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.1522\n",
      "\n",
      "Testing for epoch 40 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1782\n",
      "Epoch 41 of 60\n",
      "\n",
      "Testing for epoch 41 index 1:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.1486\n",
      "\n",
      "Testing for epoch 41 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1761\n",
      "\n",
      "Testing for epoch 41 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1609\n",
      "\n",
      "Testing for epoch 41 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1550\n",
      "\n",
      "Testing for epoch 41 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1735\n",
      "\n",
      "Testing for epoch 41 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1416\n",
      "\n",
      "Testing for epoch 41 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1514\n",
      "\n",
      "Testing for epoch 41 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1690\n",
      "\n",
      "Testing for epoch 41 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1581\n",
      "\n",
      "Testing for epoch 41 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1998\n",
      "\n",
      "Testing for epoch 41 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1665\n",
      "\n",
      "Testing for epoch 41 index 12:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1698\n",
      "\n",
      "Testing for epoch 41 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1912\n",
      "\n",
      "Testing for epoch 41 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1664\n",
      "\n",
      "Testing for epoch 41 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1654\n",
      "\n",
      "Testing for epoch 41 index 16:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.1915\n",
      "\n",
      "Testing for epoch 41 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1676\n",
      "\n",
      "Testing for epoch 41 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1583\n",
      "\n",
      "Testing for epoch 41 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1492\n",
      "\n",
      "Testing for epoch 41 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1541\n",
      "\n",
      "Testing for epoch 41 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1689\n",
      "\n",
      "Testing for epoch 41 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1786\n",
      "\n",
      "Testing for epoch 41 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1641\n",
      "\n",
      "Testing for epoch 41 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1789\n",
      "\n",
      "Testing for epoch 41 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1762\n",
      "\n",
      "Testing for epoch 41 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1873\n",
      "\n",
      "Testing for epoch 41 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1759\n",
      "\n",
      "Testing for epoch 41 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1672\n",
      "\n",
      "Testing for epoch 41 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1720\n",
      "\n",
      "Testing for epoch 41 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1939\n",
      "\n",
      "Testing for epoch 41 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1861\n",
      "\n",
      "Testing for epoch 41 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2007\n",
      "\n",
      "Testing for epoch 41 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1853\n",
      "\n",
      "Testing for epoch 41 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1854\n",
      "\n",
      "Testing for epoch 41 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1931\n",
      "\n",
      "Testing for epoch 41 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1644\n",
      "\n",
      "Testing for epoch 41 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2100\n",
      "\n",
      "Testing for epoch 41 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1818\n",
      "\n",
      "Testing for epoch 41 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1896\n",
      "\n",
      "Testing for epoch 41 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2005\n",
      "\n",
      "Testing for epoch 41 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1990\n",
      "\n",
      "Testing for epoch 41 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1903\n",
      "\n",
      "Testing for epoch 41 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1804\n",
      "\n",
      "Testing for epoch 41 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1722\n",
      "Epoch 42 of 60\n",
      "\n",
      "Testing for epoch 42 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1863\n",
      "\n",
      "Testing for epoch 42 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.1857\n",
      "\n",
      "Testing for epoch 42 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1870\n",
      "\n",
      "Testing for epoch 42 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1875\n",
      "\n",
      "Testing for epoch 42 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2136\n",
      "\n",
      "Testing for epoch 42 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1942\n",
      "\n",
      "Testing for epoch 42 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2266\n",
      "\n",
      "Testing for epoch 42 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2098\n",
      "\n",
      "Testing for epoch 42 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2172\n",
      "\n",
      "Testing for epoch 42 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2210\n",
      "\n",
      "Testing for epoch 42 index 11:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.1923\n",
      "\n",
      "Testing for epoch 42 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1994\n",
      "\n",
      "Testing for epoch 42 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1996\n",
      "\n",
      "Testing for epoch 42 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2081\n",
      "\n",
      "Testing for epoch 42 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2083\n",
      "\n",
      "Testing for epoch 42 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2216\n",
      "\n",
      "Testing for epoch 42 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2181\n",
      "\n",
      "Testing for epoch 42 index 18:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.2220\n",
      "\n",
      "Testing for epoch 42 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2235\n",
      "\n",
      "Testing for epoch 42 index 20:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2035\n",
      "\n",
      "Testing for epoch 42 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2288\n",
      "\n",
      "Testing for epoch 42 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2075\n",
      "\n",
      "Testing for epoch 42 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2217\n",
      "\n",
      "Testing for epoch 42 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2345\n",
      "\n",
      "Testing for epoch 42 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2192\n",
      "\n",
      "Testing for epoch 42 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2372\n",
      "\n",
      "Testing for epoch 42 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2101\n",
      "\n",
      "Testing for epoch 42 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2262\n",
      "\n",
      "Testing for epoch 42 index 29:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.2097\n",
      "\n",
      "Testing for epoch 42 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2421\n",
      "\n",
      "Testing for epoch 42 index 31:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2150\n",
      "\n",
      "Testing for epoch 42 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2219\n",
      "\n",
      "Testing for epoch 42 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2174\n",
      "\n",
      "Testing for epoch 42 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2271\n",
      "\n",
      "Testing for epoch 42 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2241\n",
      "\n",
      "Testing for epoch 42 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2257\n",
      "\n",
      "Testing for epoch 42 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2543\n",
      "\n",
      "Testing for epoch 42 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2616\n",
      "\n",
      "Testing for epoch 42 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2328\n",
      "\n",
      "Testing for epoch 42 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2302\n",
      "\n",
      "Testing for epoch 42 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2248\n",
      "\n",
      "Testing for epoch 42 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2312\n",
      "\n",
      "Testing for epoch 42 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2211\n",
      "\n",
      "Testing for epoch 42 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2352\n",
      "Epoch 43 of 60\n",
      "\n",
      "Testing for epoch 43 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2623\n",
      "\n",
      "Testing for epoch 43 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2380\n",
      "\n",
      "Testing for epoch 43 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2347\n",
      "\n",
      "Testing for epoch 43 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2284\n",
      "\n",
      "Testing for epoch 43 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2565\n",
      "\n",
      "Testing for epoch 43 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2333\n",
      "\n",
      "Testing for epoch 43 index 7:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2452\n",
      "\n",
      "Testing for epoch 43 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2334\n",
      "\n",
      "Testing for epoch 43 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2518\n",
      "\n",
      "Testing for epoch 43 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2621\n",
      "\n",
      "Testing for epoch 43 index 11:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.2565\n",
      "\n",
      "Testing for epoch 43 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2379\n",
      "\n",
      "Testing for epoch 43 index 13:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2641\n",
      "\n",
      "Testing for epoch 43 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2494\n",
      "\n",
      "Testing for epoch 43 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2672\n",
      "\n",
      "Testing for epoch 43 index 16:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2692\n",
      "\n",
      "Testing for epoch 43 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2390\n",
      "\n",
      "Testing for epoch 43 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2726\n",
      "\n",
      "Testing for epoch 43 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2328\n",
      "\n",
      "Testing for epoch 43 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2728\n",
      "\n",
      "Testing for epoch 43 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2745\n",
      "\n",
      "Testing for epoch 43 index 22:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2545\n",
      "\n",
      "Testing for epoch 43 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2670\n",
      "\n",
      "Testing for epoch 43 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2612\n",
      "\n",
      "Testing for epoch 43 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2504\n",
      "\n",
      "Testing for epoch 43 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2714\n",
      "\n",
      "Testing for epoch 43 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2469\n",
      "\n",
      "Testing for epoch 43 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2691\n",
      "\n",
      "Testing for epoch 43 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2387\n",
      "\n",
      "Testing for epoch 43 index 30:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2724\n",
      "\n",
      "Testing for epoch 43 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2753\n",
      "\n",
      "Testing for epoch 43 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2544\n",
      "\n",
      "Testing for epoch 43 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2661\n",
      "\n",
      "Testing for epoch 43 index 34:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2808\n",
      "\n",
      "Testing for epoch 43 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2462\n",
      "\n",
      "Testing for epoch 43 index 36:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2469\n",
      "\n",
      "Testing for epoch 43 index 37:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2613\n",
      "\n",
      "Testing for epoch 43 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2732\n",
      "\n",
      "Testing for epoch 43 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2805\n",
      "\n",
      "Testing for epoch 43 index 40:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2716\n",
      "\n",
      "Testing for epoch 43 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2726\n",
      "\n",
      "Testing for epoch 43 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2669\n",
      "\n",
      "Testing for epoch 43 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2768\n",
      "\n",
      "Testing for epoch 43 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2727\n",
      "Epoch 44 of 60\n",
      "\n",
      "Testing for epoch 44 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2818\n",
      "\n",
      "Testing for epoch 44 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2427\n",
      "\n",
      "Testing for epoch 44 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2528\n",
      "\n",
      "Testing for epoch 44 index 4:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2615\n",
      "\n",
      "Testing for epoch 44 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2804\n",
      "\n",
      "Testing for epoch 44 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3000\n",
      "\n",
      "Testing for epoch 44 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2848\n",
      "\n",
      "Testing for epoch 44 index 8:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2805\n",
      "\n",
      "Testing for epoch 44 index 9:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2882\n",
      "\n",
      "Testing for epoch 44 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2810\n",
      "\n",
      "Testing for epoch 44 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2921\n",
      "\n",
      "Testing for epoch 44 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2964\n",
      "\n",
      "Testing for epoch 44 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2721\n",
      "\n",
      "Testing for epoch 44 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2963\n",
      "\n",
      "Testing for epoch 44 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2844\n",
      "\n",
      "Testing for epoch 44 index 16:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2821\n",
      "\n",
      "Testing for epoch 44 index 17:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.2768\n",
      "\n",
      "Testing for epoch 44 index 18:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2778\n",
      "\n",
      "Testing for epoch 44 index 19:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2965\n",
      "\n",
      "Testing for epoch 44 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2959\n",
      "\n",
      "Testing for epoch 44 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2870\n",
      "\n",
      "Testing for epoch 44 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3022\n",
      "\n",
      "Testing for epoch 44 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2747\n",
      "\n",
      "Testing for epoch 44 index 24:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.2776\n",
      "\n",
      "Testing for epoch 44 index 25:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.3087\n",
      "\n",
      "Testing for epoch 44 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3002\n",
      "\n",
      "Testing for epoch 44 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2734\n",
      "\n",
      "Testing for epoch 44 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2985\n",
      "\n",
      "Testing for epoch 44 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3003\n",
      "\n",
      "Testing for epoch 44 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2960\n",
      "\n",
      "Testing for epoch 44 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2961\n",
      "\n",
      "Testing for epoch 44 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3094\n",
      "\n",
      "Testing for epoch 44 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3004\n",
      "\n",
      "Testing for epoch 44 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2873\n",
      "\n",
      "Testing for epoch 44 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3110\n",
      "\n",
      "Testing for epoch 44 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2889\n",
      "\n",
      "Testing for epoch 44 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2868\n",
      "\n",
      "Testing for epoch 44 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3162\n",
      "\n",
      "Testing for epoch 44 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3180\n",
      "\n",
      "Testing for epoch 44 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3053\n",
      "\n",
      "Testing for epoch 44 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3082\n",
      "\n",
      "Testing for epoch 44 index 42:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing for epoch 44 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3177\n",
      "\n",
      "Testing for epoch 44 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3117\n",
      "Epoch 45 of 60\n",
      "\n",
      "Testing for epoch 45 index 1:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.2834\n",
      "\n",
      "Testing for epoch 45 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3220\n",
      "\n",
      "Testing for epoch 45 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3181\n",
      "\n",
      "Testing for epoch 45 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3149\n",
      "\n",
      "Testing for epoch 45 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2916\n",
      "\n",
      "Testing for epoch 45 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3184\n",
      "\n",
      "Testing for epoch 45 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.2846\n",
      "\n",
      "Testing for epoch 45 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3080\n",
      "\n",
      "Testing for epoch 45 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3140\n",
      "\n",
      "Testing for epoch 45 index 10:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.3075\n",
      "\n",
      "Testing for epoch 45 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3238\n",
      "\n",
      "Testing for epoch 45 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3068\n",
      "\n",
      "Testing for epoch 45 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3150\n",
      "\n",
      "Testing for epoch 45 index 14:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.3388\n",
      "\n",
      "Testing for epoch 45 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3402\n",
      "\n",
      "Testing for epoch 45 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3231\n",
      "\n",
      "Testing for epoch 45 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3095\n",
      "\n",
      "Testing for epoch 45 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3376\n",
      "\n",
      "Testing for epoch 45 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3360\n",
      "\n",
      "Testing for epoch 45 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3145\n",
      "\n",
      "Testing for epoch 45 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3228\n",
      "\n",
      "Testing for epoch 45 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3252\n",
      "\n",
      "Testing for epoch 45 index 23:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.3266\n",
      "\n",
      "Testing for epoch 45 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3391\n",
      "\n",
      "Testing for epoch 45 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3303\n",
      "\n",
      "Testing for epoch 45 index 26:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3330\n",
      "\n",
      "Testing for epoch 45 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3307\n",
      "\n",
      "Testing for epoch 45 index 28:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.3605\n",
      "\n",
      "Testing for epoch 45 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3387\n",
      "\n",
      "Testing for epoch 45 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3255\n",
      "\n",
      "Testing for epoch 45 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3381\n",
      "\n",
      "Testing for epoch 45 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3344\n",
      "\n",
      "Testing for epoch 45 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3374\n",
      "\n",
      "Testing for epoch 45 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3159\n",
      "\n",
      "Testing for epoch 45 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3322\n",
      "\n",
      "Testing for epoch 45 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3407\n",
      "\n",
      "Testing for epoch 45 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3435\n",
      "\n",
      "Testing for epoch 45 index 38:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3655\n",
      "\n",
      "Testing for epoch 45 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3446\n",
      "\n",
      "Testing for epoch 45 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3524\n",
      "\n",
      "Testing for epoch 45 index 41:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.3222\n",
      "\n",
      "Testing for epoch 45 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3483\n",
      "\n",
      "Testing for epoch 45 index 43:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.3378\n",
      "\n",
      "Testing for epoch 45 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3640\n",
      "Epoch 46 of 60\n",
      "\n",
      "Testing for epoch 46 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3574\n",
      "\n",
      "Testing for epoch 46 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3422\n",
      "\n",
      "Testing for epoch 46 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3271\n",
      "\n",
      "Testing for epoch 46 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3463\n",
      "\n",
      "Testing for epoch 46 index 5:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3331\n",
      "\n",
      "Testing for epoch 46 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3626\n",
      "\n",
      "Testing for epoch 46 index 7:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.3520\n",
      "\n",
      "Testing for epoch 46 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3163\n",
      "\n",
      "Testing for epoch 46 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3447\n",
      "\n",
      "Testing for epoch 46 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3689\n",
      "\n",
      "Testing for epoch 46 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3559\n",
      "\n",
      "Testing for epoch 46 index 12:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3755\n",
      "\n",
      "Testing for epoch 46 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3501\n",
      "\n",
      "Testing for epoch 46 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3735\n",
      "\n",
      "Testing for epoch 46 index 15:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3694\n",
      "\n",
      "Testing for epoch 46 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3570\n",
      "\n",
      "Testing for epoch 46 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3579\n",
      "\n",
      "Testing for epoch 46 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3567\n",
      "\n",
      "Testing for epoch 46 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3492\n",
      "\n",
      "Testing for epoch 46 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3412\n",
      "\n",
      "Testing for epoch 46 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3801\n",
      "\n",
      "Testing for epoch 46 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3451\n",
      "\n",
      "Testing for epoch 46 index 23:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.3384\n",
      "\n",
      "Testing for epoch 46 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3577\n",
      "\n",
      "Testing for epoch 46 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3674\n",
      "\n",
      "Testing for epoch 46 index 26:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3604\n",
      "\n",
      "Testing for epoch 46 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3727\n",
      "\n",
      "Testing for epoch 46 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3695\n",
      "\n",
      "Testing for epoch 46 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3727\n",
      "\n",
      "Testing for epoch 46 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3555\n",
      "\n",
      "Testing for epoch 46 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3674\n",
      "\n",
      "Testing for epoch 46 index 32:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3734\n",
      "\n",
      "Testing for epoch 46 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3553\n",
      "\n",
      "Testing for epoch 46 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3640\n",
      "\n",
      "Testing for epoch 46 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3668\n",
      "\n",
      "Testing for epoch 46 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3841\n",
      "\n",
      "Testing for epoch 46 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3689\n",
      "\n",
      "Testing for epoch 46 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3636\n",
      "\n",
      "Testing for epoch 46 index 39:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3564\n",
      "\n",
      "Testing for epoch 46 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3635\n",
      "\n",
      "Testing for epoch 46 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3526\n",
      "\n",
      "Testing for epoch 46 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3700\n",
      "\n",
      "Testing for epoch 46 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3647\n",
      "\n",
      "Testing for epoch 46 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3618\n",
      "Epoch 47 of 60\n",
      "\n",
      "Testing for epoch 47 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3968\n",
      "\n",
      "Testing for epoch 47 index 2:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.3588\n",
      "\n",
      "Testing for epoch 47 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3922\n",
      "\n",
      "Testing for epoch 47 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3999\n",
      "\n",
      "Testing for epoch 47 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3548\n",
      "\n",
      "Testing for epoch 47 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3755\n",
      "\n",
      "Testing for epoch 47 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4151\n",
      "\n",
      "Testing for epoch 47 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4076\n",
      "\n",
      "Testing for epoch 47 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3781\n",
      "\n",
      "Testing for epoch 47 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3954\n",
      "\n",
      "Testing for epoch 47 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4115\n",
      "\n",
      "Testing for epoch 47 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3937\n",
      "\n",
      "Testing for epoch 47 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3870\n",
      "\n",
      "Testing for epoch 47 index 14:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.4012\n",
      "\n",
      "Testing for epoch 47 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4052\n",
      "\n",
      "Testing for epoch 47 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4106\n",
      "\n",
      "Testing for epoch 47 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3904\n",
      "\n",
      "Testing for epoch 47 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.3882\n",
      "\n",
      "Testing for epoch 47 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4034\n",
      "\n",
      "Testing for epoch 47 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4033\n",
      "\n",
      "Testing for epoch 47 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4000\n",
      "\n",
      "Testing for epoch 47 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3796\n",
      "\n",
      "Testing for epoch 47 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3886\n",
      "\n",
      "Testing for epoch 47 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3670\n",
      "\n",
      "Testing for epoch 47 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3933\n",
      "\n",
      "Testing for epoch 47 index 26:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.3954\n",
      "\n",
      "Testing for epoch 47 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3875\n",
      "\n",
      "Testing for epoch 47 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3696\n",
      "\n",
      "Testing for epoch 47 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3964\n",
      "\n",
      "Testing for epoch 47 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4266\n",
      "\n",
      "Testing for epoch 47 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4206\n",
      "\n",
      "Testing for epoch 47 index 32:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4151\n",
      "\n",
      "Testing for epoch 47 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3951\n",
      "\n",
      "Testing for epoch 47 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4054\n",
      "\n",
      "Testing for epoch 47 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3887\n",
      "\n",
      "Testing for epoch 47 index 36:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4173\n",
      "\n",
      "Testing for epoch 47 index 37:\n",
      "16/16 [==============================] - 0s 885us/step - loss: 7.4017\n",
      "\n",
      "Testing for epoch 47 index 38:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4319\n",
      "\n",
      "Testing for epoch 47 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4268\n",
      "\n",
      "Testing for epoch 47 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4010\n",
      "\n",
      "Testing for epoch 47 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4240\n",
      "\n",
      "Testing for epoch 47 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4080\n",
      "\n",
      "Testing for epoch 47 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4205\n",
      "\n",
      "Testing for epoch 47 index 44:\n",
      "16/16 [==============================] - 0s 933us/step - loss: 7.4256\n",
      "Epoch 48 of 60\n",
      "\n",
      "Testing for epoch 48 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.3788\n",
      "\n",
      "Testing for epoch 48 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4083\n",
      "\n",
      "Testing for epoch 48 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4124\n",
      "\n",
      "Testing for epoch 48 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4056\n",
      "\n",
      "Testing for epoch 48 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4184\n",
      "\n",
      "Testing for epoch 48 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4253\n",
      "\n",
      "Testing for epoch 48 index 7:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.4058\n",
      "\n",
      "Testing for epoch 48 index 8:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4028\n",
      "\n",
      "Testing for epoch 48 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4226\n",
      "\n",
      "Testing for epoch 48 index 10:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4155\n",
      "\n",
      "Testing for epoch 48 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4417\n",
      "\n",
      "Testing for epoch 48 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4297\n",
      "\n",
      "Testing for epoch 48 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4132\n",
      "\n",
      "Testing for epoch 48 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4059\n",
      "\n",
      "Testing for epoch 48 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4184\n",
      "\n",
      "Testing for epoch 48 index 16:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4264\n",
      "\n",
      "Testing for epoch 48 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4200\n",
      "\n",
      "Testing for epoch 48 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4282\n",
      "\n",
      "Testing for epoch 48 index 19:\n",
      "16/16 [==============================] - 0s 933us/step - loss: 7.4253\n",
      "\n",
      "Testing for epoch 48 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4458\n",
      "\n",
      "Testing for epoch 48 index 21:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4312\n",
      "\n",
      "Testing for epoch 48 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4341\n",
      "\n",
      "Testing for epoch 48 index 23:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.4173\n",
      "\n",
      "Testing for epoch 48 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4376\n",
      "\n",
      "Testing for epoch 48 index 25:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4384\n",
      "\n",
      "Testing for epoch 48 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4301\n",
      "\n",
      "Testing for epoch 48 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4395\n",
      "\n",
      "Testing for epoch 48 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4425\n",
      "\n",
      "Testing for epoch 48 index 29:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4389\n",
      "\n",
      "Testing for epoch 48 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4470\n",
      "\n",
      "Testing for epoch 48 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4182\n",
      "\n",
      "Testing for epoch 48 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4365\n",
      "\n",
      "Testing for epoch 48 index 33:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4541\n",
      "\n",
      "Testing for epoch 48 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4167\n",
      "\n",
      "Testing for epoch 48 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4562\n",
      "\n",
      "Testing for epoch 48 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4426\n",
      "\n",
      "Testing for epoch 48 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4547\n",
      "\n",
      "Testing for epoch 48 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4304\n",
      "\n",
      "Testing for epoch 48 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4191\n",
      "\n",
      "Testing for epoch 48 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4552\n",
      "\n",
      "Testing for epoch 48 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4561\n",
      "\n",
      "Testing for epoch 48 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4209\n",
      "\n",
      "Testing for epoch 48 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4684\n",
      "\n",
      "Testing for epoch 48 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4412\n",
      "Epoch 49 of 60\n",
      "\n",
      "Testing for epoch 49 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4372\n",
      "\n",
      "Testing for epoch 49 index 2:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4405\n",
      "\n",
      "Testing for epoch 49 index 3:\n",
      "16/16 [==============================] - 0s 933us/step - loss: 7.4540\n",
      "\n",
      "Testing for epoch 49 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4745\n",
      "\n",
      "Testing for epoch 49 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4469\n",
      "\n",
      "Testing for epoch 49 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4508\n",
      "\n",
      "Testing for epoch 49 index 7:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4447\n",
      "\n",
      "Testing for epoch 49 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4580\n",
      "\n",
      "Testing for epoch 49 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4282\n",
      "\n",
      "Testing for epoch 49 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4372\n",
      "\n",
      "Testing for epoch 49 index 11:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.4511\n",
      "\n",
      "Testing for epoch 49 index 12:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4663\n",
      "\n",
      "Testing for epoch 49 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4385\n",
      "\n",
      "Testing for epoch 49 index 14:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4579\n",
      "\n",
      "Testing for epoch 49 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4480\n",
      "\n",
      "Testing for epoch 49 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4712\n",
      "\n",
      "Testing for epoch 49 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4475\n",
      "\n",
      "Testing for epoch 49 index 18:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.4478\n",
      "\n",
      "Testing for epoch 49 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4678\n",
      "\n",
      "Testing for epoch 49 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4489\n",
      "\n",
      "Testing for epoch 49 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4418\n",
      "\n",
      "Testing for epoch 49 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4529\n",
      "\n",
      "Testing for epoch 49 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4503\n",
      "\n",
      "Testing for epoch 49 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4512\n",
      "\n",
      "Testing for epoch 49 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4455\n",
      "\n",
      "Testing for epoch 49 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4650\n",
      "\n",
      "Testing for epoch 49 index 27:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4756\n",
      "\n",
      "Testing for epoch 49 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4521\n",
      "\n",
      "Testing for epoch 49 index 29:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.4686\n",
      "\n",
      "Testing for epoch 49 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4447\n",
      "\n",
      "Testing for epoch 49 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4438\n",
      "\n",
      "Testing for epoch 49 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4654\n",
      "\n",
      "Testing for epoch 49 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4368\n",
      "\n",
      "Testing for epoch 49 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4585\n",
      "\n",
      "Testing for epoch 49 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4753\n",
      "\n",
      "Testing for epoch 49 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4748\n",
      "\n",
      "Testing for epoch 49 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4810\n",
      "\n",
      "Testing for epoch 49 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4555\n",
      "\n",
      "Testing for epoch 49 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4730\n",
      "\n",
      "Testing for epoch 49 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4503\n",
      "\n",
      "Testing for epoch 49 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4406\n",
      "\n",
      "Testing for epoch 49 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5007\n",
      "\n",
      "Testing for epoch 49 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4505\n",
      "\n",
      "Testing for epoch 49 index 44:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4662\n",
      "Epoch 50 of 60\n",
      "\n",
      "Testing for epoch 50 index 1:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4729\n",
      "\n",
      "Testing for epoch 50 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4522\n",
      "\n",
      "Testing for epoch 50 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4641\n",
      "\n",
      "Testing for epoch 50 index 4:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4749\n",
      "\n",
      "Testing for epoch 50 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4916\n",
      "\n",
      "Testing for epoch 50 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4805\n",
      "\n",
      "Testing for epoch 50 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4868\n",
      "\n",
      "Testing for epoch 50 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4876\n",
      "\n",
      "Testing for epoch 50 index 9:\n",
      "16/16 [==============================] - 0s 995us/step - loss: 7.4710\n",
      "\n",
      "Testing for epoch 50 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4591\n",
      "\n",
      "Testing for epoch 50 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4795\n",
      "\n",
      "Testing for epoch 50 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5136\n",
      "\n",
      "Testing for epoch 50 index 13:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4709\n",
      "\n",
      "Testing for epoch 50 index 14:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.4731\n",
      "\n",
      "Testing for epoch 50 index 15:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4761\n",
      "\n",
      "Testing for epoch 50 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4870\n",
      "\n",
      "Testing for epoch 50 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4743\n",
      "\n",
      "Testing for epoch 50 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.4668\n",
      "\n",
      "Testing for epoch 50 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4780\n",
      "\n",
      "Testing for epoch 50 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4687\n",
      "\n",
      "Testing for epoch 50 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4655\n",
      "\n",
      "Testing for epoch 50 index 22:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.4890\n",
      "\n",
      "Testing for epoch 50 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4680\n",
      "\n",
      "Testing for epoch 50 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4878\n",
      "\n",
      "Testing for epoch 50 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4562\n",
      "\n",
      "Testing for epoch 50 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4700\n",
      "\n",
      "Testing for epoch 50 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4954\n",
      "\n",
      "Testing for epoch 50 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4703\n",
      "\n",
      "Testing for epoch 50 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4815\n",
      "\n",
      "Testing for epoch 50 index 30:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.4641\n",
      "\n",
      "Testing for epoch 50 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4863\n",
      "\n",
      "Testing for epoch 50 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4888\n",
      "\n",
      "Testing for epoch 50 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4957\n",
      "\n",
      "Testing for epoch 50 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5050\n",
      "\n",
      "Testing for epoch 50 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5132\n",
      "\n",
      "Testing for epoch 50 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5097\n",
      "\n",
      "Testing for epoch 50 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4884\n",
      "\n",
      "Testing for epoch 50 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5011\n",
      "\n",
      "Testing for epoch 50 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5050\n",
      "\n",
      "Testing for epoch 50 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5114\n",
      "\n",
      "Testing for epoch 50 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4828\n",
      "\n",
      "Testing for epoch 50 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4912\n",
      "\n",
      "Testing for epoch 50 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5017\n",
      "\n",
      "Testing for epoch 50 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4812\n",
      "Epoch 51 of 60\n",
      "\n",
      "Testing for epoch 51 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4973\n",
      "\n",
      "Testing for epoch 51 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4891\n",
      "\n",
      "Testing for epoch 51 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4965\n",
      "\n",
      "Testing for epoch 51 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5287\n",
      "\n",
      "Testing for epoch 51 index 5:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5012\n",
      "\n",
      "Testing for epoch 51 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5124\n",
      "\n",
      "Testing for epoch 51 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5192\n",
      "\n",
      "Testing for epoch 51 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5040\n",
      "\n",
      "Testing for epoch 51 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5476\n",
      "\n",
      "Testing for epoch 51 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5108\n",
      "\n",
      "Testing for epoch 51 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4890\n",
      "\n",
      "Testing for epoch 51 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4737\n",
      "\n",
      "Testing for epoch 51 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5147\n",
      "\n",
      "Testing for epoch 51 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4906\n",
      "\n",
      "Testing for epoch 51 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4966\n",
      "\n",
      "Testing for epoch 51 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5315\n",
      "\n",
      "Testing for epoch 51 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5181\n",
      "\n",
      "Testing for epoch 51 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4968\n",
      "\n",
      "Testing for epoch 51 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5148\n",
      "\n",
      "Testing for epoch 51 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5166\n",
      "\n",
      "Testing for epoch 51 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5551\n",
      "\n",
      "Testing for epoch 51 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4891\n",
      "\n",
      "Testing for epoch 51 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5322\n",
      "\n",
      "Testing for epoch 51 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5052\n",
      "\n",
      "Testing for epoch 51 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5052\n",
      "\n",
      "Testing for epoch 51 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5229\n",
      "\n",
      "Testing for epoch 51 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5395\n",
      "\n",
      "Testing for epoch 51 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5300\n",
      "\n",
      "Testing for epoch 51 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5314\n",
      "\n",
      "Testing for epoch 51 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5260\n",
      "\n",
      "Testing for epoch 51 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5184\n",
      "\n",
      "Testing for epoch 51 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5413\n",
      "\n",
      "Testing for epoch 51 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5331\n",
      "\n",
      "Testing for epoch 51 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5380\n",
      "\n",
      "Testing for epoch 51 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5105\n",
      "\n",
      "Testing for epoch 51 index 36:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5240\n",
      "\n",
      "Testing for epoch 51 index 37:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.5372\n",
      "\n",
      "Testing for epoch 51 index 38:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5049\n",
      "\n",
      "Testing for epoch 51 index 39:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.5233\n",
      "\n",
      "Testing for epoch 51 index 40:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.5315\n",
      "\n",
      "Testing for epoch 51 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5127\n",
      "\n",
      "Testing for epoch 51 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5046\n",
      "\n",
      "Testing for epoch 51 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5220\n",
      "\n",
      "Testing for epoch 51 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5439\n",
      "Epoch 52 of 60\n",
      "\n",
      "Testing for epoch 52 index 1:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5356\n",
      "\n",
      "Testing for epoch 52 index 2:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.5028\n",
      "\n",
      "Testing for epoch 52 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5131\n",
      "\n",
      "Testing for epoch 52 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5388\n",
      "\n",
      "Testing for epoch 52 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5219\n",
      "\n",
      "Testing for epoch 52 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5322\n",
      "\n",
      "Testing for epoch 52 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5335\n",
      "\n",
      "Testing for epoch 52 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5161\n",
      "\n",
      "Testing for epoch 52 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5379\n",
      "\n",
      "Testing for epoch 52 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5513\n",
      "\n",
      "Testing for epoch 52 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5211\n",
      "\n",
      "Testing for epoch 52 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5246\n",
      "\n",
      "Testing for epoch 52 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5392\n",
      "\n",
      "Testing for epoch 52 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5646\n",
      "\n",
      "Testing for epoch 52 index 15:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5414\n",
      "\n",
      "Testing for epoch 52 index 16:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5477\n",
      "\n",
      "Testing for epoch 52 index 17:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5331\n",
      "\n",
      "Testing for epoch 52 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5616\n",
      "\n",
      "Testing for epoch 52 index 19:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5423\n",
      "\n",
      "Testing for epoch 52 index 20:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5295\n",
      "\n",
      "Testing for epoch 52 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5421\n",
      "\n",
      "Testing for epoch 52 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5496\n",
      "\n",
      "Testing for epoch 52 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5670\n",
      "\n",
      "Testing for epoch 52 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5341\n",
      "\n",
      "Testing for epoch 52 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5296\n",
      "\n",
      "Testing for epoch 52 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5607\n",
      "\n",
      "Testing for epoch 52 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5411\n",
      "\n",
      "Testing for epoch 52 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5459\n",
      "\n",
      "Testing for epoch 52 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5519\n",
      "\n",
      "Testing for epoch 52 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5393\n",
      "\n",
      "Testing for epoch 52 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5467\n",
      "\n",
      "Testing for epoch 52 index 32:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5510\n",
      "\n",
      "Testing for epoch 52 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5512\n",
      "\n",
      "Testing for epoch 52 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5347\n",
      "\n",
      "Testing for epoch 52 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5562\n",
      "\n",
      "Testing for epoch 52 index 36:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.5408\n",
      "\n",
      "Testing for epoch 52 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5456\n",
      "\n",
      "Testing for epoch 52 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5464\n",
      "\n",
      "Testing for epoch 52 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5712\n",
      "\n",
      "Testing for epoch 52 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5484\n",
      "\n",
      "Testing for epoch 52 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5667\n",
      "\n",
      "Testing for epoch 52 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5367\n",
      "\n",
      "Testing for epoch 52 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5443\n",
      "\n",
      "Testing for epoch 52 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5872\n",
      "Epoch 53 of 60\n",
      "\n",
      "Testing for epoch 53 index 1:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.5764\n",
      "\n",
      "Testing for epoch 53 index 2:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.5555\n",
      "\n",
      "Testing for epoch 53 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5391\n",
      "\n",
      "Testing for epoch 53 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5635\n",
      "\n",
      "Testing for epoch 53 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5779\n",
      "\n",
      "Testing for epoch 53 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5599\n",
      "\n",
      "Testing for epoch 53 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5574\n",
      "\n",
      "Testing for epoch 53 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5900\n",
      "\n",
      "Testing for epoch 53 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5735\n",
      "\n",
      "Testing for epoch 53 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5576\n",
      "\n",
      "Testing for epoch 53 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5544\n",
      "\n",
      "Testing for epoch 53 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5464\n",
      "\n",
      "Testing for epoch 53 index 13:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5605\n",
      "\n",
      "Testing for epoch 53 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5440\n",
      "\n",
      "Testing for epoch 53 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5679\n",
      "\n",
      "Testing for epoch 53 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5561\n",
      "\n",
      "Testing for epoch 53 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5646\n",
      "\n",
      "Testing for epoch 53 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5754\n",
      "\n",
      "Testing for epoch 53 index 19:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.5727\n",
      "\n",
      "Testing for epoch 53 index 20:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.5618\n",
      "\n",
      "Testing for epoch 53 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5398\n",
      "\n",
      "Testing for epoch 53 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5755\n",
      "\n",
      "Testing for epoch 53 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5665\n",
      "\n",
      "Testing for epoch 53 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5629\n",
      "\n",
      "Testing for epoch 53 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5843\n",
      "\n",
      "Testing for epoch 53 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5535\n",
      "\n",
      "Testing for epoch 53 index 27:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.5682\n",
      "\n",
      "Testing for epoch 53 index 28:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5506\n",
      "\n",
      "Testing for epoch 53 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5884\n",
      "\n",
      "Testing for epoch 53 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5756\n",
      "\n",
      "Testing for epoch 53 index 31:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5724\n",
      "\n",
      "Testing for epoch 53 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6050\n",
      "\n",
      "Testing for epoch 53 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6001\n",
      "\n",
      "Testing for epoch 53 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5731\n",
      "\n",
      "Testing for epoch 53 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5994\n",
      "\n",
      "Testing for epoch 53 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5909\n",
      "\n",
      "Testing for epoch 53 index 37:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5745\n",
      "\n",
      "Testing for epoch 53 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5878\n",
      "\n",
      "Testing for epoch 53 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5688\n",
      "\n",
      "Testing for epoch 53 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5990\n",
      "\n",
      "Testing for epoch 53 index 41:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5629\n",
      "\n",
      "Testing for epoch 53 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5844\n",
      "\n",
      "Testing for epoch 53 index 43:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5709\n",
      "\n",
      "Testing for epoch 53 index 44:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5897\n",
      "Epoch 54 of 60\n",
      "\n",
      "Testing for epoch 54 index 1:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5938\n",
      "\n",
      "Testing for epoch 54 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5926\n",
      "\n",
      "Testing for epoch 54 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5975\n",
      "\n",
      "Testing for epoch 54 index 4:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.5800\n",
      "\n",
      "Testing for epoch 54 index 5:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6036\n",
      "\n",
      "Testing for epoch 54 index 6:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5726\n",
      "\n",
      "Testing for epoch 54 index 7:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5611\n",
      "\n",
      "Testing for epoch 54 index 8:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5921\n",
      "\n",
      "Testing for epoch 54 index 9:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5817\n",
      "\n",
      "Testing for epoch 54 index 10:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.5940\n",
      "\n",
      "Testing for epoch 54 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5685\n",
      "\n",
      "Testing for epoch 54 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5829\n",
      "\n",
      "Testing for epoch 54 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5782\n",
      "\n",
      "Testing for epoch 54 index 14:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5932\n",
      "\n",
      "Testing for epoch 54 index 15:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6049\n",
      "\n",
      "Testing for epoch 54 index 16:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6267\n",
      "\n",
      "Testing for epoch 54 index 17:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6041\n",
      "\n",
      "Testing for epoch 54 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5704\n",
      "\n",
      "Testing for epoch 54 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5697\n",
      "\n",
      "Testing for epoch 54 index 20:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5662\n",
      "\n",
      "Testing for epoch 54 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6110\n",
      "\n",
      "Testing for epoch 54 index 22:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6105\n",
      "\n",
      "Testing for epoch 54 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6040\n",
      "\n",
      "Testing for epoch 54 index 24:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5763\n",
      "\n",
      "Testing for epoch 54 index 25:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6004\n",
      "\n",
      "Testing for epoch 54 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5983\n",
      "\n",
      "Testing for epoch 54 index 27:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5978\n",
      "\n",
      "Testing for epoch 54 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5775\n",
      "\n",
      "Testing for epoch 54 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5845\n",
      "\n",
      "Testing for epoch 54 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5814\n",
      "\n",
      "Testing for epoch 54 index 31:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.6169\n",
      "\n",
      "Testing for epoch 54 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5879\n",
      "\n",
      "Testing for epoch 54 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5836\n",
      "\n",
      "Testing for epoch 54 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6034\n",
      "\n",
      "Testing for epoch 54 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5886\n",
      "\n",
      "Testing for epoch 54 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5859\n",
      "\n",
      "Testing for epoch 54 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6044\n",
      "\n",
      "Testing for epoch 54 index 38:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6003\n",
      "\n",
      "Testing for epoch 54 index 39:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6191\n",
      "\n",
      "Testing for epoch 54 index 40:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6146\n",
      "\n",
      "Testing for epoch 54 index 41:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6153\n",
      "\n",
      "Testing for epoch 54 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5955\n",
      "\n",
      "Testing for epoch 54 index 43:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5937\n",
      "\n",
      "Testing for epoch 54 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5881\n",
      "Epoch 55 of 60\n",
      "\n",
      "Testing for epoch 55 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6227\n",
      "\n",
      "Testing for epoch 55 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6012\n",
      "\n",
      "Testing for epoch 55 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5918\n",
      "\n",
      "Testing for epoch 55 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6095\n",
      "\n",
      "Testing for epoch 55 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6268\n",
      "\n",
      "Testing for epoch 55 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5835\n",
      "\n",
      "Testing for epoch 55 index 7:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6137\n",
      "\n",
      "Testing for epoch 55 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5817\n",
      "\n",
      "Testing for epoch 55 index 9:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5832\n",
      "\n",
      "Testing for epoch 55 index 10:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.6163\n",
      "\n",
      "Testing for epoch 55 index 11:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6535\n",
      "\n",
      "Testing for epoch 55 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6150\n",
      "\n",
      "Testing for epoch 55 index 13:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.6329\n",
      "\n",
      "Testing for epoch 55 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6174\n",
      "\n",
      "Testing for epoch 55 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6237\n",
      "\n",
      "Testing for epoch 55 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6196\n",
      "\n",
      "Testing for epoch 55 index 17:\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.6246\n",
      "\n",
      "Testing for epoch 55 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.5932\n",
      "\n",
      "Testing for epoch 55 index 19:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6317\n",
      "\n",
      "Testing for epoch 55 index 20:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6349\n",
      "\n",
      "Testing for epoch 55 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6371\n",
      "\n",
      "Testing for epoch 55 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6549\n",
      "\n",
      "Testing for epoch 55 index 23:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6351\n",
      "\n",
      "Testing for epoch 55 index 24:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6015\n",
      "\n",
      "Testing for epoch 55 index 25:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6005\n",
      "\n",
      "Testing for epoch 55 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6249\n",
      "\n",
      "Testing for epoch 55 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6486\n",
      "\n",
      "Testing for epoch 55 index 28:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6395\n",
      "\n",
      "Testing for epoch 55 index 29:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6518\n",
      "\n",
      "Testing for epoch 55 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6290\n",
      "\n",
      "Testing for epoch 55 index 31:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.5986\n",
      "\n",
      "Testing for epoch 55 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6157\n",
      "\n",
      "Testing for epoch 55 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6339\n",
      "\n",
      "Testing for epoch 55 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6370\n",
      "\n",
      "Testing for epoch 55 index 35:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6050\n",
      "\n",
      "Testing for epoch 55 index 36:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.6361\n",
      "\n",
      "Testing for epoch 55 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6322\n",
      "\n",
      "Testing for epoch 55 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6322\n",
      "\n",
      "Testing for epoch 55 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6386\n",
      "\n",
      "Testing for epoch 55 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6553\n",
      "\n",
      "Testing for epoch 55 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6373\n",
      "\n",
      "Testing for epoch 55 index 42:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.6274\n",
      "\n",
      "Testing for epoch 55 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6220\n",
      "\n",
      "Testing for epoch 55 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6350\n",
      "Epoch 56 of 60\n",
      "\n",
      "Testing for epoch 56 index 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6250\n",
      "\n",
      "Testing for epoch 56 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6242\n",
      "\n",
      "Testing for epoch 56 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6516\n",
      "\n",
      "Testing for epoch 56 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6307\n",
      "\n",
      "Testing for epoch 56 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6203\n",
      "\n",
      "Testing for epoch 56 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6462\n",
      "\n",
      "Testing for epoch 56 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6534\n",
      "\n",
      "Testing for epoch 56 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6670\n",
      "\n",
      "Testing for epoch 56 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6419\n",
      "\n",
      "Testing for epoch 56 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6362\n",
      "\n",
      "Testing for epoch 56 index 11:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6354\n",
      "\n",
      "Testing for epoch 56 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6331\n",
      "\n",
      "Testing for epoch 56 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6491\n",
      "\n",
      "Testing for epoch 56 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6452\n",
      "\n",
      "Testing for epoch 56 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6377\n",
      "\n",
      "Testing for epoch 56 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6561\n",
      "\n",
      "Testing for epoch 56 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6204\n",
      "\n",
      "Testing for epoch 56 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6249\n",
      "\n",
      "Testing for epoch 56 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6518\n",
      "\n",
      "Testing for epoch 56 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6223\n",
      "\n",
      "Testing for epoch 56 index 21:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6731\n",
      "\n",
      "Testing for epoch 56 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6494\n",
      "\n",
      "Testing for epoch 56 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6651\n",
      "\n",
      "Testing for epoch 56 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6691\n",
      "\n",
      "Testing for epoch 56 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6426\n",
      "\n",
      "Testing for epoch 56 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6433\n",
      "\n",
      "Testing for epoch 56 index 27:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6521\n",
      "\n",
      "Testing for epoch 56 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6475\n",
      "\n",
      "Testing for epoch 56 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6409\n",
      "\n",
      "Testing for epoch 56 index 30:\n",
      "16/16 [==============================] - 0s 929us/step - loss: 7.6482\n",
      "\n",
      "Testing for epoch 56 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6231\n",
      "\n",
      "Testing for epoch 56 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6215\n",
      "\n",
      "Testing for epoch 56 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6398\n",
      "\n",
      "Testing for epoch 56 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6437\n",
      "\n",
      "Testing for epoch 56 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6558\n",
      "\n",
      "Testing for epoch 56 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6475\n",
      "\n",
      "Testing for epoch 56 index 37:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6825\n",
      "\n",
      "Testing for epoch 56 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6560\n",
      "\n",
      "Testing for epoch 56 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6584\n",
      "\n",
      "Testing for epoch 56 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6457\n",
      "\n",
      "Testing for epoch 56 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6585\n",
      "\n",
      "Testing for epoch 56 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6468\n",
      "\n",
      "Testing for epoch 56 index 43:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.6397\n",
      "\n",
      "Testing for epoch 56 index 44:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6442\n",
      "Epoch 57 of 60\n",
      "\n",
      "Testing for epoch 57 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6452\n",
      "\n",
      "Testing for epoch 57 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6738\n",
      "\n",
      "Testing for epoch 57 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6826\n",
      "\n",
      "Testing for epoch 57 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6613\n",
      "\n",
      "Testing for epoch 57 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6411\n",
      "\n",
      "Testing for epoch 57 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6721\n",
      "\n",
      "Testing for epoch 57 index 7:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.6576\n",
      "\n",
      "Testing for epoch 57 index 8:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6681\n",
      "\n",
      "Testing for epoch 57 index 9:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.6482\n",
      "\n",
      "Testing for epoch 57 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6868\n",
      "\n",
      "Testing for epoch 57 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6408\n",
      "\n",
      "Testing for epoch 57 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6542\n",
      "\n",
      "Testing for epoch 57 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6378\n",
      "\n",
      "Testing for epoch 57 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6675\n",
      "\n",
      "Testing for epoch 57 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6626\n",
      "\n",
      "Testing for epoch 57 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6619\n",
      "\n",
      "Testing for epoch 57 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6819\n",
      "\n",
      "Testing for epoch 57 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6708\n",
      "\n",
      "Testing for epoch 57 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6698\n",
      "\n",
      "Testing for epoch 57 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6770\n",
      "\n",
      "Testing for epoch 57 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6547\n",
      "\n",
      "Testing for epoch 57 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6605\n",
      "\n",
      "Testing for epoch 57 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6481\n",
      "\n",
      "Testing for epoch 57 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6610\n",
      "\n",
      "Testing for epoch 57 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6695\n",
      "\n",
      "Testing for epoch 57 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6694\n",
      "\n",
      "Testing for epoch 57 index 27:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6783\n",
      "\n",
      "Testing for epoch 57 index 28:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6538\n",
      "\n",
      "Testing for epoch 57 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6550\n",
      "\n",
      "Testing for epoch 57 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6699\n",
      "\n",
      "Testing for epoch 57 index 31:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7181\n",
      "\n",
      "Testing for epoch 57 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6562\n",
      "\n",
      "Testing for epoch 57 index 33:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6514\n",
      "\n",
      "Testing for epoch 57 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6616\n",
      "\n",
      "Testing for epoch 57 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7102\n",
      "\n",
      "Testing for epoch 57 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6728\n",
      "\n",
      "Testing for epoch 57 index 37:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.6938\n",
      "\n",
      "Testing for epoch 57 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6529\n",
      "\n",
      "Testing for epoch 57 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7274\n",
      "\n",
      "Testing for epoch 57 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6832\n",
      "\n",
      "Testing for epoch 57 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6524\n",
      "\n",
      "Testing for epoch 57 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6736\n",
      "\n",
      "Testing for epoch 57 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6784\n",
      "\n",
      "Testing for epoch 57 index 44:\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6673\n",
      "Epoch 58 of 60\n",
      "\n",
      "Testing for epoch 58 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6974\n",
      "\n",
      "Testing for epoch 58 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6887\n",
      "\n",
      "Testing for epoch 58 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6620\n",
      "\n",
      "Testing for epoch 58 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6736\n",
      "\n",
      "Testing for epoch 58 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6790\n",
      "\n",
      "Testing for epoch 58 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6664\n",
      "\n",
      "Testing for epoch 58 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6914\n",
      "\n",
      "Testing for epoch 58 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6732\n",
      "\n",
      "Testing for epoch 58 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6983\n",
      "\n",
      "Testing for epoch 58 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6546\n",
      "\n",
      "Testing for epoch 58 index 11:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6698\n",
      "\n",
      "Testing for epoch 58 index 12:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6868\n",
      "\n",
      "Testing for epoch 58 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6953\n",
      "\n",
      "Testing for epoch 58 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6927\n",
      "\n",
      "Testing for epoch 58 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6968\n",
      "\n",
      "Testing for epoch 58 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7069\n",
      "\n",
      "Testing for epoch 58 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6734\n",
      "\n",
      "Testing for epoch 58 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6668\n",
      "\n",
      "Testing for epoch 58 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6897\n",
      "\n",
      "Testing for epoch 58 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7141\n",
      "\n",
      "Testing for epoch 58 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6851\n",
      "\n",
      "Testing for epoch 58 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6785\n",
      "\n",
      "Testing for epoch 58 index 23:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6996\n",
      "\n",
      "Testing for epoch 58 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6897\n",
      "\n",
      "Testing for epoch 58 index 25:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6900\n",
      "\n",
      "Testing for epoch 58 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6972\n",
      "\n",
      "Testing for epoch 58 index 27:\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.6835\n",
      "\n",
      "Testing for epoch 58 index 28:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7206\n",
      "\n",
      "Testing for epoch 58 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6613\n",
      "\n",
      "Testing for epoch 58 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6894\n",
      "\n",
      "Testing for epoch 58 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6981\n",
      "\n",
      "Testing for epoch 58 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7085\n",
      "\n",
      "Testing for epoch 58 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7302\n",
      "\n",
      "Testing for epoch 58 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6691\n",
      "\n",
      "Testing for epoch 58 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6980\n",
      "\n",
      "Testing for epoch 58 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6839\n",
      "\n",
      "Testing for epoch 58 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6899\n",
      "\n",
      "Testing for epoch 58 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7083\n",
      "\n",
      "Testing for epoch 58 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6789\n",
      "\n",
      "Testing for epoch 58 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6968\n",
      "\n",
      "Testing for epoch 58 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6782\n",
      "\n",
      "Testing for epoch 58 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7216\n",
      "\n",
      "Testing for epoch 58 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6718\n",
      "\n",
      "Testing for epoch 58 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6814\n",
      "Epoch 59 of 60\n",
      "\n",
      "Testing for epoch 59 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6735\n",
      "\n",
      "Testing for epoch 59 index 2:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.6950\n",
      "\n",
      "Testing for epoch 59 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7070\n",
      "\n",
      "Testing for epoch 59 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7082\n",
      "\n",
      "Testing for epoch 59 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7067\n",
      "\n",
      "Testing for epoch 59 index 6:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7222\n",
      "\n",
      "Testing for epoch 59 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7322\n",
      "\n",
      "Testing for epoch 59 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7158\n",
      "\n",
      "Testing for epoch 59 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7148\n",
      "\n",
      "Testing for epoch 59 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6878\n",
      "\n",
      "Testing for epoch 59 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6961\n",
      "\n",
      "Testing for epoch 59 index 12:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7141\n",
      "\n",
      "Testing for epoch 59 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7086\n",
      "\n",
      "Testing for epoch 59 index 14:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7021\n",
      "\n",
      "Testing for epoch 59 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6836\n",
      "\n",
      "Testing for epoch 59 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6780\n",
      "\n",
      "Testing for epoch 59 index 17:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.7094\n",
      "\n",
      "Testing for epoch 59 index 18:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7064\n",
      "\n",
      "Testing for epoch 59 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7145\n",
      "\n",
      "Testing for epoch 59 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7080\n",
      "\n",
      "Testing for epoch 59 index 21:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.7110\n",
      "\n",
      "Testing for epoch 59 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7131\n",
      "\n",
      "Testing for epoch 59 index 23:\n",
      "16/16 [==============================] - 0s 996us/step - loss: 7.7368\n",
      "\n",
      "Testing for epoch 59 index 24:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7034\n",
      "\n",
      "Testing for epoch 59 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7185\n",
      "\n",
      "Testing for epoch 59 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7183\n",
      "\n",
      "Testing for epoch 59 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7108\n",
      "\n",
      "Testing for epoch 59 index 28:\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.7323\n",
      "\n",
      "Testing for epoch 59 index 29:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6893\n",
      "\n",
      "Testing for epoch 59 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7139\n",
      "\n",
      "Testing for epoch 59 index 31:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7010\n",
      "\n",
      "Testing for epoch 59 index 32:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7326\n",
      "\n",
      "Testing for epoch 59 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7210\n",
      "\n",
      "Testing for epoch 59 index 34:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7256\n",
      "\n",
      "Testing for epoch 59 index 35:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.7299\n",
      "\n",
      "Testing for epoch 59 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7454\n",
      "\n",
      "Testing for epoch 59 index 37:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7073\n",
      "\n",
      "Testing for epoch 59 index 38:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7108\n",
      "\n",
      "Testing for epoch 59 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6892\n",
      "\n",
      "Testing for epoch 59 index 40:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7198\n",
      "\n",
      "Testing for epoch 59 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7696\n",
      "\n",
      "Testing for epoch 59 index 42:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7135\n",
      "\n",
      "Testing for epoch 59 index 43:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7355\n",
      "\n",
      "Testing for epoch 59 index 44:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7518\n",
      "Epoch 60 of 60\n",
      "\n",
      "Testing for epoch 60 index 1:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7137\n",
      "\n",
      "Testing for epoch 60 index 2:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7252\n",
      "\n",
      "Testing for epoch 60 index 3:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7466\n",
      "\n",
      "Testing for epoch 60 index 4:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7381\n",
      "\n",
      "Testing for epoch 60 index 5:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7431\n",
      "\n",
      "Testing for epoch 60 index 6:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7007\n",
      "\n",
      "Testing for epoch 60 index 7:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7218\n",
      "\n",
      "Testing for epoch 60 index 8:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7329\n",
      "\n",
      "Testing for epoch 60 index 9:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7083\n",
      "\n",
      "Testing for epoch 60 index 10:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7430\n",
      "\n",
      "Testing for epoch 60 index 11:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7423\n",
      "\n",
      "Testing for epoch 60 index 12:\n",
      "16/16 [==============================] - 0s 931us/step - loss: 7.7423\n",
      "\n",
      "Testing for epoch 60 index 13:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7466\n",
      "\n",
      "Testing for epoch 60 index 14:\n",
      "16/16 [==============================] - 0s 956us/step - loss: 7.7355\n",
      "\n",
      "Testing for epoch 60 index 15:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6970\n",
      "\n",
      "Testing for epoch 60 index 16:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7409\n",
      "\n",
      "Testing for epoch 60 index 17:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7200\n",
      "\n",
      "Testing for epoch 60 index 18:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7488\n",
      "\n",
      "Testing for epoch 60 index 19:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7422\n",
      "\n",
      "Testing for epoch 60 index 20:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7663\n",
      "\n",
      "Testing for epoch 60 index 21:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7284\n",
      "\n",
      "Testing for epoch 60 index 22:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7480\n",
      "\n",
      "Testing for epoch 60 index 23:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7178\n",
      "\n",
      "Testing for epoch 60 index 24:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7439\n",
      "\n",
      "Testing for epoch 60 index 25:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7393\n",
      "\n",
      "Testing for epoch 60 index 26:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7276\n",
      "\n",
      "Testing for epoch 60 index 27:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7239\n",
      "\n",
      "Testing for epoch 60 index 28:\n",
      "16/16 [==============================] - 0s 952us/step - loss: 7.7244\n",
      "\n",
      "Testing for epoch 60 index 29:\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 7.7451\n",
      "\n",
      "Testing for epoch 60 index 30:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7282\n",
      "\n",
      "Testing for epoch 60 index 31:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7356\n",
      "\n",
      "Testing for epoch 60 index 32:\n",
      "16/16 [==============================] - 0s 991us/step - loss: 7.7407\n",
      "\n",
      "Testing for epoch 60 index 33:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7431\n",
      "\n",
      "Testing for epoch 60 index 34:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7670\n",
      "\n",
      "Testing for epoch 60 index 35:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7782\n",
      "\n",
      "Testing for epoch 60 index 36:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7355\n",
      "\n",
      "Testing for epoch 60 index 37:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7518\n",
      "\n",
      "Testing for epoch 60 index 38:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7534\n",
      "\n",
      "Testing for epoch 60 index 39:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7602\n",
      "\n",
      "Testing for epoch 60 index 40:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7550\n",
      "\n",
      "Testing for epoch 60 index 41:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7644\n",
      "\n",
      "Testing for epoch 60 index 42:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7320\n",
      "\n",
      "Testing for epoch 60 index 43:\n",
      "16/16 [==============================] - 0s 997us/step - loss: 7.7694\n",
      "\n",
      "Testing for epoch 60 index 44:\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SO_GAAL(contamination=0.025196920873612604, decay=1e-06, lr_d=0.01,\n",
       "    lr_g=0.0001, momentum=0.9, stop_epochs=20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.so_gaal import SO_GAAL\n",
    "\n",
    "clf = SO_GAAL(stop_epochs=20, lr_d=0.01, lr_g=0.0001, decay=1e-06, momentum=0.9, contamination=contamination)\n",
    "clf.fit(X_train)\n",
    "\n",
    "#0.5870339799147063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cardiac-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOS(contamination=0.025196920873612604, eps=1e-05, metric='euclidean',\n",
       "  perplexity=4.5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.sos import SOS\n",
    "\n",
    "clf = SOS(contamination=contamination, perplexity=4.5, metric='euclidean', eps=1e-05)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.vae import\n",
    "\n",
    "clf = VAE(encoder_neurons=None, decoder_neurons=None, latent_dim=2, hidden_activation='relu', \n",
    "          output_activation='sigmoid', loss=<function mean_squared_error>, optimizer='adam', \n",
    "          epochs=100, batch_size=32, dropout_rate=0.2, l2_regularizer=0.1, validation_size=0.1, \n",
    "          preprocessing=True, verbose=1, random_state=None, contamination=contamination, gamma=1.0, capacity=0.0)\n",
    "clf.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "living-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\pyod\\models\\base.py:349: UserWarning: y should not be presented in unsupervised learning.\n",
      "  \"y should not be presented in unsupervised learning.\")\n",
      "C:\\Users\\antoi\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBOD(base_score=0.65, booster='gbtree', colsample_bylevel=1,\n",
       "   colsample_bytree=1,\n",
       "   estimator_list=[OCSVM(cache_size=200, coef0=0.0, contamination=0.030134365352002434, degree=5,\n",
       "   gamma='scale', kernel='poly', max_iter=-1, nu=0.8, shrinking=True,\n",
       "   tol=0.001, verbose=False), IForest(behaviour='old', bootstrap=False, contamination=0.030134365352002434,\n",
       "    max_features=1.0, max_samples='auto', n_estimators=50, n_jobs=1,\n",
       "    random_state=None, verbose=0), HBOS(alpha=0.1, contamination=0.030134365352002434, n_bins=5, tol=0.5), COPOD(contamination=0.030134365352002434)],\n",
       "   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "   min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "   nthread=None, objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "   reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "   standardization_flag_list=[True, True, True, True], subsample=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.abod import ABOD\n",
    "\n",
    "clf1 = OCSVM(kernel='poly', degree=5, gamma='scale', coef0=0.0, tol=0.001, nu=0.8, \n",
    "            shrinking=True, cache_size=200, verbose=False, max_iter=- 1, contamination=contamination)\n",
    "\n",
    "\n",
    "clf2 = IForest(n_estimators=50, max_samples='auto', contamination=contamination, max_features=1.0, \n",
    "        bootstrap=False, n_jobs=1, behaviour='old', random_state=None, verbose=0)\n",
    "\n",
    "\n",
    "clf3 = HBOS(n_bins=5, alpha=0.1, tol=0.5, contamination=contamination)\n",
    "\n",
    "\n",
    "clf4 = COPOD(contamination = contamination)\n",
    "\n",
    "\n",
    "# clf5 = ABOD(contamination = contamination, n_neighbors=10, method='fast')\n",
    "\n",
    "\n",
    "estimator_list = [clf1, clf2, clf3, clf4]\n",
    "clf = XGBOD(estimator_list=estimator_list, standardization_flag_list=None, max_depth=3, learning_rate=0.1, \n",
    "            n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, \n",
    "            nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, \n",
    "            colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.65, \n",
    "            missing=None)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-seafood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "perfect-cancellation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "aom() missing 1 required positional argument: 'scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-489ea8409743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombination\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maom\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'static'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: aom() missing 1 required positional argument: 'scores'"
     ]
    }
   ],
   "source": [
    "from pyod.models.combination import aom\n",
    "\n",
    "clf = aom( n_buckets=5, method='static', bootstrap_estimators=False)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-pasta",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "round-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_train, clf.predict(X_train))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-claim",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "european-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8379942782373424"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decif = clf.decision_function(X_val)\n",
    "roc_auc_score(y_val, decif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dressed-botswana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189806583696999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decif = clf.decision_function(X_val)\n",
    "roc_auc_score(y_val, decif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caroline-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744656869326419"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decif = clf.decision_function(X_train)\n",
    "roc_auc_score(y_train, decif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frank-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "decif = clf.decision_function(X_test)\n",
    "np.savetxt('ytest_challenge_student.csv', decif, fmt = '%1.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-torture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
