{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebbf23-1bee-4cbd-b424-97a22f696c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exec(open(\"Libs_Modulus.py\").read())\n",
    "exec(open(\"Links.py\").read())\n",
    "exec(open(\"ConvertTool.py\").read())\n",
    "\"\"\"exec(open(\"CheckDirFiles.py\").read())\"\"\"\n",
    "\n",
    "def CHECK_DATA_DIR(MainDir,DataType):\n",
    "    data_dir = os.path.join(MainDir, DataType)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "        ExistDir = False\n",
    "    else :\n",
    "        ExistDir = True\n",
    "    print(\"Le répertoire '\", DataType, \"' exist : \", np.where(ExistDir==True, \"OK\", \"NOK \\nCréation du répertoire\"))\n",
    "    return ExistDir\n",
    "\n",
    "# Mise à jour des fichiers Excel téléchargés pour les rendre exploitables\n",
    "def UPDATE_FORMAT(file_name, name_filter, change):\n",
    "    tempdir = tempfile.mkdtemp()\n",
    "    try:\n",
    "        tempname = os.path.join(tempdir, 'new.zip')\n",
    "        with ZipFile(file_name, 'r') as r, ZipFile(tempname, 'w') as w:\n",
    "            for item in r.infolist():\n",
    "                data = r.read(item.filename)           \n",
    "                data = change(data)\n",
    "                w.writestr(item, data)\n",
    "        shutil.move(tempname, file_name)\n",
    "    finally:\n",
    "        shutil.rmtree(tempdir)\n",
    "\n",
    "# Obtention de la liste des fichiers de classements journaliers\n",
    "def GET_RANK_LIST (RankURL):\n",
    "    soup = BeautifulSoup(requests.get(RankURL).content.decode(\"utf-8\"))\n",
    "    ListSoup = soup.findAll('option')\n",
    "    RankList = []\n",
    "    for iRankList in ListSoup:\n",
    "        RankList.append(iRankList.text[2:])\n",
    "    RankList = np.unique(RankList[1:-1])\n",
    "    print (\"Il y a \", len(RankList), \"fichiers Excel de classement\")\n",
    "    return RankList\n",
    "        \n",
    "# Téléchargement de fichier de classement journalier\n",
    "def DWNLD_DAILY_RANK_FILE(DLRankURL, TFN, RankFileType, MainDir, DataDir):\n",
    "    os.chdir(MainDir+DataDir)\n",
    "    \n",
    "    with tqdm(range(len(TFN)), desc = \"Chargement des données Excel\") as outer:\n",
    "        for iTFN in TFN:\n",
    "            resp = requests.get(DLRankURL+iTFN+RankFileType)\n",
    "            print(\"vendeeglobe_\"+iTFN+RankFileType)\n",
    "            with open(\"vendeeglobe_\"+iTFN+RankFileType,'wb') as file:\n",
    "                file.write(resp.content)\n",
    "            UPDATE_FORMAT(\"vendeeglobe_\"+iTFN+RankFileType, name_filter='xl/styles.xml', change=lambda d: re.sub(b'xxid=\"\\d*\"', b\"\", d))\n",
    "            outer.update()\n",
    "    os.chdir(MainDir)\n",
    "\n",
    "# Vérification de l'existance de tous les fichiers à télécharger\n",
    "def CHECK_FILE_LIST(MainDir, DataRankDir, TFN):\n",
    "    Directory = os.path.join(MainDir, DataRankDir)\n",
    "    FilesList = [f for f in listdir(Directory) if isfile(join(Directory, f))]\n",
    "    #print(FilesList)\n",
    "    ListToDownLoad = []\n",
    "    for iTFN in TFN:\n",
    "        if  not str(\"vendeeglobe_\"+iTFN+\".xlsx\") in FilesList:\n",
    "            ListToDownLoad.append(iTFN)\n",
    "            pass\n",
    "    return ListToDownLoad\n",
    "\n",
    "\n",
    "\"\"\" MAIN \"\"\"\n",
    "ExistDir = CHECK_DATA_DIR(MainDir,DataRankDir)\n",
    "RankList = GET_RANK_LIST (RankURL)\n",
    "TL,TFN = CONVERT_TIME_FORMAT(RankList)\n",
    "if ExistDir == False :\n",
    "    DWNLD_DAILY_RANK_FILE(DLRankURL, TFN, RankFileType, MainDir, DataRankDir)\n",
    "else :\n",
    "    ListToDownLoad = CHECK_FILE_LIST(MainDir, DataRankDir, TFN)\n",
    "    if len(ListToDownLoad)!=0:\n",
    "        DWNLD_DAILY_RANK_FILE(DLRankURL, ListToDownLoad, RankFileType, MainDir, DataRankDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3ef41-9a1b-4e9d-bc19-677142556640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GEN_SEPCS_DF (SkippersURL):\n",
    "    # Paramètres des types de données à extraire\n",
    "    DataParam = {\"BoatSpecs\" : ['ul', \"class\", \"boats-list__popup-specs-list\"],\n",
    "                 \"Nom voilier\" : ['h3',\"class\",\"boats-list__boat-name\"],\n",
    "                 \"Nom skipper\" : [\"span\",\"class\", \"boats-list__skipper-name\"]}\n",
    "    # Fonction d'extraction de données techniques spécifiques (BoatSpecs, BoatName, SkipperName) sous forme de list\n",
    "    LIST_SOUP = lambda SkippersURL, DataParam,ikey : BeautifulSoup(requests.get(SkippersURL).content.decode(\"utf-8\"))\\\n",
    "    .findAll(DataParam[ikey][0],\n",
    "             {DataParam[ikey][1]:\n",
    "              DataParam[ikey][2]})\n",
    "    \n",
    "    # Création d'un DF Spécifications techniques du voilier vierge\n",
    "    SpecsDF=pd.DataFrame()\n",
    "    \n",
    "    # Remplissage du DF\n",
    "    for ikey in DataParam:\n",
    "        ListSoup = LIST_SOUP (SkippersURL, DataParam, ikey)\n",
    "        \n",
    "        # Remplir d'abord les données techniques du voilier (Num. voile, Anciens nom, Architece, Chantier, Date lanc., Longueur,...)\n",
    "        if ikey == list(DataParam.keys())[0]:\n",
    "            i = 0\n",
    "            for iul in ListSoup:\n",
    "                idata,ivalue = np.transpose([string.split(' : ',1) for string in iul.text.split(\"\\n\")[1:-1]])\n",
    "                SpecsDF = pd.concat([SpecsDF,pd.DataFrame([ivalue],columns = idata)],ignore_index=True)\n",
    "                i+=1\n",
    "        # Ajouter ensuite les colonnes Nom de voilier, et nom du marin; puis les mettre en premières colonnes\n",
    "        else:\n",
    "            SpecsDF[ikey] = [string.text for string in ListSoup]\n",
    "            SpecsDF = SpecsDF[SpecsDF.columns.tolist()[-1:]+SpecsDF.columns.tolist()[:-1]]\n",
    "    \n",
    "    # Homogénéisation des données\n",
    "       # liste des valeurs [init, new] et des unités à supprimer suivant le nom de la colonne \n",
    "    ValToReplace = {\"Date de lancement\":[], # pour reconvertion des dates\n",
    "                    \"Anciens noms du bateau\":[np.nan,''],\"Voile quille\":[np.nan,''], # Pour remplacement des valeurs\n",
    "                    \"Nombre de dérives\":[[\"foiler\", \"2 asymétriques\"],['foils', \"2\"]], # Pour remplacement des valeurs\n",
    "                    \"Longueur\":[' m'],\"Largeur\" :[' m'],\"Tirant d'eau\":[' m'],\"Hauteur mât\":[' m'], # Suppresion des unités de longueur\n",
    "                    \"Surface de voiles au près\":[' m2', ' m²'],\"Surface de voiles au portant\":[' m2', ' m²'], #Suppression des unités de surface\n",
    "                    \"Déplacement (poids)\":[' t', ' tonnes']} #Suppresion des unités de masse\n",
    "    for icol in ValToReplace:\n",
    "        if icol in [\"Anciens noms du bateau\",\"Voile quille\",\"Nombre de dérives\"]:      \n",
    "            SpecsDF[icol] = SpecsDF[icol].replace(ValToReplace[icol][0],ValToReplace[icol][1])\n",
    "        elif \"Date de lancement\" in icol:\n",
    "            SpecsDF[icol] = SpecsDF[icol].apply(dateparser.parse)\n",
    "        else :\n",
    "            for iunit in ValToReplace[icol]:\n",
    "                SpecsDF[icol] = SpecsDF[icol].str.strip(iunit)\n",
    "            if \"Déplacement (poids)\" in icol:\n",
    "                SpecsDF[icol] = SpecsDF[icol].str.replace('[a-zA-Z]', '0', regex=True)\n",
    "            SpecsDF[icol] = SpecsDF[icol].str.replace(',','.')\n",
    "            SpecsDF[icol] = SpecsDF[icol].astype('float')\n",
    "    return SpecsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cdef0-0ad8-4da7-842e-673f2346697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Specs_DF = GEN_SEPCS_DF(SkippersURL)\n",
    "Specs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772497a6-51b2-41fe-89b9-8c8791b7e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XLSX_DIR = os.path.join(MainDir, DataRankDir)\n",
    "os.chdir(XLSX_DIR)\n",
    "df = pd.read_excel (\"vendeeglobe_20210305_080000.xlsx\", header=3)\n",
    "df = df.rename(columns={'Unnamed: 0': 'Date'})\n",
    "df[\"Date\"]='2021/03/05 08:00:00'\n",
    "print('Attention! Date en format str à convertir en format date')\n",
    "\n",
    "df[\"Date d'arrivée\\nArrival date\"] = df[\"Unnamed: 7\"]\n",
    "df.loc[1:,\"Écarts\\nGaps\"] = df.loc[1:,\"Unnamed: 13\"]\n",
    "df.loc[1:,\"Unnamed: 14\"] = df.loc[1:,\"Unnamed: 15\"]\n",
    "df = df.drop([\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\", \"Unnamed: 9\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 13\", \"Unnamed: 15\"], 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9f690-dfef-457c-a341-cb7ee40c3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(XLSX_DIR)\n",
    "print(XLSX_DIR)\n",
    "df = pd.read_excel (\"vendeeglobe_20201108_140000.xlsx\", header=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c06df8-0677-4862-a750-9a986471c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(XLSX_DIR)\n",
    "print(XLSX_DIR)\n",
    "df = pd.read_excel (\"vendeeglobe_20201109_080000.xlsx\", header=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7c9b7-f7d2-46a9-a6f8-1f8f37c0a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFN[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68eaff2-ce92-44ed-b7d0-1eeb26022cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel (\"vendeeglobe_\"+TFN[0]+\".xlsx\", header=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0682af-d875-4b05-9378-07717ad5d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TFN)\n",
    "for i in TFN:\n",
    "#     print (i)\n",
    "    UPDATE_FORMAT(\"vendeeglobe_\"+i+RankFileType, name_filter='xl/styles.xml', change=lambda d: re.sub(b'xxid=\"\\d*\"', b\"\", d))\n",
    "\n",
    "    df = pd.read_excel (\"vendeeglobe_\"+i+\".xlsx\", header=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee497c1-03a2-4df5-86c0-4f5923340024",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(XLSX_DIR)\n",
    "print(XLSX_DIR)\n",
    "df = pd.read_excel (\"vendeeglobe_20201201_040000.xlsx\", header=3)\n",
    "\"\"\"df = df.rename(columns={'Unnamed: 0': 'Date'})\n",
    "df[\"Date\"]='2021/03/05 14:00:00'\n",
    "print('Attention! Date en format str à convertir en format date')\n",
    "\n",
    "df[\"Date d'arrivée\\nArrival date\"] = df[\"Unnamed: 7\"]\n",
    "df.loc[1:,\"Écarts\\nGaps\"] = df.loc[1:,\"Unnamed: 13\"]\n",
    "df.loc[1:,\"Unnamed: 14\"] = df.loc[1:,\"Unnamed: 15\"]\n",
    "df = df.drop([\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\", \"Unnamed: 9\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 13\", \"Unnamed: 15\"], 1)\n",
    "df.head()\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fe7bb-400e-4535-804f-a4911aa2ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "RankList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0d9d9-2679-42bf-a503-cd97984d8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import shutil\n",
    "url = \"https://www.vendeeglobe.org/download-race-data/vendeeglobe_20201108_140000.xlsx\"\n",
    "filename = \"vendeeglobe_20201108_140000.xlsx\"\n",
    "\n",
    "with request.urlopen(url) as response, open(filename, 'wb') as out_file: shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671eba3d-45bf-48de-b4c1-f559a5d369c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel (\"vendeeglobe_20201108_140000.xlsx\",sheet_name=0, header=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79139b42-0a57-4d2b-8d59-06af6410d0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2fba8-645b-4c06-bc4b-e054c72b79dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
